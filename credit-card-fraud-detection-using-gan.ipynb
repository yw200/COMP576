{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "1fa9c421-e3e1-4a2c-978f-28f78e01ab34",
    "_uuid": "04bcbe2c5f6b3f74f6f8732c41e8e8e15654d311",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ad3d861f-12e4-49ca-a221-6d8bd6be6f8a",
    "_uuid": "24bc772bdd624e7d844b74020e273ffe3def4246",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "ac5f5f90-1607-4c5e-b0e7-845c724c7521",
    "_uuid": "7f9f454f8341834b0c6ab1a3de99b2577dcd7dd0",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8f0c6894-0f3c-4f1a-9b2e-5155cc434ab8",
    "_uuid": "ae27e9aac252b8abebe73a7f152e8285f6ae6671",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "40293e6e-ec35-4847-90f1-1e6e89f70b91",
    "_uuid": "7ba46b55bc860137cbde1b97572a918dec5970d3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('Time',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "25ea497f-93a3-4818-b1e5-a40c9ae9b81d",
    "_uuid": "8ab18d55eacc48d3f578c2c1977a789f9b95e03e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('Class',axis=1).values \n",
    "y = df['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c4737b0e-f780-45b4-b1cc-c0bd1d419b41",
    "_uuid": "4e153e0a8bbd54231af019089db7ceac7d4a3ab2",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "5788dbeb-8aa2-42a5-99af-b4e367de3808",
    "_uuid": "66ce9da4edfea3e8b6619d5f543b365899a59a5e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X -= X.min(axis=0)\n",
    "X /= X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "57b2f8a6-9c45-4f60-a0ff-8aef07b2f484",
    "_uuid": "c36820c67500d54458d9b22ebc2293f2e8ccf99f",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5213456986251124"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "f79cfb3e-0a02-4052-b057-dfd6b96ac026",
    "_uuid": "91d77fc484400c0bc3ba4c3b16ebd9873d3da966",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "78e7cc64-e345-45c4-8c4e-52aa50cb9c21",
    "_uuid": "156872c244cdf82a28daa404fe1ebaaa96c52d0d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "572018d0-a703-43a9-aeee-4e1b655e350a",
    "_uuid": "1bf08d19c1f69f194b577e9ef1d652e1a7a24196",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Embedding, multiply, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "# Deterministic output.\n",
    "# Tired of seeing the same results every time? Remove the line below.\n",
    "np.random.seed(1000)\n",
    "\n",
    "# The results are a little better when the dimensionality of the random vector is only 10.\n",
    "# The dimensionality has been left at 100 for consistency with other GAN implementations.\n",
    "randomDim = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "0e0dc6cbb6ba7841c404ad1722a1bf957b9c0c71",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_generator(latent_dim,data_dim):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(16, input_dim=latent_dim))\n",
    "    \n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(32, input_dim=latent_dim))\n",
    "    \n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(data_dim,activation='tanh'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "dff92e28df4d9b059f7e302aff0d4d374f4380bc",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 29)                957       \n",
      "=================================================================\n",
      "Total params: 1,869\n",
      "Trainable params: 1,773\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator(latent_dim=10,data_dim=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "52ff75e25d1db36679536594e80073f1e98a8205",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_discriminator(data_dim,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(31,input_dim=data_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(16,input_dim=data_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.summary()\n",
    "    img = Input(shape=(data_dim,))\n",
    "    features = model(img)\n",
    "    valid = Dense(1, activation=\"sigmoid\")(features)\n",
    "    label = Dense(num_classes+1, activation=\"softmax\")(features)\n",
    "    return Model(img, [valid, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "c4497a47e1f8d9218ea5463f9476a7c3c7592369",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 31)                930       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 31)                124       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 1,566\n",
      "Trainable params: 1,504\n",
      "Non-trainable params: 62\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator(data_dim=29,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "c29a35e4e0a2e9d0b349373c24ab0fae1bdf85f3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0002, 0.5)\n",
    "discriminator.compile(loss=['binary_crossentropy', 'categorical_crossentropy'],\n",
    "    loss_weights=[0.5, 0.5],\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "868d72058acc8074c6144032890def6deb200def",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = Input(shape=(10,))\n",
    "img = generator(noise)\n",
    "discriminator.trainable = False\n",
    "valid,_ = discriminator(img)\n",
    "combined = Model(noise , valid)\n",
    "combined.compile(loss=['binary_crossentropy'],\n",
    "    optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "52864000452f21f43505dd97ca414deb508e839f",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256326, 29)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "b85ecac37805e937412c02f47461c0c59a2f3a0d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "e6a1493cf4397402463a18b85a2ae24d7ed93639",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "faf05a4ef5cded3a5e21681d0956cebfbf9c2efb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_res, y_res = rus.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "6d1c4f982b9a649a1191ebe975c2a9a26a6f4a3e",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 29)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "3ee6d6276b542dbb9484e14dbd75156ba8e16efb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_res -= X_res.min()\n",
    "X_res /= X_res.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "f906b0eb02f40139ed4ee9adde6e0175358d8cc4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test -= X_test.min()\n",
    "X_test /= X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "b85f188577271c544c6b82a133f70380a1ba303f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_res, y_test_res = rus.fit_sample(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "d0ed0b90189d4ae0ffad536db958905c0270d0b4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "f1c158a5e790d62752767226791a34b8583dae8f",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "68eee475d3fa477523453ff78aeef868f36f6079",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_train,y_train,\n",
    "          X_test,y_test,\n",
    "          generator,discriminator,\n",
    "          combined,\n",
    "          num_classes,\n",
    "          epochs, \n",
    "          batch_size=128):\n",
    "    \n",
    "    f1_progress = []\n",
    "    d_loss_progress = []\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    noise_until = epochs\n",
    "\n",
    "    # Class weights:\n",
    "    # To balance the difference in occurences of digit class labels.\n",
    "    # 50% of labels that the discriminator trains on are 'fake'.\n",
    "    # Weight = 1 / frequency\n",
    "    cw1 = {0: 1, 1: 1}\n",
    "    cw2 = {i: num_classes / half_batch for i in range(num_classes)}\n",
    "    cw2[num_classes] = 1 / half_batch \n",
    "    d_loss_sum = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a half batch of new images\n",
    "        noise = np.random.normal(0, 1, (half_batch, 10))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        valid = np.ones((half_batch, 1))\n",
    "        fake = np.zeros((half_batch, 1))\n",
    "\n",
    "        labels = to_categorical(y_train[idx], num_classes=num_classes+1)\n",
    "        fake_labels = to_categorical(np.full((half_batch, 1), num_classes), num_classes=num_classes+1)\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, [valid, labels], class_weight=[cw1, cw2])\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, [fake, fake_labels], class_weight=[cw1, cw2])\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, 10))\n",
    "        validity = np.ones((batch_size, 1))\n",
    "\n",
    "        # Train the generator\n",
    "        g_loss = combined.train_on_batch(noise, validity, class_weight=[cw1, cw2])\n",
    "\n",
    "        # Plot the progress\n",
    "        print (\"%d [D loss: %f, acc: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss))\n",
    "        d_loss_sum += 100*d_loss[3]\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            _,y_pred = discriminator.predict(X_test,batch_size=batch_size)\n",
    "            #print(y_pred.shape)\n",
    "            y_pred = np.argmax(y_pred[:,:-1],axis=1)\n",
    "            \n",
    "            f1 = f1_score(y_test,y_pred)\n",
    "            print('Epoch: {}, F1: {:.5f}, F1P: {}'.format(epoch,f1,len(f1_progress)))\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            print(cm)\n",
    "            print(d_loss_sum/10)\n",
    "            d_loss_progress.append(d_loss_sum/10)\n",
    "            f1_progress.append(f1)\n",
    "            d_loss_sum = 0\n",
    "    \n",
    "    return f1_progress, d_loss_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "bf5e4c217d9b0036e859b818561a9274d32027ce",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.439273, acc: 46.09%, op_acc: 25.78%] [G loss: 1.320194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, F1: 0.00000, F1P: 0\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "4.609375\n",
      "1 [D loss: 0.458723, acc: 42.97%, op_acc: 32.81%] [G loss: 1.346049]\n",
      "2 [D loss: 0.432519, acc: 45.31%, op_acc: 32.03%] [G loss: 1.374250]\n",
      "3 [D loss: 0.414698, acc: 51.56%, op_acc: 27.34%] [G loss: 1.258614]\n",
      "4 [D loss: 0.414752, acc: 49.22%, op_acc: 24.22%] [G loss: 1.314001]\n",
      "5 [D loss: 0.432760, acc: 45.31%, op_acc: 35.16%] [G loss: 1.283181]\n",
      "6 [D loss: 0.419293, acc: 52.34%, op_acc: 27.34%] [G loss: 1.280741]\n",
      "7 [D loss: 0.410582, acc: 50.00%, op_acc: 35.16%] [G loss: 1.297835]\n",
      "8 [D loss: 0.428324, acc: 44.53%, op_acc: 28.12%] [G loss: 1.289194]\n",
      "9 [D loss: 0.425711, acc: 40.62%, op_acc: 35.16%] [G loss: 1.253742]\n",
      "10 [D loss: 0.411636, acc: 46.88%, op_acc: 28.91%] [G loss: 1.252674]\n",
      "Epoch: 10, F1: 0.00000, F1P: 1\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "46.875\n",
      "11 [D loss: 0.389944, acc: 52.34%, op_acc: 26.56%] [G loss: 1.353067]\n",
      "12 [D loss: 0.428245, acc: 46.88%, op_acc: 29.69%] [G loss: 1.222009]\n",
      "13 [D loss: 0.424176, acc: 50.78%, op_acc: 28.91%] [G loss: 1.306067]\n",
      "14 [D loss: 0.416465, acc: 46.88%, op_acc: 25.78%] [G loss: 1.271082]\n",
      "15 [D loss: 0.413473, acc: 48.44%, op_acc: 25.00%] [G loss: 1.272163]\n",
      "16 [D loss: 0.376546, acc: 50.00%, op_acc: 33.59%] [G loss: 1.264589]\n",
      "17 [D loss: 0.408083, acc: 48.44%, op_acc: 32.03%] [G loss: 1.271337]\n",
      "18 [D loss: 0.409889, acc: 50.00%, op_acc: 25.78%] [G loss: 1.191557]\n",
      "19 [D loss: 0.380485, acc: 52.34%, op_acc: 33.59%] [G loss: 1.248498]\n",
      "20 [D loss: 0.393520, acc: 42.97%, op_acc: 39.84%] [G loss: 1.214618]\n",
      "Epoch: 20, F1: 0.00000, F1P: 2\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "48.90625\n",
      "21 [D loss: 0.397028, acc: 43.75%, op_acc: 32.81%] [G loss: 1.222709]\n",
      "22 [D loss: 0.410320, acc: 50.78%, op_acc: 27.34%] [G loss: 1.274109]\n",
      "23 [D loss: 0.418704, acc: 48.44%, op_acc: 28.12%] [G loss: 1.197167]\n",
      "24 [D loss: 0.372260, acc: 53.91%, op_acc: 33.59%] [G loss: 1.266017]\n",
      "25 [D loss: 0.388258, acc: 50.00%, op_acc: 30.47%] [G loss: 1.167560]\n",
      "26 [D loss: 0.405670, acc: 50.00%, op_acc: 28.12%] [G loss: 1.233591]\n",
      "27 [D loss: 0.391199, acc: 53.12%, op_acc: 35.94%] [G loss: 1.223972]\n",
      "28 [D loss: 0.395501, acc: 52.34%, op_acc: 35.16%] [G loss: 1.246824]\n",
      "29 [D loss: 0.380162, acc: 47.66%, op_acc: 35.16%] [G loss: 1.199223]\n",
      "30 [D loss: 0.386872, acc: 53.12%, op_acc: 32.81%] [G loss: 1.170817]\n",
      "Epoch: 30, F1: 0.00000, F1P: 3\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "50.3125\n",
      "31 [D loss: 0.367819, acc: 53.12%, op_acc: 28.91%] [G loss: 1.189304]\n",
      "32 [D loss: 0.404721, acc: 51.56%, op_acc: 32.81%] [G loss: 1.142359]\n",
      "33 [D loss: 0.392479, acc: 48.44%, op_acc: 37.50%] [G loss: 1.205999]\n",
      "34 [D loss: 0.382559, acc: 50.00%, op_acc: 35.94%] [G loss: 1.125578]\n",
      "35 [D loss: 0.359620, acc: 57.81%, op_acc: 39.06%] [G loss: 1.219963]\n",
      "36 [D loss: 0.406989, acc: 45.31%, op_acc: 32.81%] [G loss: 1.216635]\n",
      "37 [D loss: 0.379331, acc: 52.34%, op_acc: 32.03%] [G loss: 1.220491]\n",
      "38 [D loss: 0.384888, acc: 47.66%, op_acc: 27.34%] [G loss: 1.162245]\n",
      "39 [D loss: 0.381504, acc: 53.12%, op_acc: 35.16%] [G loss: 1.164136]\n",
      "40 [D loss: 0.389292, acc: 47.66%, op_acc: 26.56%] [G loss: 1.188822]\n",
      "Epoch: 40, F1: 0.00000, F1P: 4\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "50.703125\n",
      "41 [D loss: 0.366074, acc: 54.69%, op_acc: 32.03%] [G loss: 1.139724]\n",
      "42 [D loss: 0.343801, acc: 53.91%, op_acc: 35.94%] [G loss: 1.242477]\n",
      "43 [D loss: 0.364009, acc: 55.47%, op_acc: 37.50%] [G loss: 1.197409]\n",
      "44 [D loss: 0.383903, acc: 51.56%, op_acc: 32.81%] [G loss: 1.153367]\n",
      "45 [D loss: 0.364744, acc: 52.34%, op_acc: 36.72%] [G loss: 1.070953]\n",
      "46 [D loss: 0.372486, acc: 56.25%, op_acc: 29.69%] [G loss: 1.167153]\n",
      "47 [D loss: 0.359627, acc: 51.56%, op_acc: 36.72%] [G loss: 1.170955]\n",
      "48 [D loss: 0.386645, acc: 50.00%, op_acc: 31.25%] [G loss: 1.206775]\n",
      "49 [D loss: 0.370889, acc: 48.44%, op_acc: 40.62%] [G loss: 1.217371]\n",
      "50 [D loss: 0.362973, acc: 58.59%, op_acc: 33.59%] [G loss: 1.125053]\n",
      "Epoch: 50, F1: 0.00000, F1P: 5\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "53.28125\n",
      "51 [D loss: 0.378673, acc: 49.22%, op_acc: 29.69%] [G loss: 1.172433]\n",
      "52 [D loss: 0.344382, acc: 58.59%, op_acc: 32.03%] [G loss: 1.170774]\n",
      "53 [D loss: 0.367690, acc: 53.12%, op_acc: 31.25%] [G loss: 1.159026]\n",
      "54 [D loss: 0.362437, acc: 55.47%, op_acc: 38.28%] [G loss: 1.182828]\n",
      "55 [D loss: 0.369285, acc: 52.34%, op_acc: 34.38%] [G loss: 1.123915]\n",
      "56 [D loss: 0.381373, acc: 50.00%, op_acc: 31.25%] [G loss: 1.172302]\n",
      "57 [D loss: 0.360265, acc: 57.03%, op_acc: 39.84%] [G loss: 1.100368]\n",
      "58 [D loss: 0.359746, acc: 56.25%, op_acc: 30.47%] [G loss: 1.136445]\n",
      "59 [D loss: 0.365805, acc: 53.12%, op_acc: 28.91%] [G loss: 1.152484]\n",
      "60 [D loss: 0.373083, acc: 52.34%, op_acc: 32.81%] [G loss: 1.215223]\n",
      "Epoch: 60, F1: 0.00000, F1P: 6\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "53.75\n",
      "61 [D loss: 0.368243, acc: 55.47%, op_acc: 32.03%] [G loss: 1.184590]\n",
      "62 [D loss: 0.343684, acc: 53.91%, op_acc: 35.94%] [G loss: 1.161571]\n",
      "63 [D loss: 0.377171, acc: 50.00%, op_acc: 33.59%] [G loss: 1.182199]\n",
      "64 [D loss: 0.361677, acc: 53.12%, op_acc: 36.72%] [G loss: 1.125134]\n",
      "65 [D loss: 0.361813, acc: 53.91%, op_acc: 33.59%] [G loss: 1.133728]\n",
      "66 [D loss: 0.362174, acc: 51.56%, op_acc: 43.75%] [G loss: 1.148651]\n",
      "67 [D loss: 0.370196, acc: 54.69%, op_acc: 25.78%] [G loss: 1.123719]\n",
      "68 [D loss: 0.380704, acc: 49.22%, op_acc: 36.72%] [G loss: 1.117914]\n",
      "69 [D loss: 0.369235, acc: 55.47%, op_acc: 35.94%] [G loss: 1.077492]\n",
      "70 [D loss: 0.367161, acc: 53.91%, op_acc: 25.00%] [G loss: 1.066731]\n",
      "Epoch: 70, F1: 0.00000, F1P: 7\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "53.125\n",
      "71 [D loss: 0.379071, acc: 50.00%, op_acc: 34.38%] [G loss: 1.120597]\n",
      "72 [D loss: 0.355970, acc: 56.25%, op_acc: 36.72%] [G loss: 1.084354]\n",
      "73 [D loss: 0.356793, acc: 58.59%, op_acc: 34.38%] [G loss: 1.165477]\n",
      "74 [D loss: 0.347343, acc: 56.25%, op_acc: 35.94%] [G loss: 1.159560]\n",
      "75 [D loss: 0.368971, acc: 46.09%, op_acc: 35.94%] [G loss: 1.112389]\n",
      "76 [D loss: 0.381689, acc: 50.78%, op_acc: 37.50%] [G loss: 1.124418]\n",
      "77 [D loss: 0.359621, acc: 51.56%, op_acc: 37.50%] [G loss: 1.151844]\n",
      "78 [D loss: 0.355513, acc: 53.91%, op_acc: 28.91%] [G loss: 1.070052]\n",
      "79 [D loss: 0.367373, acc: 50.00%, op_acc: 34.38%] [G loss: 1.107402]\n",
      "80 [D loss: 0.333537, acc: 59.38%, op_acc: 30.47%] [G loss: 1.152173]\n",
      "Epoch: 80, F1: 0.00000, F1P: 8\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "53.28125\n",
      "81 [D loss: 0.348061, acc: 59.38%, op_acc: 33.59%] [G loss: 1.125344]\n",
      "82 [D loss: 0.365762, acc: 54.69%, op_acc: 37.50%] [G loss: 1.174474]\n",
      "83 [D loss: 0.351349, acc: 57.81%, op_acc: 36.72%] [G loss: 1.088875]\n",
      "84 [D loss: 0.359248, acc: 54.69%, op_acc: 44.53%] [G loss: 1.148298]\n",
      "85 [D loss: 0.365918, acc: 53.91%, op_acc: 34.38%] [G loss: 1.099133]\n",
      "86 [D loss: 0.364931, acc: 54.69%, op_acc: 30.47%] [G loss: 1.130146]\n",
      "87 [D loss: 0.345372, acc: 60.94%, op_acc: 43.75%] [G loss: 1.081763]\n",
      "88 [D loss: 0.349099, acc: 60.94%, op_acc: 38.28%] [G loss: 1.104506]\n",
      "89 [D loss: 0.355478, acc: 56.25%, op_acc: 34.38%] [G loss: 1.014384]\n",
      "90 [D loss: 0.350153, acc: 61.72%, op_acc: 32.81%] [G loss: 1.085823]\n",
      "Epoch: 90, F1: 0.00000, F1P: 9\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "57.5\n",
      "91 [D loss: 0.350695, acc: 53.91%, op_acc: 42.19%] [G loss: 1.159383]\n",
      "92 [D loss: 0.355989, acc: 51.56%, op_acc: 39.06%] [G loss: 1.135880]\n",
      "93 [D loss: 0.328679, acc: 66.41%, op_acc: 35.16%] [G loss: 1.078219]\n",
      "94 [D loss: 0.340485, acc: 57.03%, op_acc: 39.84%] [G loss: 1.179299]\n",
      "95 [D loss: 0.320286, acc: 64.06%, op_acc: 35.16%] [G loss: 1.118599]\n",
      "96 [D loss: 0.341265, acc: 59.38%, op_acc: 35.94%] [G loss: 1.133572]\n",
      "97 [D loss: 0.332950, acc: 61.72%, op_acc: 38.28%] [G loss: 1.131717]\n",
      "98 [D loss: 0.342183, acc: 61.72%, op_acc: 42.19%] [G loss: 1.155226]\n",
      "99 [D loss: 0.334219, acc: 65.62%, op_acc: 37.50%] [G loss: 1.144267]\n",
      "100 [D loss: 0.341200, acc: 64.06%, op_acc: 34.38%] [G loss: 1.089590]\n",
      "Epoch: 100, F1: 0.00000, F1P: 10\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.546875\n",
      "101 [D loss: 0.342635, acc: 56.25%, op_acc: 36.72%] [G loss: 1.095805]\n",
      "102 [D loss: 0.330414, acc: 60.94%, op_acc: 33.59%] [G loss: 1.077238]\n",
      "103 [D loss: 0.341854, acc: 60.16%, op_acc: 34.38%] [G loss: 1.097973]\n",
      "104 [D loss: 0.338749, acc: 58.59%, op_acc: 37.50%] [G loss: 1.148107]\n",
      "105 [D loss: 0.343576, acc: 56.25%, op_acc: 38.28%] [G loss: 1.081483]\n",
      "106 [D loss: 0.328250, acc: 64.84%, op_acc: 36.72%] [G loss: 1.101701]\n",
      "107 [D loss: 0.318374, acc: 70.31%, op_acc: 37.50%] [G loss: 1.098279]\n",
      "108 [D loss: 0.309786, acc: 66.41%, op_acc: 43.75%] [G loss: 1.116617]\n",
      "109 [D loss: 0.332053, acc: 60.16%, op_acc: 39.06%] [G loss: 1.078907]\n",
      "110 [D loss: 0.349847, acc: 60.16%, op_acc: 39.06%] [G loss: 1.078754]\n",
      "Epoch: 110, F1: 0.00000, F1P: 11\n",
      "[[28431     1]\n",
      " [   49     0]]\n",
      "61.40625\n",
      "111 [D loss: 0.330602, acc: 62.50%, op_acc: 36.72%] [G loss: 0.986616]\n",
      "112 [D loss: 0.325907, acc: 67.19%, op_acc: 37.50%] [G loss: 1.099256]\n",
      "113 [D loss: 0.339320, acc: 57.81%, op_acc: 41.41%] [G loss: 1.167797]\n",
      "114 [D loss: 0.333529, acc: 63.28%, op_acc: 34.38%] [G loss: 1.070431]\n",
      "115 [D loss: 0.337532, acc: 58.59%, op_acc: 43.75%] [G loss: 1.096843]\n",
      "116 [D loss: 0.327837, acc: 61.72%, op_acc: 39.84%] [G loss: 1.131990]\n",
      "117 [D loss: 0.330124, acc: 66.41%, op_acc: 42.19%] [G loss: 1.074313]\n",
      "118 [D loss: 0.327258, acc: 64.06%, op_acc: 38.28%] [G loss: 1.102253]\n",
      "119 [D loss: 0.345894, acc: 61.72%, op_acc: 41.41%] [G loss: 1.044495]\n",
      "120 [D loss: 0.320218, acc: 69.53%, op_acc: 38.28%] [G loss: 1.060041]\n",
      "Epoch: 120, F1: 0.00000, F1P: 12\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "63.28125\n",
      "121 [D loss: 0.335597, acc: 60.16%, op_acc: 38.28%] [G loss: 1.030897]\n",
      "122 [D loss: 0.344511, acc: 60.16%, op_acc: 39.06%] [G loss: 1.019514]\n",
      "123 [D loss: 0.324414, acc: 63.28%, op_acc: 41.41%] [G loss: 1.099241]\n",
      "124 [D loss: 0.326731, acc: 67.97%, op_acc: 39.84%] [G loss: 1.081991]\n",
      "125 [D loss: 0.340483, acc: 60.94%, op_acc: 39.06%] [G loss: 1.078916]\n",
      "126 [D loss: 0.325992, acc: 66.41%, op_acc: 39.84%] [G loss: 1.086772]\n",
      "127 [D loss: 0.332455, acc: 57.03%, op_acc: 42.19%] [G loss: 1.059948]\n",
      "128 [D loss: 0.314587, acc: 71.09%, op_acc: 42.97%] [G loss: 1.055153]\n",
      "129 [D loss: 0.323194, acc: 62.50%, op_acc: 40.62%] [G loss: 1.057197]\n",
      "130 [D loss: 0.317132, acc: 67.19%, op_acc: 40.62%] [G loss: 1.069801]\n",
      "Epoch: 130, F1: 0.00000, F1P: 13\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "63.671875\n",
      "131 [D loss: 0.313411, acc: 66.41%, op_acc: 35.94%] [G loss: 1.106210]\n",
      "132 [D loss: 0.342674, acc: 63.28%, op_acc: 35.94%] [G loss: 1.094955]\n",
      "133 [D loss: 0.318375, acc: 70.31%, op_acc: 35.94%] [G loss: 1.038174]\n",
      "134 [D loss: 0.335142, acc: 64.84%, op_acc: 42.97%] [G loss: 1.104150]\n",
      "135 [D loss: 0.319883, acc: 65.62%, op_acc: 37.50%] [G loss: 1.055049]\n",
      "136 [D loss: 0.302745, acc: 66.41%, op_acc: 41.41%] [G loss: 1.083780]\n",
      "137 [D loss: 0.328300, acc: 69.53%, op_acc: 39.84%] [G loss: 1.071023]\n",
      "138 [D loss: 0.322591, acc: 65.62%, op_acc: 43.75%] [G loss: 1.037179]\n",
      "139 [D loss: 0.327310, acc: 66.41%, op_acc: 42.97%] [G loss: 1.030512]\n",
      "140 [D loss: 0.344444, acc: 63.28%, op_acc: 38.28%] [G loss: 1.034173]\n",
      "Epoch: 140, F1: 0.00000, F1P: 14\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "66.171875\n",
      "141 [D loss: 0.330726, acc: 64.06%, op_acc: 42.19%] [G loss: 1.172268]\n",
      "142 [D loss: 0.347060, acc: 61.72%, op_acc: 36.72%] [G loss: 1.033087]\n",
      "143 [D loss: 0.321833, acc: 69.53%, op_acc: 44.53%] [G loss: 1.064355]\n",
      "144 [D loss: 0.329337, acc: 68.75%, op_acc: 44.53%] [G loss: 1.070136]\n",
      "145 [D loss: 0.324993, acc: 71.09%, op_acc: 35.94%] [G loss: 1.038772]\n",
      "146 [D loss: 0.324695, acc: 68.75%, op_acc: 41.41%] [G loss: 1.056578]\n",
      "147 [D loss: 0.321528, acc: 65.62%, op_acc: 35.16%] [G loss: 1.075774]\n",
      "148 [D loss: 0.330202, acc: 65.62%, op_acc: 44.53%] [G loss: 1.112142]\n",
      "149 [D loss: 0.309444, acc: 69.53%, op_acc: 35.94%] [G loss: 1.070227]\n",
      "150 [D loss: 0.331468, acc: 61.72%, op_acc: 42.97%] [G loss: 1.056003]\n",
      "Epoch: 150, F1: 0.00000, F1P: 15\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "66.640625\n",
      "151 [D loss: 0.326433, acc: 64.84%, op_acc: 36.72%] [G loss: 1.046116]\n",
      "152 [D loss: 0.334988, acc: 58.59%, op_acc: 36.72%] [G loss: 1.081584]\n",
      "153 [D loss: 0.313519, acc: 65.62%, op_acc: 39.06%] [G loss: 1.064012]\n",
      "154 [D loss: 0.315581, acc: 71.88%, op_acc: 42.19%] [G loss: 1.069188]\n",
      "155 [D loss: 0.328314, acc: 72.66%, op_acc: 40.62%] [G loss: 1.089309]\n",
      "156 [D loss: 0.327339, acc: 66.41%, op_acc: 35.94%] [G loss: 1.070366]\n",
      "157 [D loss: 0.308909, acc: 67.97%, op_acc: 40.62%] [G loss: 1.060195]\n",
      "158 [D loss: 0.312102, acc: 71.88%, op_acc: 45.31%] [G loss: 1.069137]\n",
      "159 [D loss: 0.317068, acc: 66.41%, op_acc: 43.75%] [G loss: 1.062211]\n",
      "160 [D loss: 0.313451, acc: 71.88%, op_acc: 45.31%] [G loss: 1.007311]\n",
      "Epoch: 160, F1: 0.00000, F1P: 16\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "67.8125\n",
      "161 [D loss: 0.321146, acc: 71.09%, op_acc: 42.97%] [G loss: 1.129062]\n",
      "162 [D loss: 0.321134, acc: 70.31%, op_acc: 39.06%] [G loss: 1.054168]\n",
      "163 [D loss: 0.325694, acc: 67.97%, op_acc: 40.62%] [G loss: 1.167095]\n",
      "164 [D loss: 0.323147, acc: 67.19%, op_acc: 38.28%] [G loss: 1.046729]\n",
      "165 [D loss: 0.327642, acc: 70.31%, op_acc: 36.72%] [G loss: 1.016927]\n",
      "166 [D loss: 0.301752, acc: 69.53%, op_acc: 42.97%] [G loss: 1.166117]\n",
      "167 [D loss: 0.315138, acc: 67.19%, op_acc: 42.19%] [G loss: 1.091724]\n",
      "168 [D loss: 0.320858, acc: 70.31%, op_acc: 42.19%] [G loss: 1.077971]\n",
      "169 [D loss: 0.313380, acc: 75.78%, op_acc: 39.84%] [G loss: 1.040231]\n",
      "170 [D loss: 0.313276, acc: 77.34%, op_acc: 49.22%] [G loss: 1.077505]\n",
      "Epoch: 170, F1: 0.00000, F1P: 17\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "70.703125\n",
      "171 [D loss: 0.302652, acc: 73.44%, op_acc: 41.41%] [G loss: 1.094785]\n",
      "172 [D loss: 0.324669, acc: 64.84%, op_acc: 45.31%] [G loss: 1.053584]\n",
      "173 [D loss: 0.305676, acc: 74.22%, op_acc: 42.97%] [G loss: 1.040566]\n",
      "174 [D loss: 0.306162, acc: 71.88%, op_acc: 37.50%] [G loss: 1.063030]\n",
      "175 [D loss: 0.306922, acc: 68.75%, op_acc: 43.75%] [G loss: 1.051876]\n",
      "176 [D loss: 0.305072, acc: 74.22%, op_acc: 39.84%] [G loss: 1.087731]\n",
      "177 [D loss: 0.293400, acc: 75.00%, op_acc: 42.19%] [G loss: 1.051767]\n",
      "178 [D loss: 0.323442, acc: 67.97%, op_acc: 50.78%] [G loss: 1.051927]\n",
      "179 [D loss: 0.305911, acc: 67.97%, op_acc: 42.19%] [G loss: 1.074584]\n",
      "180 [D loss: 0.317372, acc: 71.09%, op_acc: 41.41%] [G loss: 1.148330]\n",
      "Epoch: 180, F1: 0.00000, F1P: 18\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "70.9375\n",
      "181 [D loss: 0.306972, acc: 74.22%, op_acc: 46.09%] [G loss: 1.042850]\n",
      "182 [D loss: 0.316126, acc: 63.28%, op_acc: 43.75%] [G loss: 1.008363]\n",
      "183 [D loss: 0.299155, acc: 75.78%, op_acc: 42.19%] [G loss: 1.090851]\n",
      "184 [D loss: 0.326745, acc: 67.19%, op_acc: 38.28%] [G loss: 1.116122]\n",
      "185 [D loss: 0.309705, acc: 74.22%, op_acc: 43.75%] [G loss: 1.026601]\n",
      "186 [D loss: 0.311381, acc: 72.66%, op_acc: 43.75%] [G loss: 1.104953]\n",
      "187 [D loss: 0.321407, acc: 64.84%, op_acc: 38.28%] [G loss: 1.042981]\n",
      "188 [D loss: 0.312617, acc: 72.66%, op_acc: 43.75%] [G loss: 1.077401]\n",
      "189 [D loss: 0.287239, acc: 76.56%, op_acc: 45.31%] [G loss: 1.086213]\n",
      "190 [D loss: 0.318191, acc: 67.97%, op_acc: 40.62%] [G loss: 1.102275]\n",
      "Epoch: 190, F1: 0.00000, F1P: 19\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "70.9375\n",
      "191 [D loss: 0.287823, acc: 72.66%, op_acc: 33.59%] [G loss: 1.010010]\n",
      "192 [D loss: 0.299103, acc: 73.44%, op_acc: 36.72%] [G loss: 1.000885]\n",
      "193 [D loss: 0.298861, acc: 72.66%, op_acc: 50.78%] [G loss: 1.033689]\n",
      "194 [D loss: 0.299523, acc: 72.66%, op_acc: 40.62%] [G loss: 1.017385]\n",
      "195 [D loss: 0.299518, acc: 72.66%, op_acc: 43.75%] [G loss: 1.012811]\n",
      "196 [D loss: 0.296699, acc: 72.66%, op_acc: 40.62%] [G loss: 1.085452]\n",
      "197 [D loss: 0.307432, acc: 75.00%, op_acc: 38.28%] [G loss: 1.034146]\n",
      "198 [D loss: 0.317269, acc: 70.31%, op_acc: 45.31%] [G loss: 1.020125]\n",
      "199 [D loss: 0.305793, acc: 73.44%, op_acc: 47.66%] [G loss: 1.042288]\n",
      "200 [D loss: 0.344835, acc: 69.53%, op_acc: 41.41%] [G loss: 1.033631]\n",
      "Epoch: 200, F1: 0.00000, F1P: 20\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "72.5\n",
      "201 [D loss: 0.303177, acc: 71.88%, op_acc: 48.44%] [G loss: 1.077688]\n",
      "202 [D loss: 0.331452, acc: 71.09%, op_acc: 42.97%] [G loss: 1.074507]\n",
      "203 [D loss: 0.313339, acc: 71.09%, op_acc: 43.75%] [G loss: 1.055948]\n",
      "204 [D loss: 0.310410, acc: 67.97%, op_acc: 47.66%] [G loss: 1.052838]\n",
      "205 [D loss: 0.300557, acc: 77.34%, op_acc: 45.31%] [G loss: 1.093252]\n",
      "206 [D loss: 0.307978, acc: 75.00%, op_acc: 40.62%] [G loss: 1.036367]\n",
      "207 [D loss: 0.298133, acc: 74.22%, op_acc: 41.41%] [G loss: 1.077150]\n",
      "208 [D loss: 0.293276, acc: 76.56%, op_acc: 41.41%] [G loss: 1.012458]\n",
      "209 [D loss: 0.285016, acc: 81.25%, op_acc: 50.00%] [G loss: 1.121001]\n",
      "210 [D loss: 0.295890, acc: 74.22%, op_acc: 41.41%] [G loss: 1.006451]\n",
      "Epoch: 210, F1: 0.00000, F1P: 21\n",
      "[[28429     3]\n",
      " [   49     0]]\n",
      "74.0625\n",
      "211 [D loss: 0.299135, acc: 75.78%, op_acc: 48.44%] [G loss: 1.134943]\n",
      "212 [D loss: 0.306944, acc: 74.22%, op_acc: 44.53%] [G loss: 1.070477]\n",
      "213 [D loss: 0.306969, acc: 72.66%, op_acc: 37.50%] [G loss: 1.023729]\n",
      "214 [D loss: 0.292048, acc: 75.78%, op_acc: 39.84%] [G loss: 1.109500]\n",
      "215 [D loss: 0.295695, acc: 75.00%, op_acc: 42.97%] [G loss: 1.081762]\n",
      "216 [D loss: 0.298414, acc: 77.34%, op_acc: 49.22%] [G loss: 1.039369]\n",
      "217 [D loss: 0.315545, acc: 75.00%, op_acc: 43.75%] [G loss: 1.092831]\n",
      "218 [D loss: 0.300803, acc: 76.56%, op_acc: 51.56%] [G loss: 1.111460]\n",
      "219 [D loss: 0.301178, acc: 71.88%, op_acc: 47.66%] [G loss: 1.051965]\n",
      "220 [D loss: 0.301037, acc: 71.88%, op_acc: 42.97%] [G loss: 1.095058]\n",
      "Epoch: 220, F1: 0.00000, F1P: 22\n",
      "[[28429     3]\n",
      " [   49     0]]\n",
      "74.609375\n",
      "221 [D loss: 0.312945, acc: 70.31%, op_acc: 41.41%] [G loss: 1.114216]\n",
      "222 [D loss: 0.310161, acc: 71.09%, op_acc: 46.09%] [G loss: 1.119179]\n",
      "223 [D loss: 0.283830, acc: 81.25%, op_acc: 48.44%] [G loss: 1.038442]\n",
      "224 [D loss: 0.303731, acc: 72.66%, op_acc: 45.31%] [G loss: 1.070157]\n",
      "225 [D loss: 0.318325, acc: 72.66%, op_acc: 39.84%] [G loss: 1.078884]\n",
      "226 [D loss: 0.287308, acc: 79.69%, op_acc: 42.19%] [G loss: 0.991039]\n",
      "227 [D loss: 0.312972, acc: 68.75%, op_acc: 42.97%] [G loss: 1.016699]\n",
      "228 [D loss: 0.296722, acc: 78.12%, op_acc: 50.00%] [G loss: 1.012977]\n",
      "229 [D loss: 0.316783, acc: 67.19%, op_acc: 39.84%] [G loss: 1.064511]\n",
      "230 [D loss: 0.292527, acc: 78.91%, op_acc: 45.31%] [G loss: 1.056918]\n",
      "Epoch: 230, F1: 0.00000, F1P: 23\n",
      "[[28428     4]\n",
      " [   49     0]]\n",
      "74.0625\n",
      "231 [D loss: 0.316061, acc: 68.75%, op_acc: 40.62%] [G loss: 1.009877]\n",
      "232 [D loss: 0.313861, acc: 69.53%, op_acc: 45.31%] [G loss: 0.959954]\n",
      "233 [D loss: 0.285838, acc: 78.91%, op_acc: 51.56%] [G loss: 1.087385]\n",
      "234 [D loss: 0.284135, acc: 76.56%, op_acc: 40.62%] [G loss: 1.023288]\n",
      "235 [D loss: 0.302984, acc: 77.34%, op_acc: 45.31%] [G loss: 1.104268]\n",
      "236 [D loss: 0.289917, acc: 77.34%, op_acc: 48.44%] [G loss: 1.041414]\n",
      "237 [D loss: 0.295602, acc: 77.34%, op_acc: 39.84%] [G loss: 0.989583]\n",
      "238 [D loss: 0.287235, acc: 78.91%, op_acc: 48.44%] [G loss: 1.037120]\n",
      "239 [D loss: 0.301521, acc: 77.34%, op_acc: 37.50%] [G loss: 1.010582]\n",
      "240 [D loss: 0.291387, acc: 74.22%, op_acc: 49.22%] [G loss: 1.019917]\n",
      "Epoch: 240, F1: 0.00000, F1P: 24\n",
      "[[28428     4]\n",
      " [   49     0]]\n",
      "75.625\n",
      "241 [D loss: 0.305179, acc: 74.22%, op_acc: 43.75%] [G loss: 1.006282]\n",
      "242 [D loss: 0.293954, acc: 75.00%, op_acc: 44.53%] [G loss: 1.082366]\n",
      "243 [D loss: 0.288173, acc: 75.00%, op_acc: 44.53%] [G loss: 1.006082]\n",
      "244 [D loss: 0.306326, acc: 75.78%, op_acc: 45.31%] [G loss: 1.078740]\n",
      "245 [D loss: 0.304986, acc: 75.78%, op_acc: 42.97%] [G loss: 1.039147]\n",
      "246 [D loss: 0.283051, acc: 78.12%, op_acc: 46.88%] [G loss: 0.977244]\n",
      "247 [D loss: 0.308016, acc: 68.75%, op_acc: 44.53%] [G loss: 1.001222]\n",
      "248 [D loss: 0.291781, acc: 74.22%, op_acc: 43.75%] [G loss: 1.079561]\n",
      "249 [D loss: 0.285790, acc: 79.69%, op_acc: 43.75%] [G loss: 1.058910]\n",
      "250 [D loss: 0.304162, acc: 77.34%, op_acc: 46.88%] [G loss: 0.996897]\n",
      "Epoch: 250, F1: 0.00000, F1P: 25\n",
      "[[28428     4]\n",
      " [   49     0]]\n",
      "75.390625\n",
      "251 [D loss: 0.304326, acc: 72.66%, op_acc: 43.75%] [G loss: 1.073165]\n",
      "252 [D loss: 0.294954, acc: 75.78%, op_acc: 48.44%] [G loss: 1.081226]\n",
      "253 [D loss: 0.294205, acc: 80.47%, op_acc: 51.56%] [G loss: 1.055723]\n",
      "254 [D loss: 0.290535, acc: 77.34%, op_acc: 44.53%] [G loss: 1.068135]\n",
      "255 [D loss: 0.299079, acc: 73.44%, op_acc: 44.53%] [G loss: 1.090629]\n",
      "256 [D loss: 0.268583, acc: 84.38%, op_acc: 49.22%] [G loss: 1.037681]\n",
      "257 [D loss: 0.285288, acc: 76.56%, op_acc: 45.31%] [G loss: 1.004958]\n",
      "258 [D loss: 0.278732, acc: 81.25%, op_acc: 48.44%] [G loss: 1.010608]\n",
      "259 [D loss: 0.301563, acc: 72.66%, op_acc: 44.53%] [G loss: 1.022916]\n",
      "260 [D loss: 0.310050, acc: 74.22%, op_acc: 49.22%] [G loss: 1.079844]\n",
      "Epoch: 260, F1: 0.00000, F1P: 26\n",
      "[[28425     7]\n",
      " [   49     0]]\n",
      "76.875\n",
      "261 [D loss: 0.290200, acc: 78.91%, op_acc: 45.31%] [G loss: 1.045628]\n",
      "262 [D loss: 0.284034, acc: 76.56%, op_acc: 45.31%] [G loss: 1.063965]\n",
      "263 [D loss: 0.294519, acc: 75.00%, op_acc: 42.97%] [G loss: 1.065063]\n",
      "264 [D loss: 0.289850, acc: 74.22%, op_acc: 48.44%] [G loss: 1.090914]\n",
      "265 [D loss: 0.293168, acc: 73.44%, op_acc: 47.66%] [G loss: 1.053191]\n",
      "266 [D loss: 0.283690, acc: 81.25%, op_acc: 45.31%] [G loss: 1.029579]\n",
      "267 [D loss: 0.278032, acc: 80.47%, op_acc: 49.22%] [G loss: 1.020819]\n",
      "268 [D loss: 0.295830, acc: 74.22%, op_acc: 43.75%] [G loss: 1.067459]\n",
      "269 [D loss: 0.289299, acc: 76.56%, op_acc: 41.41%] [G loss: 1.001461]\n",
      "270 [D loss: 0.288094, acc: 75.78%, op_acc: 52.34%] [G loss: 1.083634]\n",
      "Epoch: 270, F1: 0.00000, F1P: 27\n",
      "[[28420    12]\n",
      " [   49     0]]\n",
      "76.640625\n",
      "271 [D loss: 0.281341, acc: 81.25%, op_acc: 43.75%] [G loss: 1.044859]\n",
      "272 [D loss: 0.281190, acc: 81.25%, op_acc: 46.09%] [G loss: 1.066814]\n",
      "273 [D loss: 0.283192, acc: 78.91%, op_acc: 48.44%] [G loss: 1.099584]\n",
      "274 [D loss: 0.277252, acc: 81.25%, op_acc: 46.09%] [G loss: 1.089840]\n",
      "275 [D loss: 0.289877, acc: 76.56%, op_acc: 43.75%] [G loss: 1.107396]\n",
      "276 [D loss: 0.295996, acc: 76.56%, op_acc: 41.41%] [G loss: 1.013628]\n",
      "277 [D loss: 0.294479, acc: 76.56%, op_acc: 43.75%] [G loss: 1.067586]\n",
      "278 [D loss: 0.279322, acc: 81.25%, op_acc: 47.66%] [G loss: 1.037618]\n",
      "279 [D loss: 0.275658, acc: 85.16%, op_acc: 46.88%] [G loss: 1.051912]\n",
      "280 [D loss: 0.309915, acc: 70.31%, op_acc: 42.97%] [G loss: 1.073953]\n",
      "Epoch: 280, F1: 0.00000, F1P: 28\n",
      "[[28402    30]\n",
      " [   49     0]]\n",
      "78.90625\n",
      "281 [D loss: 0.273557, acc: 81.25%, op_acc: 42.97%] [G loss: 1.023663]\n",
      "282 [D loss: 0.288859, acc: 75.00%, op_acc: 47.66%] [G loss: 1.045738]\n",
      "283 [D loss: 0.286593, acc: 79.69%, op_acc: 50.00%] [G loss: 1.081074]\n",
      "284 [D loss: 0.287622, acc: 77.34%, op_acc: 46.09%] [G loss: 1.085389]\n",
      "285 [D loss: 0.286251, acc: 84.38%, op_acc: 53.12%] [G loss: 1.074647]\n",
      "286 [D loss: 0.280709, acc: 82.03%, op_acc: 47.66%] [G loss: 1.001937]\n",
      "287 [D loss: 0.277012, acc: 78.12%, op_acc: 47.66%] [G loss: 1.019347]\n",
      "288 [D loss: 0.281213, acc: 75.78%, op_acc: 46.88%] [G loss: 1.066811]\n",
      "289 [D loss: 0.303115, acc: 74.22%, op_acc: 42.97%] [G loss: 1.037114]\n",
      "290 [D loss: 0.277243, acc: 78.91%, op_acc: 53.91%] [G loss: 1.010656]\n",
      "Epoch: 290, F1: 0.03419, F1P: 29\n",
      "[[28366    66]\n",
      " [   47     2]]\n",
      "78.671875\n",
      "291 [D loss: 0.280152, acc: 79.69%, op_acc: 50.78%] [G loss: 1.018979]\n",
      "292 [D loss: 0.285383, acc: 77.34%, op_acc: 51.56%] [G loss: 1.019834]\n",
      "293 [D loss: 0.283689, acc: 75.78%, op_acc: 45.31%] [G loss: 1.025271]\n",
      "294 [D loss: 0.280979, acc: 76.56%, op_acc: 47.66%] [G loss: 1.067291]\n",
      "295 [D loss: 0.289832, acc: 75.00%, op_acc: 44.53%] [G loss: 1.086660]\n",
      "296 [D loss: 0.285392, acc: 80.47%, op_acc: 49.22%] [G loss: 1.048267]\n",
      "297 [D loss: 0.278505, acc: 79.69%, op_acc: 47.66%] [G loss: 1.012105]\n",
      "298 [D loss: 0.283625, acc: 77.34%, op_acc: 45.31%] [G loss: 1.042806]\n",
      "299 [D loss: 0.290423, acc: 75.00%, op_acc: 46.88%] [G loss: 1.013333]\n",
      "300 [D loss: 0.287652, acc: 73.44%, op_acc: 44.53%] [G loss: 1.051287]\n",
      "Epoch: 300, F1: 0.05622, F1P: 30\n",
      "[[28239   193]\n",
      " [   42     7]]\n",
      "77.03125\n",
      "301 [D loss: 0.301504, acc: 73.44%, op_acc: 41.41%] [G loss: 1.047770]\n",
      "302 [D loss: 0.275294, acc: 82.81%, op_acc: 46.09%] [G loss: 0.999776]\n",
      "303 [D loss: 0.307225, acc: 72.66%, op_acc: 47.66%] [G loss: 0.967399]\n",
      "304 [D loss: 0.301945, acc: 78.91%, op_acc: 51.56%] [G loss: 1.045315]\n",
      "305 [D loss: 0.279969, acc: 80.47%, op_acc: 47.66%] [G loss: 1.053004]\n",
      "306 [D loss: 0.290430, acc: 76.56%, op_acc: 42.19%] [G loss: 1.024447]\n",
      "307 [D loss: 0.270659, acc: 85.16%, op_acc: 45.31%] [G loss: 1.034182]\n",
      "308 [D loss: 0.283514, acc: 76.56%, op_acc: 49.22%] [G loss: 1.058418]\n",
      "309 [D loss: 0.285189, acc: 77.34%, op_acc: 44.53%] [G loss: 1.018678]\n",
      "310 [D loss: 0.291624, acc: 81.25%, op_acc: 50.78%] [G loss: 0.967980]\n",
      "Epoch: 310, F1: 0.06235, F1P: 31\n",
      "[[28077   355]\n",
      " [   36    13]]\n",
      "78.515625\n",
      "311 [D loss: 0.286397, acc: 76.56%, op_acc: 46.88%] [G loss: 1.005998]\n",
      "312 [D loss: 0.300226, acc: 71.09%, op_acc: 37.50%] [G loss: 1.002959]\n",
      "313 [D loss: 0.292145, acc: 75.00%, op_acc: 49.22%] [G loss: 0.979947]\n",
      "314 [D loss: 0.285011, acc: 76.56%, op_acc: 42.97%] [G loss: 1.049694]\n",
      "315 [D loss: 0.309803, acc: 75.78%, op_acc: 50.00%] [G loss: 1.020949]\n",
      "316 [D loss: 0.311610, acc: 71.88%, op_acc: 42.19%] [G loss: 0.997728]\n",
      "317 [D loss: 0.278121, acc: 79.69%, op_acc: 48.44%] [G loss: 1.061735]\n",
      "318 [D loss: 0.279739, acc: 78.12%, op_acc: 51.56%] [G loss: 1.010799]\n",
      "319 [D loss: 0.283132, acc: 80.47%, op_acc: 57.81%] [G loss: 0.951563]\n",
      "320 [D loss: 0.283640, acc: 78.12%, op_acc: 46.09%] [G loss: 1.069768]\n",
      "Epoch: 320, F1: 0.07477, F1P: 32\n",
      "[[28069   363]\n",
      " [   33    16]]\n",
      "76.328125\n",
      "321 [D loss: 0.286558, acc: 78.91%, op_acc: 41.41%] [G loss: 1.039026]\n",
      "322 [D loss: 0.289326, acc: 77.34%, op_acc: 47.66%] [G loss: 1.014290]\n",
      "323 [D loss: 0.293932, acc: 75.78%, op_acc: 55.47%] [G loss: 0.957869]\n",
      "324 [D loss: 0.295113, acc: 80.47%, op_acc: 46.88%] [G loss: 1.051357]\n",
      "325 [D loss: 0.298175, acc: 72.66%, op_acc: 46.09%] [G loss: 1.010809]\n",
      "326 [D loss: 0.294886, acc: 73.44%, op_acc: 47.66%] [G loss: 1.047117]\n",
      "327 [D loss: 0.298882, acc: 75.00%, op_acc: 42.97%] [G loss: 1.021094]\n",
      "328 [D loss: 0.289326, acc: 76.56%, op_acc: 50.78%] [G loss: 0.992383]\n",
      "329 [D loss: 0.296080, acc: 75.78%, op_acc: 46.88%] [G loss: 1.016373]\n",
      "330 [D loss: 0.287016, acc: 78.91%, op_acc: 53.12%] [G loss: 1.081496]\n",
      "Epoch: 330, F1: 0.08054, F1P: 33\n",
      "[[28052   380]\n",
      " [   31    18]]\n",
      "76.484375\n",
      "331 [D loss: 0.290858, acc: 76.56%, op_acc: 50.00%] [G loss: 1.038808]\n",
      "332 [D loss: 0.297195, acc: 75.78%, op_acc: 46.09%] [G loss: 0.974377]\n",
      "333 [D loss: 0.288815, acc: 78.91%, op_acc: 50.78%] [G loss: 1.074218]\n",
      "334 [D loss: 0.281568, acc: 79.69%, op_acc: 50.00%] [G loss: 1.042318]\n",
      "335 [D loss: 0.289973, acc: 78.91%, op_acc: 46.09%] [G loss: 1.017800]\n",
      "336 [D loss: 0.303518, acc: 70.31%, op_acc: 46.88%] [G loss: 1.065184]\n",
      "337 [D loss: 0.285534, acc: 75.78%, op_acc: 46.88%] [G loss: 0.954409]\n",
      "338 [D loss: 0.305247, acc: 78.12%, op_acc: 53.91%] [G loss: 0.972545]\n",
      "339 [D loss: 0.295563, acc: 77.34%, op_acc: 46.09%] [G loss: 1.037031]\n",
      "340 [D loss: 0.293026, acc: 74.22%, op_acc: 52.34%] [G loss: 0.948491]\n",
      "Epoch: 340, F1: 0.08230, F1P: 34\n",
      "[[28015   417]\n",
      " [   29    20]]\n",
      "76.5625\n",
      "341 [D loss: 0.291742, acc: 73.44%, op_acc: 46.88%] [G loss: 1.040173]\n",
      "342 [D loss: 0.303987, acc: 75.00%, op_acc: 49.22%] [G loss: 1.000999]\n",
      "343 [D loss: 0.284188, acc: 79.69%, op_acc: 54.69%] [G loss: 0.974784]\n",
      "344 [D loss: 0.290134, acc: 73.44%, op_acc: 51.56%] [G loss: 0.950770]\n",
      "345 [D loss: 0.296387, acc: 76.56%, op_acc: 53.12%] [G loss: 0.998704]\n",
      "346 [D loss: 0.299974, acc: 71.09%, op_acc: 45.31%] [G loss: 1.034411]\n",
      "347 [D loss: 0.307294, acc: 71.09%, op_acc: 50.00%] [G loss: 1.025283]\n",
      "348 [D loss: 0.272528, acc: 77.34%, op_acc: 48.44%] [G loss: 1.063231]\n",
      "349 [D loss: 0.288518, acc: 76.56%, op_acc: 48.44%] [G loss: 0.942679]\n",
      "350 [D loss: 0.288324, acc: 75.00%, op_acc: 50.78%] [G loss: 1.023866]\n",
      "Epoch: 350, F1: 0.12209, F1P: 35\n",
      "[[28158   274]\n",
      " [   28    21]]\n",
      "74.921875\n",
      "351 [D loss: 0.291585, acc: 73.44%, op_acc: 42.97%] [G loss: 1.030614]\n",
      "352 [D loss: 0.288321, acc: 75.78%, op_acc: 51.56%] [G loss: 0.989252]\n",
      "353 [D loss: 0.300958, acc: 75.78%, op_acc: 50.78%] [G loss: 0.984297]\n",
      "354 [D loss: 0.291534, acc: 80.47%, op_acc: 49.22%] [G loss: 1.033430]\n",
      "355 [D loss: 0.303434, acc: 71.88%, op_acc: 51.56%] [G loss: 1.082966]\n",
      "356 [D loss: 0.295527, acc: 72.66%, op_acc: 52.34%] [G loss: 0.982366]\n",
      "357 [D loss: 0.296951, acc: 75.78%, op_acc: 48.44%] [G loss: 0.921250]\n",
      "358 [D loss: 0.285006, acc: 75.00%, op_acc: 51.56%] [G loss: 1.026716]\n",
      "359 [D loss: 0.298977, acc: 76.56%, op_acc: 50.00%] [G loss: 1.003053]\n",
      "360 [D loss: 0.287396, acc: 75.78%, op_acc: 45.31%] [G loss: 0.966817]\n",
      "Epoch: 360, F1: 0.17671, F1P: 36\n",
      "[[28254   178]\n",
      " [   27    22]]\n",
      "75.3125\n",
      "361 [D loss: 0.303560, acc: 73.44%, op_acc: 51.56%] [G loss: 1.025420]\n",
      "362 [D loss: 0.298674, acc: 73.44%, op_acc: 57.81%] [G loss: 1.003988]\n",
      "363 [D loss: 0.307818, acc: 74.22%, op_acc: 50.78%] [G loss: 0.978697]\n",
      "364 [D loss: 0.292399, acc: 74.22%, op_acc: 53.12%] [G loss: 0.981370]\n",
      "365 [D loss: 0.308964, acc: 67.19%, op_acc: 49.22%] [G loss: 0.909341]\n",
      "366 [D loss: 0.296504, acc: 78.91%, op_acc: 49.22%] [G loss: 1.000661]\n",
      "367 [D loss: 0.293946, acc: 73.44%, op_acc: 48.44%] [G loss: 0.967885]\n",
      "368 [D loss: 0.295555, acc: 72.66%, op_acc: 50.78%] [G loss: 0.961604]\n",
      "369 [D loss: 0.300777, acc: 73.44%, op_acc: 50.00%] [G loss: 0.965799]\n",
      "370 [D loss: 0.299516, acc: 71.88%, op_acc: 46.88%] [G loss: 0.992800]\n",
      "Epoch: 370, F1: 0.21154, F1P: 37\n",
      "[[28295   137]\n",
      " [   27    22]]\n",
      "73.28125\n",
      "371 [D loss: 0.298585, acc: 74.22%, op_acc: 47.66%] [G loss: 1.043403]\n",
      "372 [D loss: 0.297963, acc: 77.34%, op_acc: 49.22%] [G loss: 0.943220]\n",
      "373 [D loss: 0.291432, acc: 74.22%, op_acc: 50.78%] [G loss: 0.987669]\n",
      "374 [D loss: 0.286912, acc: 75.00%, op_acc: 50.78%] [G loss: 0.990949]\n",
      "375 [D loss: 0.301561, acc: 71.88%, op_acc: 53.12%] [G loss: 0.988384]\n",
      "376 [D loss: 0.293216, acc: 76.56%, op_acc: 49.22%] [G loss: 1.047414]\n",
      "377 [D loss: 0.295976, acc: 73.44%, op_acc: 52.34%] [G loss: 1.009882]\n",
      "378 [D loss: 0.300820, acc: 73.44%, op_acc: 45.31%] [G loss: 0.906304]\n",
      "379 [D loss: 0.295257, acc: 75.78%, op_acc: 47.66%] [G loss: 1.010941]\n",
      "380 [D loss: 0.289521, acc: 76.56%, op_acc: 49.22%] [G loss: 0.930714]\n",
      "Epoch: 380, F1: 0.25263, F1P: 38\n",
      "[[28315   117]\n",
      " [   25    24]]\n",
      "74.84375\n",
      "381 [D loss: 0.289933, acc: 75.78%, op_acc: 57.03%] [G loss: 0.984287]\n",
      "382 [D loss: 0.291572, acc: 71.09%, op_acc: 50.78%] [G loss: 1.058026]\n",
      "383 [D loss: 0.292662, acc: 78.91%, op_acc: 47.66%] [G loss: 1.048737]\n",
      "384 [D loss: 0.281657, acc: 74.22%, op_acc: 50.78%] [G loss: 1.024025]\n",
      "385 [D loss: 0.295254, acc: 76.56%, op_acc: 46.88%] [G loss: 1.005587]\n",
      "386 [D loss: 0.303085, acc: 76.56%, op_acc: 54.69%] [G loss: 1.057288]\n",
      "387 [D loss: 0.268768, acc: 84.38%, op_acc: 60.94%] [G loss: 1.007934]\n",
      "388 [D loss: 0.298367, acc: 73.44%, op_acc: 53.91%] [G loss: 0.976399]\n",
      "389 [D loss: 0.298160, acc: 78.12%, op_acc: 54.69%] [G loss: 0.981041]\n",
      "390 [D loss: 0.293735, acc: 73.44%, op_acc: 55.47%] [G loss: 0.972497]\n",
      "Epoch: 390, F1: 0.40678, F1P: 39\n",
      "[[28387    45]\n",
      " [   25    24]]\n",
      "76.25\n",
      "391 [D loss: 0.288169, acc: 77.34%, op_acc: 55.47%] [G loss: 1.060541]\n",
      "392 [D loss: 0.284624, acc: 74.22%, op_acc: 55.47%] [G loss: 1.022462]\n",
      "393 [D loss: 0.289526, acc: 73.44%, op_acc: 50.00%] [G loss: 1.064720]\n",
      "394 [D loss: 0.305468, acc: 73.44%, op_acc: 57.03%] [G loss: 0.999255]\n",
      "395 [D loss: 0.303835, acc: 70.31%, op_acc: 50.00%] [G loss: 0.968011]\n",
      "396 [D loss: 0.292348, acc: 77.34%, op_acc: 50.78%] [G loss: 0.962651]\n",
      "397 [D loss: 0.313811, acc: 69.53%, op_acc: 48.44%] [G loss: 0.990630]\n",
      "398 [D loss: 0.287888, acc: 75.78%, op_acc: 50.78%] [G loss: 0.974864]\n",
      "399 [D loss: 0.295411, acc: 79.69%, op_acc: 53.12%] [G loss: 0.962070]\n",
      "400 [D loss: 0.298547, acc: 77.34%, op_acc: 55.47%] [G loss: 0.984180]\n",
      "Epoch: 400, F1: 0.57143, F1P: 40\n",
      "[[28406    26]\n",
      " [   19    30]]\n",
      "74.84375\n",
      "401 [D loss: 0.280211, acc: 81.25%, op_acc: 55.47%] [G loss: 1.009140]\n",
      "402 [D loss: 0.295800, acc: 78.91%, op_acc: 53.12%] [G loss: 1.020890]\n",
      "403 [D loss: 0.283638, acc: 81.25%, op_acc: 51.56%] [G loss: 1.015657]\n",
      "404 [D loss: 0.303106, acc: 74.22%, op_acc: 52.34%] [G loss: 0.992106]\n",
      "405 [D loss: 0.290250, acc: 74.22%, op_acc: 54.69%] [G loss: 1.020924]\n",
      "406 [D loss: 0.281368, acc: 79.69%, op_acc: 48.44%] [G loss: 0.935040]\n",
      "407 [D loss: 0.278284, acc: 81.25%, op_acc: 48.44%] [G loss: 0.991084]\n",
      "408 [D loss: 0.281533, acc: 76.56%, op_acc: 59.38%] [G loss: 1.010052]\n",
      "409 [D loss: 0.306508, acc: 75.78%, op_acc: 53.91%] [G loss: 1.015014]\n",
      "410 [D loss: 0.290418, acc: 77.34%, op_acc: 59.38%] [G loss: 0.989653]\n",
      "Epoch: 410, F1: 0.62222, F1P: 41\n",
      "[[28419    13]\n",
      " [   21    28]]\n",
      "78.046875\n",
      "411 [D loss: 0.313742, acc: 65.62%, op_acc: 50.00%] [G loss: 1.011298]\n",
      "412 [D loss: 0.279398, acc: 79.69%, op_acc: 57.03%] [G loss: 1.049956]\n",
      "413 [D loss: 0.301019, acc: 74.22%, op_acc: 51.56%] [G loss: 1.000988]\n",
      "414 [D loss: 0.279692, acc: 78.12%, op_acc: 50.78%] [G loss: 0.948167]\n",
      "415 [D loss: 0.303538, acc: 77.34%, op_acc: 53.12%] [G loss: 1.022760]\n",
      "416 [D loss: 0.310735, acc: 68.75%, op_acc: 52.34%] [G loss: 1.013795]\n",
      "417 [D loss: 0.302423, acc: 71.88%, op_acc: 42.97%] [G loss: 0.968559]\n",
      "418 [D loss: 0.292512, acc: 71.88%, op_acc: 54.69%] [G loss: 1.001762]\n",
      "419 [D loss: 0.293278, acc: 73.44%, op_acc: 53.91%] [G loss: 0.964823]\n",
      "420 [D loss: 0.287149, acc: 71.09%, op_acc: 53.91%] [G loss: 0.925542]\n",
      "Epoch: 420, F1: 0.65116, F1P: 42\n",
      "[[28423     9]\n",
      " [   21    28]]\n",
      "73.203125\n",
      "421 [D loss: 0.292041, acc: 74.22%, op_acc: 53.91%] [G loss: 1.035490]\n",
      "422 [D loss: 0.289598, acc: 78.91%, op_acc: 53.91%] [G loss: 1.041711]\n",
      "423 [D loss: 0.316387, acc: 73.44%, op_acc: 53.91%] [G loss: 0.984991]\n",
      "424 [D loss: 0.275690, acc: 80.47%, op_acc: 55.47%] [G loss: 0.959305]\n",
      "425 [D loss: 0.300282, acc: 75.00%, op_acc: 55.47%] [G loss: 1.030724]\n",
      "426 [D loss: 0.310548, acc: 68.75%, op_acc: 50.00%] [G loss: 1.049741]\n",
      "427 [D loss: 0.293234, acc: 69.53%, op_acc: 49.22%] [G loss: 0.992649]\n",
      "428 [D loss: 0.283871, acc: 78.12%, op_acc: 53.12%] [G loss: 1.003359]\n",
      "429 [D loss: 0.288058, acc: 75.78%, op_acc: 49.22%] [G loss: 1.075199]\n",
      "430 [D loss: 0.281766, acc: 80.47%, op_acc: 54.69%] [G loss: 1.008534]\n",
      "Epoch: 430, F1: 0.65882, F1P: 43\n",
      "[[28424     8]\n",
      " [   21    28]]\n",
      "75.46875\n",
      "431 [D loss: 0.297334, acc: 78.91%, op_acc: 53.91%] [G loss: 0.988351]\n",
      "432 [D loss: 0.258162, acc: 85.16%, op_acc: 51.56%] [G loss: 1.011634]\n",
      "433 [D loss: 0.308480, acc: 69.53%, op_acc: 56.25%] [G loss: 1.042905]\n",
      "434 [D loss: 0.307975, acc: 69.53%, op_acc: 52.34%] [G loss: 0.979243]\n",
      "435 [D loss: 0.295667, acc: 73.44%, op_acc: 58.59%] [G loss: 1.071207]\n",
      "436 [D loss: 0.287668, acc: 80.47%, op_acc: 53.91%] [G loss: 0.987615]\n",
      "437 [D loss: 0.279573, acc: 80.47%, op_acc: 51.56%] [G loss: 1.059166]\n",
      "438 [D loss: 0.292238, acc: 77.34%, op_acc: 54.69%] [G loss: 0.968355]\n",
      "439 [D loss: 0.311576, acc: 67.19%, op_acc: 49.22%] [G loss: 1.017389]\n",
      "440 [D loss: 0.290439, acc: 74.22%, op_acc: 55.47%] [G loss: 1.024575]\n",
      "Epoch: 440, F1: 0.64286, F1P: 44\n",
      "[[28424     8]\n",
      " [   22    27]]\n",
      "75.625\n",
      "441 [D loss: 0.279977, acc: 82.81%, op_acc: 56.25%] [G loss: 1.057366]\n",
      "442 [D loss: 0.293426, acc: 75.00%, op_acc: 56.25%] [G loss: 1.025497]\n",
      "443 [D loss: 0.289608, acc: 77.34%, op_acc: 55.47%] [G loss: 1.049134]\n",
      "444 [D loss: 0.285976, acc: 75.00%, op_acc: 53.12%] [G loss: 0.994979]\n",
      "445 [D loss: 0.308375, acc: 74.22%, op_acc: 50.78%] [G loss: 0.971095]\n",
      "446 [D loss: 0.289459, acc: 78.12%, op_acc: 49.22%] [G loss: 1.010948]\n",
      "447 [D loss: 0.287930, acc: 75.78%, op_acc: 50.00%] [G loss: 1.061123]\n",
      "448 [D loss: 0.291194, acc: 78.12%, op_acc: 48.44%] [G loss: 1.040572]\n",
      "449 [D loss: 0.295430, acc: 74.22%, op_acc: 53.12%] [G loss: 1.053652]\n",
      "450 [D loss: 0.287041, acc: 80.47%, op_acc: 51.56%] [G loss: 1.023210]\n",
      "Epoch: 450, F1: 0.65060, F1P: 45\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "77.109375\n",
      "451 [D loss: 0.294376, acc: 78.12%, op_acc: 46.88%] [G loss: 1.030030]\n",
      "452 [D loss: 0.304117, acc: 75.78%, op_acc: 50.00%] [G loss: 0.997036]\n",
      "453 [D loss: 0.286083, acc: 77.34%, op_acc: 55.47%] [G loss: 0.972653]\n",
      "454 [D loss: 0.294399, acc: 73.44%, op_acc: 49.22%] [G loss: 1.035772]\n",
      "455 [D loss: 0.292166, acc: 74.22%, op_acc: 53.91%] [G loss: 0.997756]\n",
      "456 [D loss: 0.275647, acc: 78.91%, op_acc: 55.47%] [G loss: 1.031375]\n",
      "457 [D loss: 0.287324, acc: 77.34%, op_acc: 59.38%] [G loss: 1.034384]\n",
      "458 [D loss: 0.294418, acc: 69.53%, op_acc: 57.03%] [G loss: 1.035501]\n",
      "459 [D loss: 0.288307, acc: 78.12%, op_acc: 51.56%] [G loss: 0.995620]\n",
      "460 [D loss: 0.299112, acc: 67.97%, op_acc: 49.22%] [G loss: 1.016900]\n",
      "Epoch: 460, F1: 0.66667, F1P: 46\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "75.078125\n",
      "461 [D loss: 0.299409, acc: 72.66%, op_acc: 52.34%] [G loss: 1.038369]\n",
      "462 [D loss: 0.282615, acc: 76.56%, op_acc: 50.78%] [G loss: 1.036437]\n",
      "463 [D loss: 0.274781, acc: 77.34%, op_acc: 53.91%] [G loss: 1.024099]\n",
      "464 [D loss: 0.284724, acc: 78.91%, op_acc: 53.91%] [G loss: 1.010119]\n",
      "465 [D loss: 0.296202, acc: 75.78%, op_acc: 52.34%] [G loss: 1.029073]\n",
      "466 [D loss: 0.285914, acc: 80.47%, op_acc: 55.47%] [G loss: 1.083373]\n",
      "467 [D loss: 0.297869, acc: 75.78%, op_acc: 55.47%] [G loss: 1.088466]\n",
      "468 [D loss: 0.308017, acc: 69.53%, op_acc: 52.34%] [G loss: 1.066545]\n",
      "469 [D loss: 0.284016, acc: 75.78%, op_acc: 54.69%] [G loss: 1.050313]\n",
      "470 [D loss: 0.285342, acc: 82.03%, op_acc: 57.03%] [G loss: 1.062944]\n",
      "Epoch: 470, F1: 0.66667, F1P: 47\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "76.484375\n",
      "471 [D loss: 0.283088, acc: 77.34%, op_acc: 54.69%] [G loss: 1.014290]\n",
      "472 [D loss: 0.296390, acc: 75.78%, op_acc: 55.47%] [G loss: 1.018852]\n",
      "473 [D loss: 0.289554, acc: 78.12%, op_acc: 54.69%] [G loss: 1.084979]\n",
      "474 [D loss: 0.278543, acc: 81.25%, op_acc: 60.16%] [G loss: 1.099067]\n",
      "475 [D loss: 0.296542, acc: 75.78%, op_acc: 58.59%] [G loss: 1.020139]\n",
      "476 [D loss: 0.293558, acc: 78.91%, op_acc: 57.81%] [G loss: 1.029538]\n",
      "477 [D loss: 0.296535, acc: 75.00%, op_acc: 56.25%] [G loss: 1.055417]\n",
      "478 [D loss: 0.294797, acc: 72.66%, op_acc: 48.44%] [G loss: 1.103652]\n",
      "479 [D loss: 0.292463, acc: 80.47%, op_acc: 61.72%] [G loss: 1.026136]\n",
      "480 [D loss: 0.283829, acc: 74.22%, op_acc: 59.38%] [G loss: 1.061972]\n",
      "Epoch: 480, F1: 0.65854, F1P: 48\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "76.953125\n",
      "481 [D loss: 0.299708, acc: 73.44%, op_acc: 57.81%] [G loss: 1.058730]\n",
      "482 [D loss: 0.283254, acc: 74.22%, op_acc: 52.34%] [G loss: 1.069211]\n",
      "483 [D loss: 0.281404, acc: 78.12%, op_acc: 58.59%] [G loss: 1.054685]\n",
      "484 [D loss: 0.287696, acc: 77.34%, op_acc: 53.12%] [G loss: 1.115961]\n",
      "485 [D loss: 0.293310, acc: 70.31%, op_acc: 52.34%] [G loss: 1.021186]\n",
      "486 [D loss: 0.286618, acc: 74.22%, op_acc: 51.56%] [G loss: 1.062073]\n",
      "487 [D loss: 0.292397, acc: 75.78%, op_acc: 53.91%] [G loss: 1.044301]\n",
      "488 [D loss: 0.295618, acc: 73.44%, op_acc: 53.91%] [G loss: 1.035751]\n",
      "489 [D loss: 0.274670, acc: 79.69%, op_acc: 52.34%] [G loss: 1.058195]\n",
      "490 [D loss: 0.298571, acc: 73.44%, op_acc: 60.94%] [G loss: 1.012445]\n",
      "Epoch: 490, F1: 0.65854, F1P: 49\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "75.0\n",
      "491 [D loss: 0.280741, acc: 79.69%, op_acc: 59.38%] [G loss: 1.128478]\n",
      "492 [D loss: 0.300709, acc: 74.22%, op_acc: 55.47%] [G loss: 0.997179]\n",
      "493 [D loss: 0.289632, acc: 75.78%, op_acc: 54.69%] [G loss: 1.055169]\n",
      "494 [D loss: 0.286804, acc: 78.91%, op_acc: 48.44%] [G loss: 1.068012]\n",
      "495 [D loss: 0.292421, acc: 78.12%, op_acc: 50.78%] [G loss: 1.026295]\n",
      "496 [D loss: 0.287995, acc: 77.34%, op_acc: 53.91%] [G loss: 1.040205]\n",
      "497 [D loss: 0.297051, acc: 73.44%, op_acc: 44.53%] [G loss: 1.044304]\n",
      "498 [D loss: 0.294774, acc: 75.78%, op_acc: 55.47%] [G loss: 1.078100]\n",
      "499 [D loss: 0.292517, acc: 75.00%, op_acc: 56.25%] [G loss: 1.043197]\n",
      "500 [D loss: 0.262230, acc: 85.16%, op_acc: 60.16%] [G loss: 1.042917]\n",
      "Epoch: 500, F1: 0.66667, F1P: 50\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "77.34375\n",
      "501 [D loss: 0.293107, acc: 76.56%, op_acc: 49.22%] [G loss: 1.106908]\n",
      "502 [D loss: 0.288646, acc: 71.88%, op_acc: 49.22%] [G loss: 1.058310]\n",
      "503 [D loss: 0.283365, acc: 75.00%, op_acc: 54.69%] [G loss: 1.066728]\n",
      "504 [D loss: 0.285878, acc: 72.66%, op_acc: 51.56%] [G loss: 1.081573]\n",
      "505 [D loss: 0.279635, acc: 82.81%, op_acc: 58.59%] [G loss: 1.022120]\n",
      "506 [D loss: 0.286179, acc: 75.78%, op_acc: 54.69%] [G loss: 1.092352]\n",
      "507 [D loss: 0.292559, acc: 71.88%, op_acc: 56.25%] [G loss: 1.077786]\n",
      "508 [D loss: 0.290125, acc: 74.22%, op_acc: 55.47%] [G loss: 1.056384]\n",
      "509 [D loss: 0.293486, acc: 74.22%, op_acc: 48.44%] [G loss: 1.131999]\n",
      "510 [D loss: 0.297494, acc: 74.22%, op_acc: 52.34%] [G loss: 1.000967]\n",
      "Epoch: 510, F1: 0.67470, F1P: 51\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "74.921875\n",
      "511 [D loss: 0.289124, acc: 77.34%, op_acc: 55.47%] [G loss: 1.044155]\n",
      "512 [D loss: 0.302480, acc: 75.78%, op_acc: 51.56%] [G loss: 1.052141]\n",
      "513 [D loss: 0.278599, acc: 79.69%, op_acc: 64.06%] [G loss: 1.045653]\n",
      "514 [D loss: 0.293710, acc: 71.09%, op_acc: 53.91%] [G loss: 1.056300]\n",
      "515 [D loss: 0.278802, acc: 79.69%, op_acc: 57.03%] [G loss: 1.030740]\n",
      "516 [D loss: 0.280203, acc: 75.00%, op_acc: 56.25%] [G loss: 1.157391]\n",
      "517 [D loss: 0.305414, acc: 71.88%, op_acc: 54.69%] [G loss: 1.059672]\n",
      "518 [D loss: 0.291389, acc: 78.91%, op_acc: 57.03%] [G loss: 1.083401]\n",
      "519 [D loss: 0.283132, acc: 79.69%, op_acc: 59.38%] [G loss: 1.099325]\n",
      "520 [D loss: 0.277805, acc: 75.78%, op_acc: 57.81%] [G loss: 1.132383]\n",
      "Epoch: 520, F1: 0.62500, F1P: 52\n",
      "[[28426     6]\n",
      " [   24    25]]\n",
      "76.484375\n",
      "521 [D loss: 0.269304, acc: 80.47%, op_acc: 57.03%] [G loss: 1.056883]\n",
      "522 [D loss: 0.282467, acc: 80.47%, op_acc: 55.47%] [G loss: 1.127481]\n",
      "523 [D loss: 0.291291, acc: 71.88%, op_acc: 53.91%] [G loss: 1.078343]\n",
      "524 [D loss: 0.300568, acc: 74.22%, op_acc: 58.59%] [G loss: 1.039858]\n",
      "525 [D loss: 0.278600, acc: 78.91%, op_acc: 57.81%] [G loss: 1.058552]\n",
      "526 [D loss: 0.280378, acc: 78.12%, op_acc: 59.38%] [G loss: 1.014135]\n",
      "527 [D loss: 0.286340, acc: 81.25%, op_acc: 56.25%] [G loss: 1.041206]\n",
      "528 [D loss: 0.283152, acc: 72.66%, op_acc: 53.12%] [G loss: 1.166793]\n",
      "529 [D loss: 0.286703, acc: 73.44%, op_acc: 52.34%] [G loss: 1.085623]\n",
      "530 [D loss: 0.289358, acc: 77.34%, op_acc: 58.59%] [G loss: 1.036334]\n",
      "Epoch: 530, F1: 0.62500, F1P: 53\n",
      "[[28426     6]\n",
      " [   24    25]]\n",
      "76.875\n",
      "531 [D loss: 0.279218, acc: 76.56%, op_acc: 57.81%] [G loss: 1.096701]\n",
      "532 [D loss: 0.295542, acc: 73.44%, op_acc: 50.78%] [G loss: 1.110932]\n",
      "533 [D loss: 0.286614, acc: 75.78%, op_acc: 57.81%] [G loss: 1.031263]\n",
      "534 [D loss: 0.289612, acc: 77.34%, op_acc: 54.69%] [G loss: 1.030915]\n",
      "535 [D loss: 0.291121, acc: 80.47%, op_acc: 56.25%] [G loss: 1.067094]\n",
      "536 [D loss: 0.302188, acc: 71.88%, op_acc: 51.56%] [G loss: 1.045537]\n",
      "537 [D loss: 0.278604, acc: 78.12%, op_acc: 53.12%] [G loss: 1.090013]\n",
      "538 [D loss: 0.281465, acc: 78.12%, op_acc: 56.25%] [G loss: 1.093025]\n",
      "539 [D loss: 0.286642, acc: 72.66%, op_acc: 52.34%] [G loss: 1.049215]\n",
      "540 [D loss: 0.306019, acc: 70.31%, op_acc: 51.56%] [G loss: 1.110637]\n",
      "Epoch: 540, F1: 0.65060, F1P: 54\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "75.46875\n",
      "541 [D loss: 0.276302, acc: 78.91%, op_acc: 54.69%] [G loss: 1.094428]\n",
      "542 [D loss: 0.293053, acc: 72.66%, op_acc: 54.69%] [G loss: 1.083173]\n",
      "543 [D loss: 0.288020, acc: 76.56%, op_acc: 53.12%] [G loss: 1.081361]\n",
      "544 [D loss: 0.281638, acc: 76.56%, op_acc: 54.69%] [G loss: 1.076710]\n",
      "545 [D loss: 0.269627, acc: 85.94%, op_acc: 57.81%] [G loss: 1.069473]\n",
      "546 [D loss: 0.285748, acc: 78.12%, op_acc: 51.56%] [G loss: 1.113073]\n",
      "547 [D loss: 0.293046, acc: 73.44%, op_acc: 56.25%] [G loss: 1.066357]\n",
      "548 [D loss: 0.299974, acc: 71.09%, op_acc: 53.12%] [G loss: 1.085963]\n",
      "549 [D loss: 0.288170, acc: 78.12%, op_acc: 54.69%] [G loss: 1.070759]\n",
      "550 [D loss: 0.284431, acc: 77.34%, op_acc: 53.91%] [G loss: 1.143938]\n",
      "Epoch: 550, F1: 0.65060, F1P: 55\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "76.875\n",
      "551 [D loss: 0.269142, acc: 77.34%, op_acc: 53.12%] [G loss: 1.105849]\n",
      "552 [D loss: 0.268869, acc: 80.47%, op_acc: 51.56%] [G loss: 1.077491]\n",
      "553 [D loss: 0.285607, acc: 75.78%, op_acc: 51.56%] [G loss: 1.118366]\n",
      "554 [D loss: 0.276426, acc: 81.25%, op_acc: 51.56%] [G loss: 1.066347]\n",
      "555 [D loss: 0.282598, acc: 76.56%, op_acc: 58.59%] [G loss: 1.159307]\n",
      "556 [D loss: 0.281969, acc: 79.69%, op_acc: 52.34%] [G loss: 1.039169]\n",
      "557 [D loss: 0.292641, acc: 75.00%, op_acc: 51.56%] [G loss: 1.134848]\n",
      "558 [D loss: 0.287144, acc: 81.25%, op_acc: 54.69%] [G loss: 1.147150]\n",
      "559 [D loss: 0.292013, acc: 75.00%, op_acc: 49.22%] [G loss: 1.054652]\n",
      "560 [D loss: 0.262808, acc: 81.25%, op_acc: 55.47%] [G loss: 1.085274]\n",
      "Epoch: 560, F1: 0.65882, F1P: 56\n",
      "[[28424     8]\n",
      " [   21    28]]\n",
      "78.359375\n",
      "561 [D loss: 0.291120, acc: 73.44%, op_acc: 50.00%] [G loss: 1.042132]\n",
      "562 [D loss: 0.293905, acc: 75.78%, op_acc: 56.25%] [G loss: 1.098980]\n",
      "563 [D loss: 0.283991, acc: 78.91%, op_acc: 52.34%] [G loss: 1.114284]\n",
      "564 [D loss: 0.281054, acc: 76.56%, op_acc: 50.78%] [G loss: 1.084251]\n",
      "565 [D loss: 0.303466, acc: 72.66%, op_acc: 52.34%] [G loss: 1.087280]\n",
      "566 [D loss: 0.291407, acc: 74.22%, op_acc: 50.78%] [G loss: 1.140669]\n",
      "567 [D loss: 0.273987, acc: 79.69%, op_acc: 53.91%] [G loss: 1.043164]\n",
      "568 [D loss: 0.282436, acc: 71.88%, op_acc: 55.47%] [G loss: 1.078235]\n",
      "569 [D loss: 0.296063, acc: 72.66%, op_acc: 50.78%] [G loss: 1.081561]\n",
      "570 [D loss: 0.283866, acc: 78.12%, op_acc: 54.69%] [G loss: 1.101765]\n",
      "Epoch: 570, F1: 0.63415, F1P: 57\n",
      "[[28425     7]\n",
      " [   23    26]]\n",
      "75.390625\n",
      "571 [D loss: 0.267905, acc: 78.91%, op_acc: 54.69%] [G loss: 1.073415]\n",
      "572 [D loss: 0.283436, acc: 80.47%, op_acc: 56.25%] [G loss: 1.072445]\n",
      "573 [D loss: 0.282169, acc: 79.69%, op_acc: 57.81%] [G loss: 1.101273]\n",
      "574 [D loss: 0.287627, acc: 75.78%, op_acc: 52.34%] [G loss: 1.111874]\n",
      "575 [D loss: 0.275488, acc: 76.56%, op_acc: 50.78%] [G loss: 1.092575]\n",
      "576 [D loss: 0.276869, acc: 82.81%, op_acc: 60.94%] [G loss: 1.076665]\n",
      "577 [D loss: 0.285066, acc: 78.12%, op_acc: 60.94%] [G loss: 1.104528]\n",
      "578 [D loss: 0.277307, acc: 81.25%, op_acc: 57.03%] [G loss: 1.101746]\n",
      "579 [D loss: 0.290026, acc: 72.66%, op_acc: 57.81%] [G loss: 1.124853]\n",
      "580 [D loss: 0.291067, acc: 72.66%, op_acc: 54.69%] [G loss: 1.090814]\n",
      "Epoch: 580, F1: 0.63415, F1P: 58\n",
      "[[28425     7]\n",
      " [   23    26]]\n",
      "77.890625\n",
      "581 [D loss: 0.290866, acc: 75.78%, op_acc: 50.78%] [G loss: 1.115064]\n",
      "582 [D loss: 0.267765, acc: 81.25%, op_acc: 54.69%] [G loss: 1.103937]\n",
      "583 [D loss: 0.289999, acc: 78.12%, op_acc: 53.91%] [G loss: 1.108732]\n",
      "584 [D loss: 0.280551, acc: 78.91%, op_acc: 53.12%] [G loss: 1.176151]\n",
      "585 [D loss: 0.289309, acc: 81.25%, op_acc: 53.91%] [G loss: 1.061079]\n",
      "586 [D loss: 0.280137, acc: 76.56%, op_acc: 56.25%] [G loss: 1.109077]\n",
      "587 [D loss: 0.279651, acc: 79.69%, op_acc: 53.91%] [G loss: 1.077002]\n",
      "588 [D loss: 0.279502, acc: 76.56%, op_acc: 53.91%] [G loss: 1.087085]\n",
      "589 [D loss: 0.277431, acc: 78.91%, op_acc: 51.56%] [G loss: 1.116870]\n",
      "590 [D loss: 0.283849, acc: 76.56%, op_acc: 53.91%] [G loss: 1.114776]\n",
      "Epoch: 590, F1: 0.65060, F1P: 59\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "78.359375\n",
      "591 [D loss: 0.267855, acc: 84.38%, op_acc: 60.16%] [G loss: 1.121223]\n",
      "592 [D loss: 0.279982, acc: 81.25%, op_acc: 57.81%] [G loss: 1.082710]\n",
      "593 [D loss: 0.295167, acc: 72.66%, op_acc: 51.56%] [G loss: 1.063170]\n",
      "594 [D loss: 0.278274, acc: 82.03%, op_acc: 53.91%] [G loss: 1.124643]\n",
      "595 [D loss: 0.273325, acc: 78.12%, op_acc: 53.91%] [G loss: 1.096478]\n",
      "596 [D loss: 0.263898, acc: 82.81%, op_acc: 50.00%] [G loss: 1.096794]\n",
      "597 [D loss: 0.285804, acc: 76.56%, op_acc: 47.66%] [G loss: 1.078135]\n",
      "598 [D loss: 0.273804, acc: 80.47%, op_acc: 53.12%] [G loss: 1.052268]\n",
      "599 [D loss: 0.265803, acc: 81.25%, op_acc: 56.25%] [G loss: 1.081389]\n",
      "600 [D loss: 0.276829, acc: 80.47%, op_acc: 58.59%] [G loss: 1.135427]\n",
      "Epoch: 600, F1: 0.66667, F1P: 60\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "80.0\n",
      "601 [D loss: 0.278945, acc: 78.12%, op_acc: 58.59%] [G loss: 1.106748]\n",
      "602 [D loss: 0.283119, acc: 77.34%, op_acc: 54.69%] [G loss: 1.125087]\n",
      "603 [D loss: 0.269969, acc: 82.03%, op_acc: 57.81%] [G loss: 1.049140]\n",
      "604 [D loss: 0.284344, acc: 78.12%, op_acc: 54.69%] [G loss: 1.103817]\n",
      "605 [D loss: 0.258413, acc: 87.50%, op_acc: 54.69%] [G loss: 1.086431]\n",
      "606 [D loss: 0.275790, acc: 79.69%, op_acc: 52.34%] [G loss: 1.142965]\n",
      "607 [D loss: 0.275317, acc: 80.47%, op_acc: 57.81%] [G loss: 1.168378]\n",
      "608 [D loss: 0.270381, acc: 78.12%, op_acc: 60.16%] [G loss: 1.084429]\n",
      "609 [D loss: 0.274650, acc: 77.34%, op_acc: 54.69%] [G loss: 1.123301]\n",
      "610 [D loss: 0.267937, acc: 76.56%, op_acc: 55.47%] [G loss: 1.093255]\n",
      "Epoch: 610, F1: 0.66667, F1P: 61\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "79.53125\n",
      "611 [D loss: 0.274711, acc: 82.81%, op_acc: 52.34%] [G loss: 1.070987]\n",
      "612 [D loss: 0.275834, acc: 78.91%, op_acc: 57.81%] [G loss: 1.162819]\n",
      "613 [D loss: 0.285384, acc: 71.88%, op_acc: 56.25%] [G loss: 1.120187]\n",
      "614 [D loss: 0.273209, acc: 81.25%, op_acc: 54.69%] [G loss: 1.096982]\n",
      "615 [D loss: 0.279575, acc: 74.22%, op_acc: 52.34%] [G loss: 1.183770]\n",
      "616 [D loss: 0.278224, acc: 75.00%, op_acc: 53.91%] [G loss: 1.170044]\n",
      "617 [D loss: 0.284872, acc: 77.34%, op_acc: 53.91%] [G loss: 1.145734]\n",
      "618 [D loss: 0.267560, acc: 75.78%, op_acc: 53.91%] [G loss: 1.113648]\n",
      "619 [D loss: 0.277938, acc: 78.91%, op_acc: 54.69%] [G loss: 1.134689]\n",
      "620 [D loss: 0.269539, acc: 80.47%, op_acc: 54.69%] [G loss: 1.094227]\n",
      "Epoch: 620, F1: 0.65116, F1P: 62\n",
      "[[28423     9]\n",
      " [   21    28]]\n",
      "77.65625\n",
      "621 [D loss: 0.278424, acc: 78.91%, op_acc: 53.12%] [G loss: 1.097529]\n",
      "622 [D loss: 0.271552, acc: 78.12%, op_acc: 53.91%] [G loss: 1.134368]\n",
      "623 [D loss: 0.268482, acc: 77.34%, op_acc: 55.47%] [G loss: 1.127418]\n",
      "624 [D loss: 0.274862, acc: 79.69%, op_acc: 53.91%] [G loss: 1.133858]\n",
      "625 [D loss: 0.271861, acc: 80.47%, op_acc: 57.03%] [G loss: 1.119068]\n",
      "626 [D loss: 0.276372, acc: 78.91%, op_acc: 52.34%] [G loss: 1.126238]\n",
      "627 [D loss: 0.255050, acc: 86.72%, op_acc: 60.94%] [G loss: 1.111080]\n",
      "628 [D loss: 0.282162, acc: 77.34%, op_acc: 57.03%] [G loss: 1.047368]\n",
      "629 [D loss: 0.277142, acc: 75.78%, op_acc: 55.47%] [G loss: 1.164507]\n",
      "630 [D loss: 0.270876, acc: 82.81%, op_acc: 57.81%] [G loss: 1.118297]\n",
      "Epoch: 630, F1: 0.65116, F1P: 63\n",
      "[[28423     9]\n",
      " [   21    28]]\n",
      "79.609375\n",
      "631 [D loss: 0.274399, acc: 78.12%, op_acc: 51.56%] [G loss: 1.140038]\n",
      "632 [D loss: 0.276398, acc: 76.56%, op_acc: 50.00%] [G loss: 1.101039]\n",
      "633 [D loss: 0.285396, acc: 80.47%, op_acc: 50.00%] [G loss: 1.079765]\n",
      "634 [D loss: 0.268386, acc: 85.16%, op_acc: 61.72%] [G loss: 1.060496]\n",
      "635 [D loss: 0.275919, acc: 75.78%, op_acc: 55.47%] [G loss: 1.168110]\n",
      "636 [D loss: 0.269858, acc: 81.25%, op_acc: 54.69%] [G loss: 1.133354]\n",
      "637 [D loss: 0.261813, acc: 82.03%, op_acc: 55.47%] [G loss: 1.090710]\n",
      "638 [D loss: 0.280293, acc: 83.59%, op_acc: 53.12%] [G loss: 1.170766]\n",
      "639 [D loss: 0.283799, acc: 78.91%, op_acc: 52.34%] [G loss: 1.179201]\n",
      "640 [D loss: 0.284791, acc: 75.00%, op_acc: 54.69%] [G loss: 1.147323]\n",
      "Epoch: 640, F1: 0.66667, F1P: 64\n",
      "[[28423     9]\n",
      " [   20    29]]\n",
      "79.6875\n",
      "641 [D loss: 0.269440, acc: 80.47%, op_acc: 53.12%] [G loss: 1.208940]\n",
      "642 [D loss: 0.267889, acc: 82.03%, op_acc: 56.25%] [G loss: 1.141536]\n",
      "643 [D loss: 0.272410, acc: 81.25%, op_acc: 57.03%] [G loss: 1.126666]\n",
      "644 [D loss: 0.264500, acc: 81.25%, op_acc: 57.03%] [G loss: 1.093323]\n",
      "645 [D loss: 0.260580, acc: 84.38%, op_acc: 61.72%] [G loss: 1.190194]\n",
      "646 [D loss: 0.276674, acc: 81.25%, op_acc: 59.38%] [G loss: 1.159482]\n",
      "647 [D loss: 0.261354, acc: 82.03%, op_acc: 52.34%] [G loss: 1.194049]\n",
      "648 [D loss: 0.247525, acc: 85.94%, op_acc: 59.38%] [G loss: 1.203955]\n",
      "649 [D loss: 0.273053, acc: 81.25%, op_acc: 53.12%] [G loss: 1.114491]\n",
      "650 [D loss: 0.267158, acc: 85.94%, op_acc: 56.25%] [G loss: 1.134343]\n",
      "Epoch: 650, F1: 0.66667, F1P: 65\n",
      "[[28423     9]\n",
      " [   20    29]]\n",
      "82.578125\n",
      "651 [D loss: 0.265478, acc: 80.47%, op_acc: 57.03%] [G loss: 1.136411]\n",
      "652 [D loss: 0.283629, acc: 77.34%, op_acc: 59.38%] [G loss: 1.175354]\n",
      "653 [D loss: 0.262517, acc: 83.59%, op_acc: 57.81%] [G loss: 1.128547]\n",
      "654 [D loss: 0.255819, acc: 84.38%, op_acc: 59.38%] [G loss: 1.136709]\n",
      "655 [D loss: 0.274362, acc: 77.34%, op_acc: 55.47%] [G loss: 1.133381]\n",
      "656 [D loss: 0.271080, acc: 79.69%, op_acc: 53.12%] [G loss: 1.138679]\n",
      "657 [D loss: 0.261568, acc: 83.59%, op_acc: 55.47%] [G loss: 1.108563]\n",
      "658 [D loss: 0.254082, acc: 82.81%, op_acc: 60.94%] [G loss: 1.161254]\n",
      "659 [D loss: 0.267643, acc: 83.59%, op_acc: 57.03%] [G loss: 1.161157]\n",
      "660 [D loss: 0.266322, acc: 80.47%, op_acc: 57.03%] [G loss: 1.111392]\n",
      "Epoch: 660, F1: 0.69663, F1P: 66\n",
      "[[28423     9]\n",
      " [   18    31]]\n",
      "81.328125\n",
      "661 [D loss: 0.261946, acc: 81.25%, op_acc: 57.81%] [G loss: 1.164809]\n",
      "662 [D loss: 0.272306, acc: 83.59%, op_acc: 55.47%] [G loss: 1.173945]\n",
      "663 [D loss: 0.264208, acc: 82.03%, op_acc: 53.12%] [G loss: 1.126801]\n",
      "664 [D loss: 0.271410, acc: 82.03%, op_acc: 49.22%] [G loss: 1.154776]\n",
      "665 [D loss: 0.275278, acc: 80.47%, op_acc: 57.81%] [G loss: 1.073759]\n",
      "666 [D loss: 0.282167, acc: 76.56%, op_acc: 57.03%] [G loss: 1.129065]\n",
      "667 [D loss: 0.271629, acc: 78.12%, op_acc: 61.72%] [G loss: 1.169209]\n",
      "668 [D loss: 0.248454, acc: 85.16%, op_acc: 62.50%] [G loss: 1.133176]\n",
      "669 [D loss: 0.273834, acc: 78.91%, op_acc: 54.69%] [G loss: 1.162931]\n",
      "670 [D loss: 0.279230, acc: 76.56%, op_acc: 46.09%] [G loss: 1.149655]\n",
      "Epoch: 670, F1: 0.65263, F1P: 67\n",
      "[[28417    15]\n",
      " [   18    31]]\n",
      "80.46875\n",
      "671 [D loss: 0.260591, acc: 82.03%, op_acc: 56.25%] [G loss: 1.183349]\n",
      "672 [D loss: 0.270202, acc: 84.38%, op_acc: 49.22%] [G loss: 1.133948]\n",
      "673 [D loss: 0.258976, acc: 85.16%, op_acc: 50.00%] [G loss: 1.162041]\n",
      "674 [D loss: 0.269563, acc: 77.34%, op_acc: 48.44%] [G loss: 1.179905]\n",
      "675 [D loss: 0.273848, acc: 82.81%, op_acc: 50.78%] [G loss: 1.139398]\n",
      "676 [D loss: 0.253855, acc: 87.50%, op_acc: 57.81%] [G loss: 1.172204]\n",
      "677 [D loss: 0.270449, acc: 82.03%, op_acc: 49.22%] [G loss: 1.175179]\n",
      "678 [D loss: 0.270830, acc: 81.25%, op_acc: 56.25%] [G loss: 1.223209]\n",
      "679 [D loss: 0.257126, acc: 85.16%, op_acc: 54.69%] [G loss: 1.168935]\n",
      "680 [D loss: 0.261895, acc: 83.59%, op_acc: 53.91%] [G loss: 1.167008]\n",
      "Epoch: 680, F1: 0.65385, F1P: 68\n",
      "[[28411    21]\n",
      " [   15    34]]\n",
      "83.125\n",
      "681 [D loss: 0.254317, acc: 84.38%, op_acc: 57.03%] [G loss: 1.126035]\n",
      "682 [D loss: 0.248636, acc: 90.62%, op_acc: 59.38%] [G loss: 1.206982]\n",
      "683 [D loss: 0.269249, acc: 82.03%, op_acc: 62.50%] [G loss: 1.195028]\n",
      "684 [D loss: 0.275782, acc: 78.12%, op_acc: 57.81%] [G loss: 1.225096]\n",
      "685 [D loss: 0.255964, acc: 84.38%, op_acc: 53.12%] [G loss: 1.197231]\n",
      "686 [D loss: 0.269627, acc: 75.00%, op_acc: 58.59%] [G loss: 1.198981]\n",
      "687 [D loss: 0.249495, acc: 89.84%, op_acc: 55.47%] [G loss: 1.144934]\n",
      "688 [D loss: 0.252551, acc: 87.50%, op_acc: 53.12%] [G loss: 1.163018]\n",
      "689 [D loss: 0.265813, acc: 82.81%, op_acc: 61.72%] [G loss: 1.218458]\n",
      "690 [D loss: 0.270463, acc: 82.81%, op_acc: 52.34%] [G loss: 1.214625]\n",
      "Epoch: 690, F1: 0.63636, F1P: 69\n",
      "[[28406    26]\n",
      " [   14    35]]\n",
      "83.75\n",
      "691 [D loss: 0.249781, acc: 85.94%, op_acc: 59.38%] [G loss: 1.190228]\n",
      "692 [D loss: 0.277778, acc: 81.25%, op_acc: 57.81%] [G loss: 1.185937]\n",
      "693 [D loss: 0.270460, acc: 80.47%, op_acc: 53.91%] [G loss: 1.198382]\n",
      "694 [D loss: 0.261020, acc: 82.03%, op_acc: 55.47%] [G loss: 1.152927]\n",
      "695 [D loss: 0.268670, acc: 82.81%, op_acc: 54.69%] [G loss: 1.161798]\n",
      "696 [D loss: 0.252405, acc: 79.69%, op_acc: 56.25%] [G loss: 1.196448]\n",
      "697 [D loss: 0.267821, acc: 82.03%, op_acc: 51.56%] [G loss: 1.193714]\n",
      "698 [D loss: 0.278107, acc: 79.69%, op_acc: 52.34%] [G loss: 1.216098]\n",
      "699 [D loss: 0.260834, acc: 83.59%, op_acc: 50.78%] [G loss: 1.212299]\n",
      "700 [D loss: 0.258483, acc: 80.47%, op_acc: 53.91%] [G loss: 1.195860]\n",
      "Epoch: 700, F1: 0.60345, F1P: 70\n",
      "[[28400    32]\n",
      " [   14    35]]\n",
      "81.796875\n",
      "701 [D loss: 0.272860, acc: 78.12%, op_acc: 50.00%] [G loss: 1.211483]\n",
      "702 [D loss: 0.257906, acc: 82.03%, op_acc: 60.94%] [G loss: 1.232751]\n",
      "703 [D loss: 0.259443, acc: 82.03%, op_acc: 53.12%] [G loss: 1.170456]\n",
      "704 [D loss: 0.245587, acc: 85.94%, op_acc: 55.47%] [G loss: 1.177031]\n",
      "705 [D loss: 0.268301, acc: 82.81%, op_acc: 53.12%] [G loss: 1.214805]\n",
      "706 [D loss: 0.246671, acc: 89.84%, op_acc: 60.16%] [G loss: 1.158427]\n",
      "707 [D loss: 0.264569, acc: 76.56%, op_acc: 50.78%] [G loss: 1.149759]\n",
      "708 [D loss: 0.255791, acc: 83.59%, op_acc: 53.12%] [G loss: 1.270621]\n",
      "709 [D loss: 0.259209, acc: 83.59%, op_acc: 55.47%] [G loss: 1.142238]\n",
      "710 [D loss: 0.264479, acc: 85.16%, op_acc: 50.78%] [G loss: 1.228743]\n",
      "Epoch: 710, F1: 0.57143, F1P: 71\n",
      "[[28391    41]\n",
      " [   13    36]]\n",
      "82.96875\n",
      "711 [D loss: 0.246185, acc: 88.28%, op_acc: 57.03%] [G loss: 1.175154]\n",
      "712 [D loss: 0.265130, acc: 78.91%, op_acc: 58.59%] [G loss: 1.252184]\n",
      "713 [D loss: 0.264115, acc: 82.81%, op_acc: 45.31%] [G loss: 1.178594]\n",
      "714 [D loss: 0.251468, acc: 85.16%, op_acc: 62.50%] [G loss: 1.175664]\n",
      "715 [D loss: 0.262698, acc: 82.81%, op_acc: 55.47%] [G loss: 1.301656]\n",
      "716 [D loss: 0.258915, acc: 83.59%, op_acc: 53.12%] [G loss: 1.161669]\n",
      "717 [D loss: 0.259335, acc: 86.72%, op_acc: 53.12%] [G loss: 1.263535]\n",
      "718 [D loss: 0.260241, acc: 81.25%, op_acc: 51.56%] [G loss: 1.231266]\n",
      "719 [D loss: 0.244304, acc: 90.62%, op_acc: 58.59%] [G loss: 1.151661]\n",
      "720 [D loss: 0.264660, acc: 82.03%, op_acc: 55.47%] [G loss: 1.223586]\n",
      "Epoch: 720, F1: 0.56693, F1P: 72\n",
      "[[28390    42]\n",
      " [   13    36]]\n",
      "84.21875\n",
      "721 [D loss: 0.247089, acc: 82.03%, op_acc: 49.22%] [G loss: 1.174696]\n",
      "722 [D loss: 0.272451, acc: 78.91%, op_acc: 46.88%] [G loss: 1.182893]\n",
      "723 [D loss: 0.262720, acc: 85.94%, op_acc: 52.34%] [G loss: 1.138467]\n",
      "724 [D loss: 0.259495, acc: 83.59%, op_acc: 56.25%] [G loss: 1.210573]\n",
      "725 [D loss: 0.270264, acc: 76.56%, op_acc: 53.12%] [G loss: 1.183785]\n",
      "726 [D loss: 0.256347, acc: 80.47%, op_acc: 53.12%] [G loss: 1.224185]\n",
      "727 [D loss: 0.265544, acc: 85.16%, op_acc: 52.34%] [G loss: 1.194530]\n",
      "728 [D loss: 0.262633, acc: 82.03%, op_acc: 57.03%] [G loss: 1.188859]\n",
      "729 [D loss: 0.257590, acc: 79.69%, op_acc: 59.38%] [G loss: 1.165953]\n",
      "730 [D loss: 0.265637, acc: 81.25%, op_acc: 53.12%] [G loss: 1.165205]\n",
      "Epoch: 730, F1: 0.56693, F1P: 73\n",
      "[[28390    42]\n",
      " [   13    36]]\n",
      "81.5625\n",
      "731 [D loss: 0.257944, acc: 81.25%, op_acc: 54.69%] [G loss: 1.252834]\n",
      "732 [D loss: 0.263714, acc: 80.47%, op_acc: 55.47%] [G loss: 1.264370]\n",
      "733 [D loss: 0.270890, acc: 74.22%, op_acc: 52.34%] [G loss: 1.163002]\n",
      "734 [D loss: 0.253074, acc: 85.94%, op_acc: 53.91%] [G loss: 1.139755]\n",
      "735 [D loss: 0.256922, acc: 80.47%, op_acc: 52.34%] [G loss: 1.250847]\n",
      "736 [D loss: 0.253099, acc: 82.03%, op_acc: 58.59%] [G loss: 1.204617]\n",
      "737 [D loss: 0.262648, acc: 82.81%, op_acc: 60.16%] [G loss: 1.247977]\n",
      "738 [D loss: 0.249487, acc: 83.59%, op_acc: 53.91%] [G loss: 1.252515]\n",
      "739 [D loss: 0.251776, acc: 85.16%, op_acc: 59.38%] [G loss: 1.245320]\n",
      "740 [D loss: 0.259556, acc: 84.38%, op_acc: 51.56%] [G loss: 1.227439]\n",
      "Epoch: 740, F1: 0.52941, F1P: 74\n",
      "[[28381    51]\n",
      " [   13    36]]\n",
      "82.03125\n",
      "741 [D loss: 0.257337, acc: 82.03%, op_acc: 49.22%] [G loss: 1.167249]\n",
      "742 [D loss: 0.258233, acc: 83.59%, op_acc: 56.25%] [G loss: 1.221065]\n",
      "743 [D loss: 0.244665, acc: 85.94%, op_acc: 56.25%] [G loss: 1.163914]\n",
      "744 [D loss: 0.267353, acc: 78.12%, op_acc: 54.69%] [G loss: 1.222555]\n",
      "745 [D loss: 0.256813, acc: 78.91%, op_acc: 60.16%] [G loss: 1.284789]\n",
      "746 [D loss: 0.259008, acc: 81.25%, op_acc: 59.38%] [G loss: 1.242394]\n",
      "747 [D loss: 0.259381, acc: 84.38%, op_acc: 54.69%] [G loss: 1.247360]\n",
      "748 [D loss: 0.253185, acc: 84.38%, op_acc: 55.47%] [G loss: 1.217992]\n",
      "749 [D loss: 0.256795, acc: 85.16%, op_acc: 56.25%] [G loss: 1.186508]\n",
      "750 [D loss: 0.265510, acc: 78.91%, op_acc: 55.47%] [G loss: 1.246892]\n",
      "Epoch: 750, F1: 0.50000, F1P: 75\n",
      "[[28370    62]\n",
      " [   12    37]]\n",
      "82.265625\n",
      "751 [D loss: 0.270405, acc: 78.91%, op_acc: 57.81%] [G loss: 1.213198]\n",
      "752 [D loss: 0.248200, acc: 85.94%, op_acc: 57.81%] [G loss: 1.240099]\n",
      "753 [D loss: 0.250519, acc: 89.06%, op_acc: 46.09%] [G loss: 1.208702]\n",
      "754 [D loss: 0.249609, acc: 89.06%, op_acc: 55.47%] [G loss: 1.265378]\n",
      "755 [D loss: 0.253615, acc: 84.38%, op_acc: 64.84%] [G loss: 1.253220]\n",
      "756 [D loss: 0.245797, acc: 87.50%, op_acc: 53.91%] [G loss: 1.185975]\n",
      "757 [D loss: 0.257211, acc: 84.38%, op_acc: 60.16%] [G loss: 1.283404]\n",
      "758 [D loss: 0.258244, acc: 79.69%, op_acc: 53.91%] [G loss: 1.264159]\n",
      "759 [D loss: 0.244100, acc: 86.72%, op_acc: 55.47%] [G loss: 1.276051]\n",
      "760 [D loss: 0.256991, acc: 82.81%, op_acc: 53.91%] [G loss: 1.261891]\n",
      "Epoch: 760, F1: 0.49007, F1P: 76\n",
      "[[28367    65]\n",
      " [   12    37]]\n",
      "84.84375\n",
      "761 [D loss: 0.228567, acc: 89.84%, op_acc: 57.03%] [G loss: 1.236454]\n",
      "762 [D loss: 0.248853, acc: 85.16%, op_acc: 46.88%] [G loss: 1.283175]\n",
      "763 [D loss: 0.249771, acc: 85.94%, op_acc: 54.69%] [G loss: 1.206948]\n",
      "764 [D loss: 0.245008, acc: 89.06%, op_acc: 57.03%] [G loss: 1.282794]\n",
      "765 [D loss: 0.237433, acc: 90.62%, op_acc: 58.59%] [G loss: 1.287471]\n",
      "766 [D loss: 0.249404, acc: 84.38%, op_acc: 56.25%] [G loss: 1.262421]\n",
      "767 [D loss: 0.249410, acc: 89.06%, op_acc: 62.50%] [G loss: 1.230246]\n",
      "768 [D loss: 0.233147, acc: 88.28%, op_acc: 48.44%] [G loss: 1.205853]\n",
      "769 [D loss: 0.236153, acc: 87.50%, op_acc: 55.47%] [G loss: 1.260767]\n",
      "770 [D loss: 0.255902, acc: 82.81%, op_acc: 57.81%] [G loss: 1.283004]\n",
      "Epoch: 770, F1: 0.50340, F1P: 77\n",
      "[[28371    61]\n",
      " [   12    37]]\n",
      "87.265625\n",
      "771 [D loss: 0.252248, acc: 85.16%, op_acc: 56.25%] [G loss: 1.277092]\n",
      "772 [D loss: 0.243806, acc: 87.50%, op_acc: 52.34%] [G loss: 1.276367]\n",
      "773 [D loss: 0.245854, acc: 85.16%, op_acc: 57.81%] [G loss: 1.217523]\n",
      "774 [D loss: 0.254816, acc: 81.25%, op_acc: 57.03%] [G loss: 1.223129]\n",
      "775 [D loss: 0.243989, acc: 91.41%, op_acc: 61.72%] [G loss: 1.294074]\n",
      "776 [D loss: 0.242582, acc: 87.50%, op_acc: 60.94%] [G loss: 1.264611]\n",
      "777 [D loss: 0.241201, acc: 85.94%, op_acc: 53.91%] [G loss: 1.202406]\n",
      "778 [D loss: 0.233611, acc: 88.28%, op_acc: 56.25%] [G loss: 1.299731]\n",
      "779 [D loss: 0.252933, acc: 89.84%, op_acc: 58.59%] [G loss: 1.213776]\n",
      "780 [D loss: 0.234943, acc: 86.72%, op_acc: 59.38%] [G loss: 1.269530]\n",
      "Epoch: 780, F1: 0.49664, F1P: 78\n",
      "[[28369    63]\n",
      " [   12    37]]\n",
      "86.875\n",
      "781 [D loss: 0.237426, acc: 87.50%, op_acc: 57.03%] [G loss: 1.231025]\n",
      "782 [D loss: 0.243084, acc: 86.72%, op_acc: 54.69%] [G loss: 1.275777]\n",
      "783 [D loss: 0.244242, acc: 88.28%, op_acc: 61.72%] [G loss: 1.248087]\n",
      "784 [D loss: 0.246080, acc: 85.94%, op_acc: 57.03%] [G loss: 1.291499]\n",
      "785 [D loss: 0.224721, acc: 90.62%, op_acc: 57.81%] [G loss: 1.347832]\n",
      "786 [D loss: 0.241736, acc: 87.50%, op_acc: 60.16%] [G loss: 1.231783]\n",
      "787 [D loss: 0.226729, acc: 92.97%, op_acc: 61.72%] [G loss: 1.292535]\n",
      "788 [D loss: 0.232010, acc: 91.41%, op_acc: 64.06%] [G loss: 1.225992]\n",
      "789 [D loss: 0.234400, acc: 87.50%, op_acc: 63.28%] [G loss: 1.180561]\n",
      "790 [D loss: 0.232332, acc: 86.72%, op_acc: 58.59%] [G loss: 1.206827]\n",
      "Epoch: 790, F1: 0.49333, F1P: 79\n",
      "[[28368    64]\n",
      " [   12    37]]\n",
      "88.515625\n",
      "791 [D loss: 0.242827, acc: 83.59%, op_acc: 60.94%] [G loss: 1.200783]\n",
      "792 [D loss: 0.249478, acc: 90.62%, op_acc: 60.94%] [G loss: 1.233687]\n",
      "793 [D loss: 0.238234, acc: 90.62%, op_acc: 59.38%] [G loss: 1.269359]\n",
      "794 [D loss: 0.249354, acc: 82.03%, op_acc: 60.16%] [G loss: 1.231280]\n",
      "795 [D loss: 0.242070, acc: 86.72%, op_acc: 58.59%] [G loss: 1.238880]\n",
      "796 [D loss: 0.236927, acc: 89.06%, op_acc: 54.69%] [G loss: 1.216233]\n",
      "797 [D loss: 0.242149, acc: 83.59%, op_acc: 54.69%] [G loss: 1.303897]\n",
      "798 [D loss: 0.256002, acc: 82.03%, op_acc: 58.59%] [G loss: 1.315067]\n",
      "799 [D loss: 0.239545, acc: 87.50%, op_acc: 60.16%] [G loss: 1.298686]\n",
      "800 [D loss: 0.232427, acc: 87.50%, op_acc: 60.94%] [G loss: 1.291105]\n",
      "Epoch: 800, F1: 0.43275, F1P: 80\n",
      "[[28347    85]\n",
      " [   12    37]]\n",
      "86.328125\n",
      "801 [D loss: 0.240168, acc: 85.94%, op_acc: 61.72%] [G loss: 1.331611]\n",
      "802 [D loss: 0.232879, acc: 89.84%, op_acc: 64.06%] [G loss: 1.278779]\n",
      "803 [D loss: 0.251378, acc: 81.25%, op_acc: 58.59%] [G loss: 1.301340]\n",
      "804 [D loss: 0.239993, acc: 86.72%, op_acc: 60.16%] [G loss: 1.202113]\n",
      "805 [D loss: 0.240721, acc: 87.50%, op_acc: 58.59%] [G loss: 1.290187]\n",
      "806 [D loss: 0.229284, acc: 87.50%, op_acc: 67.97%] [G loss: 1.314373]\n",
      "807 [D loss: 0.230200, acc: 85.94%, op_acc: 60.94%] [G loss: 1.357337]\n",
      "808 [D loss: 0.230044, acc: 83.59%, op_acc: 59.38%] [G loss: 1.266557]\n",
      "809 [D loss: 0.241004, acc: 88.28%, op_acc: 61.72%] [G loss: 1.305697]\n",
      "810 [D loss: 0.240301, acc: 89.84%, op_acc: 60.16%] [G loss: 1.303001]\n",
      "Epoch: 810, F1: 0.48684, F1P: 81\n",
      "[[28366    66]\n",
      " [   12    37]]\n",
      "86.640625\n",
      "811 [D loss: 0.244698, acc: 86.72%, op_acc: 58.59%] [G loss: 1.290883]\n",
      "812 [D loss: 0.242084, acc: 89.06%, op_acc: 60.16%] [G loss: 1.331201]\n",
      "813 [D loss: 0.241879, acc: 85.94%, op_acc: 57.03%] [G loss: 1.249366]\n",
      "814 [D loss: 0.243834, acc: 92.19%, op_acc: 62.50%] [G loss: 1.265823]\n",
      "815 [D loss: 0.229956, acc: 89.84%, op_acc: 61.72%] [G loss: 1.329374]\n",
      "816 [D loss: 0.230744, acc: 89.84%, op_acc: 59.38%] [G loss: 1.284807]\n",
      "817 [D loss: 0.228276, acc: 88.28%, op_acc: 58.59%] [G loss: 1.348945]\n",
      "818 [D loss: 0.232546, acc: 89.06%, op_acc: 56.25%] [G loss: 1.227162]\n",
      "819 [D loss: 0.222750, acc: 92.97%, op_acc: 68.75%] [G loss: 1.317976]\n",
      "820 [D loss: 0.227356, acc: 89.84%, op_acc: 65.62%] [G loss: 1.316176]\n",
      "Epoch: 820, F1: 0.50685, F1P: 82\n",
      "[[28372    60]\n",
      " [   12    37]]\n",
      "89.375\n",
      "821 [D loss: 0.244718, acc: 87.50%, op_acc: 54.69%] [G loss: 1.311894]\n",
      "822 [D loss: 0.229911, acc: 86.72%, op_acc: 60.94%] [G loss: 1.241227]\n",
      "823 [D loss: 0.237404, acc: 85.94%, op_acc: 67.19%] [G loss: 1.261776]\n",
      "824 [D loss: 0.246835, acc: 86.72%, op_acc: 62.50%] [G loss: 1.316889]\n",
      "825 [D loss: 0.243717, acc: 83.59%, op_acc: 57.03%] [G loss: 1.349597]\n",
      "826 [D loss: 0.216029, acc: 90.62%, op_acc: 59.38%] [G loss: 1.276982]\n",
      "827 [D loss: 0.240461, acc: 88.28%, op_acc: 60.16%] [G loss: 1.309726]\n",
      "828 [D loss: 0.238246, acc: 84.38%, op_acc: 62.50%] [G loss: 1.282461]\n",
      "829 [D loss: 0.225325, acc: 92.97%, op_acc: 63.28%] [G loss: 1.305462]\n",
      "830 [D loss: 0.230512, acc: 89.06%, op_acc: 65.62%] [G loss: 1.333840]\n",
      "Epoch: 830, F1: 0.56250, F1P: 83\n",
      "[[28389    43]\n",
      " [   13    36]]\n",
      "87.578125\n",
      "831 [D loss: 0.247481, acc: 83.59%, op_acc: 55.47%] [G loss: 1.361325]\n",
      "832 [D loss: 0.239070, acc: 88.28%, op_acc: 63.28%] [G loss: 1.321792]\n",
      "833 [D loss: 0.238453, acc: 86.72%, op_acc: 57.81%] [G loss: 1.310410]\n",
      "834 [D loss: 0.224692, acc: 92.97%, op_acc: 62.50%] [G loss: 1.256808]\n",
      "835 [D loss: 0.243220, acc: 82.81%, op_acc: 67.97%] [G loss: 1.257625]\n",
      "836 [D loss: 0.236576, acc: 91.41%, op_acc: 57.03%] [G loss: 1.277654]\n",
      "837 [D loss: 0.238575, acc: 84.38%, op_acc: 64.06%] [G loss: 1.283135]\n",
      "838 [D loss: 0.223327, acc: 88.28%, op_acc: 62.50%] [G loss: 1.257009]\n",
      "839 [D loss: 0.240336, acc: 83.59%, op_acc: 64.84%] [G loss: 1.293289]\n",
      "840 [D loss: 0.235443, acc: 87.50%, op_acc: 57.81%] [G loss: 1.283470]\n",
      "Epoch: 840, F1: 0.58537, F1P: 84\n",
      "[[28394    38]\n",
      " [   13    36]]\n",
      "86.953125\n",
      "841 [D loss: 0.244903, acc: 85.16%, op_acc: 66.41%] [G loss: 1.321719]\n",
      "842 [D loss: 0.240238, acc: 89.06%, op_acc: 67.97%] [G loss: 1.273704]\n",
      "843 [D loss: 0.242406, acc: 85.94%, op_acc: 62.50%] [G loss: 1.316058]\n",
      "844 [D loss: 0.231797, acc: 87.50%, op_acc: 67.97%] [G loss: 1.345835]\n",
      "845 [D loss: 0.227842, acc: 88.28%, op_acc: 64.84%] [G loss: 1.294160]\n",
      "846 [D loss: 0.238323, acc: 86.72%, op_acc: 56.25%] [G loss: 1.216413]\n",
      "847 [D loss: 0.245854, acc: 83.59%, op_acc: 57.81%] [G loss: 1.286676]\n",
      "848 [D loss: 0.233792, acc: 90.62%, op_acc: 66.41%] [G loss: 1.228330]\n",
      "849 [D loss: 0.239689, acc: 84.38%, op_acc: 62.50%] [G loss: 1.291330]\n",
      "850 [D loss: 0.239609, acc: 83.59%, op_acc: 63.28%] [G loss: 1.249268]\n",
      "Epoch: 850, F1: 0.59016, F1P: 85\n",
      "[[28395    37]\n",
      " [   13    36]]\n",
      "86.484375\n",
      "851 [D loss: 0.236490, acc: 85.16%, op_acc: 68.75%] [G loss: 1.284102]\n",
      "852 [D loss: 0.240032, acc: 89.06%, op_acc: 64.06%] [G loss: 1.349944]\n",
      "853 [D loss: 0.238313, acc: 85.94%, op_acc: 61.72%] [G loss: 1.345304]\n",
      "854 [D loss: 0.229121, acc: 90.62%, op_acc: 67.19%] [G loss: 1.317656]\n",
      "855 [D loss: 0.236899, acc: 89.06%, op_acc: 55.47%] [G loss: 1.275043]\n",
      "856 [D loss: 0.247717, acc: 87.50%, op_acc: 64.06%] [G loss: 1.355006]\n",
      "857 [D loss: 0.225795, acc: 90.62%, op_acc: 65.62%] [G loss: 1.358185]\n",
      "858 [D loss: 0.233296, acc: 86.72%, op_acc: 65.62%] [G loss: 1.286397]\n",
      "859 [D loss: 0.238105, acc: 86.72%, op_acc: 62.50%] [G loss: 1.279636]\n",
      "860 [D loss: 0.225448, acc: 94.53%, op_acc: 64.06%] [G loss: 1.262841]\n",
      "Epoch: 860, F1: 0.60000, F1P: 86\n",
      "[[28397    35]\n",
      " [   13    36]]\n",
      "88.59375\n",
      "861 [D loss: 0.244659, acc: 89.06%, op_acc: 58.59%] [G loss: 1.246581]\n",
      "862 [D loss: 0.246068, acc: 84.38%, op_acc: 65.62%] [G loss: 1.275512]\n",
      "863 [D loss: 0.265063, acc: 78.12%, op_acc: 55.47%] [G loss: 1.337289]\n",
      "864 [D loss: 0.265424, acc: 83.59%, op_acc: 65.62%] [G loss: 1.357945]\n",
      "865 [D loss: 0.231601, acc: 88.28%, op_acc: 60.16%] [G loss: 1.300011]\n",
      "866 [D loss: 0.242003, acc: 89.84%, op_acc: 69.53%] [G loss: 1.332864]\n",
      "867 [D loss: 0.239808, acc: 89.06%, op_acc: 62.50%] [G loss: 1.252452]\n",
      "868 [D loss: 0.229524, acc: 89.06%, op_acc: 67.19%] [G loss: 1.324560]\n",
      "869 [D loss: 0.225511, acc: 90.62%, op_acc: 64.84%] [G loss: 1.323346]\n",
      "870 [D loss: 0.234658, acc: 86.72%, op_acc: 70.31%] [G loss: 1.287816]\n",
      "Epoch: 870, F1: 0.64865, F1P: 87\n",
      "[[28406    26]\n",
      " [   13    36]]\n",
      "86.875\n",
      "871 [D loss: 0.235061, acc: 87.50%, op_acc: 69.53%] [G loss: 1.373078]\n",
      "872 [D loss: 0.244899, acc: 86.72%, op_acc: 60.16%] [G loss: 1.394121]\n",
      "873 [D loss: 0.223107, acc: 86.72%, op_acc: 61.72%] [G loss: 1.259121]\n",
      "874 [D loss: 0.239410, acc: 86.72%, op_acc: 64.06%] [G loss: 1.278370]\n",
      "875 [D loss: 0.241790, acc: 85.16%, op_acc: 64.84%] [G loss: 1.374253]\n",
      "876 [D loss: 0.239315, acc: 88.28%, op_acc: 66.41%] [G loss: 1.346316]\n",
      "877 [D loss: 0.233009, acc: 86.72%, op_acc: 57.81%] [G loss: 1.360949]\n",
      "878 [D loss: 0.233271, acc: 85.94%, op_acc: 64.84%] [G loss: 1.299202]\n",
      "879 [D loss: 0.230993, acc: 89.84%, op_acc: 60.16%] [G loss: 1.302886]\n",
      "880 [D loss: 0.233559, acc: 87.50%, op_acc: 70.31%] [G loss: 1.307403]\n",
      "Epoch: 880, F1: 0.66055, F1P: 88\n",
      "[[28408    24]\n",
      " [   13    36]]\n",
      "87.109375\n",
      "881 [D loss: 0.238002, acc: 88.28%, op_acc: 67.97%] [G loss: 1.259784]\n",
      "882 [D loss: 0.235326, acc: 85.94%, op_acc: 64.06%] [G loss: 1.361124]\n",
      "883 [D loss: 0.232472, acc: 89.84%, op_acc: 61.72%] [G loss: 1.339336]\n",
      "884 [D loss: 0.244133, acc: 87.50%, op_acc: 64.06%] [G loss: 1.353705]\n",
      "885 [D loss: 0.239702, acc: 86.72%, op_acc: 61.72%] [G loss: 1.357705]\n",
      "886 [D loss: 0.233831, acc: 87.50%, op_acc: 64.84%] [G loss: 1.318576]\n",
      "887 [D loss: 0.228721, acc: 90.62%, op_acc: 66.41%] [G loss: 1.299110]\n",
      "888 [D loss: 0.221456, acc: 89.84%, op_acc: 68.75%] [G loss: 1.367774]\n",
      "889 [D loss: 0.234574, acc: 86.72%, op_acc: 66.41%] [G loss: 1.365010]\n",
      "890 [D loss: 0.233495, acc: 85.16%, op_acc: 67.97%] [G loss: 1.293582]\n",
      "Epoch: 890, F1: 0.68627, F1P: 89\n",
      "[[28414    18]\n",
      " [   14    35]]\n",
      "87.8125\n",
      "891 [D loss: 0.229497, acc: 92.19%, op_acc: 65.62%] [G loss: 1.263737]\n",
      "892 [D loss: 0.217192, acc: 94.53%, op_acc: 69.53%] [G loss: 1.333264]\n",
      "893 [D loss: 0.233308, acc: 89.84%, op_acc: 64.84%] [G loss: 1.366263]\n",
      "894 [D loss: 0.231532, acc: 89.84%, op_acc: 60.94%] [G loss: 1.316370]\n",
      "895 [D loss: 0.244067, acc: 87.50%, op_acc: 68.75%] [G loss: 1.320239]\n",
      "896 [D loss: 0.230047, acc: 93.75%, op_acc: 67.97%] [G loss: 1.377215]\n",
      "897 [D loss: 0.238360, acc: 89.84%, op_acc: 68.75%] [G loss: 1.307181]\n",
      "898 [D loss: 0.233112, acc: 88.28%, op_acc: 66.41%] [G loss: 1.388213]\n",
      "899 [D loss: 0.223326, acc: 89.84%, op_acc: 68.75%] [G loss: 1.353925]\n",
      "900 [D loss: 0.229748, acc: 91.41%, op_acc: 65.62%] [G loss: 1.402059]\n",
      "Epoch: 900, F1: 0.71579, F1P: 90\n",
      "[[28420    12]\n",
      " [   15    34]]\n",
      "90.703125\n",
      "901 [D loss: 0.240279, acc: 89.84%, op_acc: 67.19%] [G loss: 1.294144]\n",
      "902 [D loss: 0.234050, acc: 90.62%, op_acc: 67.97%] [G loss: 1.332721]\n",
      "903 [D loss: 0.230259, acc: 89.06%, op_acc: 59.38%] [G loss: 1.392864]\n",
      "904 [D loss: 0.220047, acc: 88.28%, op_acc: 54.69%] [G loss: 1.354976]\n",
      "905 [D loss: 0.227634, acc: 87.50%, op_acc: 64.06%] [G loss: 1.281550]\n",
      "906 [D loss: 0.221759, acc: 89.06%, op_acc: 60.94%] [G loss: 1.329777]\n",
      "907 [D loss: 0.232402, acc: 88.28%, op_acc: 60.16%] [G loss: 1.341200]\n",
      "908 [D loss: 0.228310, acc: 90.62%, op_acc: 66.41%] [G loss: 1.394511]\n",
      "909 [D loss: 0.236026, acc: 89.84%, op_acc: 63.28%] [G loss: 1.324906]\n",
      "910 [D loss: 0.226154, acc: 90.62%, op_acc: 72.66%] [G loss: 1.332624]\n",
      "Epoch: 910, F1: 0.69565, F1P: 91\n",
      "[[28421    11]\n",
      " [   17    32]]\n",
      "89.375\n",
      "911 [D loss: 0.233116, acc: 90.62%, op_acc: 60.16%] [G loss: 1.265934]\n",
      "912 [D loss: 0.247673, acc: 83.59%, op_acc: 59.38%] [G loss: 1.386031]\n",
      "913 [D loss: 0.239678, acc: 86.72%, op_acc: 68.75%] [G loss: 1.348888]\n",
      "914 [D loss: 0.224851, acc: 90.62%, op_acc: 68.75%] [G loss: 1.372872]\n",
      "915 [D loss: 0.220798, acc: 92.97%, op_acc: 64.84%] [G loss: 1.362170]\n",
      "916 [D loss: 0.231301, acc: 89.84%, op_acc: 65.62%] [G loss: 1.371141]\n",
      "917 [D loss: 0.226310, acc: 89.06%, op_acc: 60.94%] [G loss: 1.379955]\n",
      "918 [D loss: 0.250948, acc: 88.28%, op_acc: 67.19%] [G loss: 1.352948]\n",
      "919 [D loss: 0.233440, acc: 89.06%, op_acc: 71.09%] [G loss: 1.383066]\n",
      "920 [D loss: 0.233988, acc: 87.50%, op_acc: 55.47%] [G loss: 1.394548]\n",
      "Epoch: 920, F1: 0.68132, F1P: 92\n",
      "[[28421    11]\n",
      " [   18    31]]\n",
      "88.828125\n",
      "921 [D loss: 0.235525, acc: 89.84%, op_acc: 65.62%] [G loss: 1.312403]\n",
      "922 [D loss: 0.231808, acc: 87.50%, op_acc: 64.06%] [G loss: 1.409811]\n",
      "923 [D loss: 0.224823, acc: 92.97%, op_acc: 60.94%] [G loss: 1.366438]\n",
      "924 [D loss: 0.217095, acc: 92.97%, op_acc: 67.19%] [G loss: 1.379124]\n",
      "925 [D loss: 0.222752, acc: 89.06%, op_acc: 69.53%] [G loss: 1.346935]\n",
      "926 [D loss: 0.228409, acc: 89.84%, op_acc: 70.31%] [G loss: 1.370004]\n",
      "927 [D loss: 0.220856, acc: 94.53%, op_acc: 67.97%] [G loss: 1.369342]\n",
      "928 [D loss: 0.216167, acc: 91.41%, op_acc: 69.53%] [G loss: 1.351696]\n",
      "929 [D loss: 0.211816, acc: 89.84%, op_acc: 74.22%] [G loss: 1.319202]\n",
      "930 [D loss: 0.237915, acc: 89.84%, op_acc: 64.06%] [G loss: 1.429667]\n",
      "Epoch: 930, F1: 0.68889, F1P: 93\n",
      "[[28422    10]\n",
      " [   18    31]]\n",
      "90.78125\n",
      "931 [D loss: 0.222321, acc: 87.50%, op_acc: 65.62%] [G loss: 1.371552]\n",
      "932 [D loss: 0.245886, acc: 85.16%, op_acc: 66.41%] [G loss: 1.369540]\n",
      "933 [D loss: 0.218547, acc: 89.06%, op_acc: 66.41%] [G loss: 1.431930]\n",
      "934 [D loss: 0.243504, acc: 82.03%, op_acc: 69.53%] [G loss: 1.437237]\n",
      "935 [D loss: 0.217634, acc: 92.19%, op_acc: 68.75%] [G loss: 1.339088]\n",
      "936 [D loss: 0.246529, acc: 85.94%, op_acc: 67.97%] [G loss: 1.408524]\n",
      "937 [D loss: 0.238315, acc: 86.72%, op_acc: 65.62%] [G loss: 1.394755]\n",
      "938 [D loss: 0.230541, acc: 85.16%, op_acc: 64.06%] [G loss: 1.287075]\n",
      "939 [D loss: 0.228992, acc: 84.38%, op_acc: 61.72%] [G loss: 1.440044]\n",
      "940 [D loss: 0.231587, acc: 89.84%, op_acc: 67.19%] [G loss: 1.394628]\n",
      "Epoch: 940, F1: 0.68889, F1P: 94\n",
      "[[28422    10]\n",
      " [   18    31]]\n",
      "86.796875\n",
      "941 [D loss: 0.221833, acc: 92.19%, op_acc: 64.84%] [G loss: 1.347618]\n",
      "942 [D loss: 0.220103, acc: 89.84%, op_acc: 64.84%] [G loss: 1.359021]\n",
      "943 [D loss: 0.221293, acc: 86.72%, op_acc: 67.97%] [G loss: 1.370540]\n",
      "944 [D loss: 0.228418, acc: 90.62%, op_acc: 70.31%] [G loss: 1.354920]\n",
      "945 [D loss: 0.214122, acc: 91.41%, op_acc: 67.97%] [G loss: 1.320025]\n",
      "946 [D loss: 0.235731, acc: 82.81%, op_acc: 70.31%] [G loss: 1.431686]\n",
      "947 [D loss: 0.236652, acc: 87.50%, op_acc: 64.06%] [G loss: 1.382069]\n",
      "948 [D loss: 0.222178, acc: 92.19%, op_acc: 70.31%] [G loss: 1.416240]\n",
      "949 [D loss: 0.219791, acc: 92.19%, op_acc: 62.50%] [G loss: 1.400834]\n",
      "950 [D loss: 0.227326, acc: 85.94%, op_acc: 64.84%] [G loss: 1.475914]\n",
      "Epoch: 950, F1: 0.67442, F1P: 95\n",
      "[[28424     8]\n",
      " [   20    29]]\n",
      "89.140625\n",
      "951 [D loss: 0.217796, acc: 93.75%, op_acc: 70.31%] [G loss: 1.338153]\n",
      "952 [D loss: 0.211129, acc: 92.97%, op_acc: 74.22%] [G loss: 1.417069]\n",
      "953 [D loss: 0.229993, acc: 89.84%, op_acc: 58.59%] [G loss: 1.360055]\n",
      "954 [D loss: 0.222674, acc: 91.41%, op_acc: 63.28%] [G loss: 1.400180]\n",
      "955 [D loss: 0.230532, acc: 88.28%, op_acc: 67.97%] [G loss: 1.370319]\n",
      "956 [D loss: 0.224148, acc: 89.06%, op_acc: 58.59%] [G loss: 1.417571]\n",
      "957 [D loss: 0.208242, acc: 92.19%, op_acc: 70.31%] [G loss: 1.466225]\n",
      "958 [D loss: 0.223888, acc: 91.41%, op_acc: 67.97%] [G loss: 1.322866]\n",
      "959 [D loss: 0.221592, acc: 91.41%, op_acc: 68.75%] [G loss: 1.423019]\n",
      "960 [D loss: 0.231305, acc: 90.62%, op_acc: 64.06%] [G loss: 1.384995]\n",
      "Epoch: 960, F1: 0.65882, F1P: 96\n",
      "[[28424     8]\n",
      " [   21    28]]\n",
      "91.09375\n",
      "961 [D loss: 0.229261, acc: 91.41%, op_acc: 62.50%] [G loss: 1.294637]\n",
      "962 [D loss: 0.228118, acc: 85.16%, op_acc: 64.06%] [G loss: 1.409657]\n",
      "963 [D loss: 0.222433, acc: 89.84%, op_acc: 67.97%] [G loss: 1.397128]\n",
      "964 [D loss: 0.221599, acc: 89.84%, op_acc: 64.06%] [G loss: 1.404570]\n",
      "965 [D loss: 0.224595, acc: 89.84%, op_acc: 64.06%] [G loss: 1.412211]\n",
      "966 [D loss: 0.219692, acc: 91.41%, op_acc: 67.19%] [G loss: 1.404229]\n",
      "967 [D loss: 0.223836, acc: 89.06%, op_acc: 66.41%] [G loss: 1.335985]\n",
      "968 [D loss: 0.234160, acc: 86.72%, op_acc: 60.16%] [G loss: 1.392610]\n",
      "969 [D loss: 0.203955, acc: 96.09%, op_acc: 67.19%] [G loss: 1.371094]\n",
      "970 [D loss: 0.219303, acc: 92.19%, op_acc: 71.88%] [G loss: 1.363413]\n",
      "Epoch: 970, F1: 0.65882, F1P: 97\n",
      "[[28424     8]\n",
      " [   21    28]]\n",
      "90.15625\n",
      "971 [D loss: 0.228570, acc: 86.72%, op_acc: 60.94%] [G loss: 1.394993]\n",
      "972 [D loss: 0.226474, acc: 87.50%, op_acc: 66.41%] [G loss: 1.467958]\n",
      "973 [D loss: 0.222579, acc: 90.62%, op_acc: 67.97%] [G loss: 1.423631]\n",
      "974 [D loss: 0.221396, acc: 89.84%, op_acc: 64.84%] [G loss: 1.499802]\n",
      "975 [D loss: 0.240743, acc: 85.16%, op_acc: 67.97%] [G loss: 1.374782]\n",
      "976 [D loss: 0.219062, acc: 88.28%, op_acc: 63.28%] [G loss: 1.434173]\n",
      "977 [D loss: 0.230103, acc: 91.41%, op_acc: 60.16%] [G loss: 1.422106]\n",
      "978 [D loss: 0.224787, acc: 84.38%, op_acc: 67.19%] [G loss: 1.372086]\n",
      "979 [D loss: 0.210870, acc: 92.97%, op_acc: 60.94%] [G loss: 1.390628]\n",
      "980 [D loss: 0.239094, acc: 86.72%, op_acc: 67.19%] [G loss: 1.401190]\n",
      "Epoch: 980, F1: 0.66667, F1P: 98\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "88.359375\n",
      "981 [D loss: 0.220231, acc: 89.06%, op_acc: 67.97%] [G loss: 1.326274]\n",
      "982 [D loss: 0.223923, acc: 87.50%, op_acc: 69.53%] [G loss: 1.391609]\n",
      "983 [D loss: 0.217419, acc: 92.97%, op_acc: 67.97%] [G loss: 1.431610]\n",
      "984 [D loss: 0.214832, acc: 94.53%, op_acc: 67.97%] [G loss: 1.363993]\n",
      "985 [D loss: 0.217679, acc: 91.41%, op_acc: 67.97%] [G loss: 1.323210]\n",
      "986 [D loss: 0.219238, acc: 92.19%, op_acc: 71.09%] [G loss: 1.432479]\n",
      "987 [D loss: 0.227475, acc: 84.38%, op_acc: 65.62%] [G loss: 1.349477]\n",
      "988 [D loss: 0.223228, acc: 87.50%, op_acc: 66.41%] [G loss: 1.407969]\n",
      "989 [D loss: 0.229848, acc: 87.50%, op_acc: 62.50%] [G loss: 1.424835]\n",
      "990 [D loss: 0.247162, acc: 80.47%, op_acc: 64.06%] [G loss: 1.404307]\n",
      "Epoch: 990, F1: 0.67470, F1P: 99\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "88.75\n",
      "991 [D loss: 0.216549, acc: 86.72%, op_acc: 64.06%] [G loss: 1.391614]\n",
      "992 [D loss: 0.220487, acc: 88.28%, op_acc: 68.75%] [G loss: 1.440454]\n",
      "993 [D loss: 0.223932, acc: 89.84%, op_acc: 69.53%] [G loss: 1.389778]\n",
      "994 [D loss: 0.217067, acc: 92.19%, op_acc: 70.31%] [G loss: 1.350045]\n",
      "995 [D loss: 0.231777, acc: 85.94%, op_acc: 67.19%] [G loss: 1.339601]\n",
      "996 [D loss: 0.214111, acc: 92.97%, op_acc: 69.53%] [G loss: 1.487481]\n",
      "997 [D loss: 0.222310, acc: 88.28%, op_acc: 71.88%] [G loss: 1.289851]\n",
      "998 [D loss: 0.220406, acc: 89.06%, op_acc: 69.53%] [G loss: 1.387983]\n",
      "999 [D loss: 0.217296, acc: 90.62%, op_acc: 64.06%] [G loss: 1.364051]\n",
      "1000 [D loss: 0.206042, acc: 91.41%, op_acc: 63.28%] [G loss: 1.394602]\n",
      "Epoch: 1000, F1: 0.67470, F1P: 100\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.53125\n",
      "1001 [D loss: 0.224230, acc: 89.06%, op_acc: 67.19%] [G loss: 1.377766]\n",
      "1002 [D loss: 0.231057, acc: 86.72%, op_acc: 57.81%] [G loss: 1.405529]\n",
      "1003 [D loss: 0.233394, acc: 88.28%, op_acc: 67.19%] [G loss: 1.348080]\n",
      "1004 [D loss: 0.231073, acc: 87.50%, op_acc: 69.53%] [G loss: 1.317310]\n",
      "1005 [D loss: 0.227016, acc: 86.72%, op_acc: 61.72%] [G loss: 1.392532]\n",
      "1006 [D loss: 0.235363, acc: 85.16%, op_acc: 61.72%] [G loss: 1.419726]\n",
      "1007 [D loss: 0.209977, acc: 87.50%, op_acc: 66.41%] [G loss: 1.355983]\n",
      "1008 [D loss: 0.231348, acc: 88.28%, op_acc: 58.59%] [G loss: 1.380187]\n",
      "1009 [D loss: 0.241134, acc: 86.72%, op_acc: 59.38%] [G loss: 1.301365]\n",
      "1010 [D loss: 0.246112, acc: 82.81%, op_acc: 57.81%] [G loss: 1.385065]\n",
      "Epoch: 1010, F1: 0.67470, F1P: 101\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "86.875\n",
      "1011 [D loss: 0.224074, acc: 87.50%, op_acc: 64.84%] [G loss: 1.413261]\n",
      "1012 [D loss: 0.219980, acc: 89.84%, op_acc: 65.62%] [G loss: 1.386257]\n",
      "1013 [D loss: 0.218576, acc: 89.06%, op_acc: 71.88%] [G loss: 1.386192]\n",
      "1014 [D loss: 0.230602, acc: 89.06%, op_acc: 67.97%] [G loss: 1.432852]\n",
      "1015 [D loss: 0.232065, acc: 89.06%, op_acc: 65.62%] [G loss: 1.463481]\n",
      "1016 [D loss: 0.219519, acc: 89.84%, op_acc: 65.62%] [G loss: 1.465721]\n",
      "1017 [D loss: 0.227840, acc: 90.62%, op_acc: 61.72%] [G loss: 1.409529]\n",
      "1018 [D loss: 0.236554, acc: 89.84%, op_acc: 66.41%] [G loss: 1.400759]\n",
      "1019 [D loss: 0.214081, acc: 89.06%, op_acc: 70.31%] [G loss: 1.330781]\n",
      "1020 [D loss: 0.220022, acc: 91.41%, op_acc: 71.09%] [G loss: 1.375637]\n",
      "Epoch: 1020, F1: 0.67470, F1P: 102\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.53125\n",
      "1021 [D loss: 0.215401, acc: 89.84%, op_acc: 60.94%] [G loss: 1.351718]\n",
      "1022 [D loss: 0.212579, acc: 93.75%, op_acc: 62.50%] [G loss: 1.442168]\n",
      "1023 [D loss: 0.219666, acc: 90.62%, op_acc: 70.31%] [G loss: 1.414650]\n",
      "1024 [D loss: 0.231529, acc: 86.72%, op_acc: 68.75%] [G loss: 1.450536]\n",
      "1025 [D loss: 0.214809, acc: 89.84%, op_acc: 71.88%] [G loss: 1.376694]\n",
      "1026 [D loss: 0.223717, acc: 89.06%, op_acc: 61.72%] [G loss: 1.469588]\n",
      "1027 [D loss: 0.223895, acc: 84.38%, op_acc: 69.53%] [G loss: 1.430778]\n",
      "1028 [D loss: 0.224800, acc: 91.41%, op_acc: 61.72%] [G loss: 1.481617]\n",
      "1029 [D loss: 0.209105, acc: 91.41%, op_acc: 73.44%] [G loss: 1.427487]\n",
      "1030 [D loss: 0.221720, acc: 89.84%, op_acc: 64.84%] [G loss: 1.380764]\n",
      "Epoch: 1030, F1: 0.67470, F1P: 103\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.6875\n",
      "1031 [D loss: 0.208745, acc: 92.97%, op_acc: 72.66%] [G loss: 1.379055]\n",
      "1032 [D loss: 0.236443, acc: 87.50%, op_acc: 65.62%] [G loss: 1.431750]\n",
      "1033 [D loss: 0.218683, acc: 91.41%, op_acc: 64.06%] [G loss: 1.349113]\n",
      "1034 [D loss: 0.223346, acc: 89.84%, op_acc: 70.31%] [G loss: 1.355171]\n",
      "1035 [D loss: 0.211754, acc: 85.94%, op_acc: 64.06%] [G loss: 1.432492]\n",
      "1036 [D loss: 0.228603, acc: 87.50%, op_acc: 68.75%] [G loss: 1.417171]\n",
      "1037 [D loss: 0.221922, acc: 85.94%, op_acc: 67.97%] [G loss: 1.421013]\n",
      "1038 [D loss: 0.227580, acc: 89.06%, op_acc: 63.28%] [G loss: 1.389412]\n",
      "1039 [D loss: 0.226833, acc: 92.97%, op_acc: 69.53%] [G loss: 1.396284]\n",
      "1040 [D loss: 0.225196, acc: 89.84%, op_acc: 72.66%] [G loss: 1.446633]\n",
      "Epoch: 1040, F1: 0.67470, F1P: 104\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.296875\n",
      "1041 [D loss: 0.214593, acc: 92.19%, op_acc: 75.78%] [G loss: 1.447864]\n",
      "1042 [D loss: 0.227283, acc: 87.50%, op_acc: 64.84%] [G loss: 1.394682]\n",
      "1043 [D loss: 0.227867, acc: 89.84%, op_acc: 74.22%] [G loss: 1.374753]\n",
      "1044 [D loss: 0.214401, acc: 92.19%, op_acc: 68.75%] [G loss: 1.436151]\n",
      "1045 [D loss: 0.199705, acc: 92.19%, op_acc: 74.22%] [G loss: 1.403813]\n",
      "1046 [D loss: 0.211724, acc: 92.19%, op_acc: 67.97%] [G loss: 1.455969]\n",
      "1047 [D loss: 0.212727, acc: 91.41%, op_acc: 68.75%] [G loss: 1.362559]\n",
      "1048 [D loss: 0.211387, acc: 91.41%, op_acc: 68.75%] [G loss: 1.396662]\n",
      "1049 [D loss: 0.215989, acc: 92.97%, op_acc: 71.09%] [G loss: 1.377997]\n",
      "1050 [D loss: 0.209485, acc: 89.06%, op_acc: 72.66%] [G loss: 1.382852]\n",
      "Epoch: 1050, F1: 0.67470, F1P: 105\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "91.09375\n",
      "1051 [D loss: 0.216220, acc: 89.06%, op_acc: 71.09%] [G loss: 1.449670]\n",
      "1052 [D loss: 0.210821, acc: 90.62%, op_acc: 72.66%] [G loss: 1.387287]\n",
      "1053 [D loss: 0.222394, acc: 87.50%, op_acc: 72.66%] [G loss: 1.508554]\n",
      "1054 [D loss: 0.230038, acc: 85.94%, op_acc: 67.97%] [G loss: 1.483263]\n",
      "1055 [D loss: 0.219382, acc: 88.28%, op_acc: 68.75%] [G loss: 1.386302]\n",
      "1056 [D loss: 0.199616, acc: 95.31%, op_acc: 74.22%] [G loss: 1.492263]\n",
      "1057 [D loss: 0.216145, acc: 94.53%, op_acc: 67.19%] [G loss: 1.398047]\n",
      "1058 [D loss: 0.224790, acc: 87.50%, op_acc: 67.97%] [G loss: 1.433288]\n",
      "1059 [D loss: 0.219401, acc: 89.06%, op_acc: 69.53%] [G loss: 1.458917]\n",
      "1060 [D loss: 0.225122, acc: 87.50%, op_acc: 67.19%] [G loss: 1.339344]\n",
      "Epoch: 1060, F1: 0.67470, F1P: 106\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.53125\n",
      "1061 [D loss: 0.218386, acc: 89.84%, op_acc: 70.31%] [G loss: 1.447642]\n",
      "1062 [D loss: 0.218682, acc: 88.28%, op_acc: 66.41%] [G loss: 1.471121]\n",
      "1063 [D loss: 0.205406, acc: 92.19%, op_acc: 67.97%] [G loss: 1.494056]\n",
      "1064 [D loss: 0.217072, acc: 87.50%, op_acc: 64.84%] [G loss: 1.513668]\n",
      "1065 [D loss: 0.219367, acc: 89.84%, op_acc: 70.31%] [G loss: 1.507689]\n",
      "1066 [D loss: 0.214283, acc: 89.06%, op_acc: 66.41%] [G loss: 1.470498]\n",
      "1067 [D loss: 0.218316, acc: 85.16%, op_acc: 68.75%] [G loss: 1.404849]\n",
      "1068 [D loss: 0.201279, acc: 91.41%, op_acc: 69.53%] [G loss: 1.497229]\n",
      "1069 [D loss: 0.212747, acc: 90.62%, op_acc: 78.91%] [G loss: 1.377994]\n",
      "1070 [D loss: 0.217095, acc: 90.62%, op_acc: 74.22%] [G loss: 1.358834]\n",
      "Epoch: 1070, F1: 0.67470, F1P: 107\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.453125\n",
      "1071 [D loss: 0.206809, acc: 94.53%, op_acc: 71.09%] [G loss: 1.425836]\n",
      "1072 [D loss: 0.213874, acc: 89.06%, op_acc: 64.84%] [G loss: 1.442013]\n",
      "1073 [D loss: 0.210454, acc: 89.84%, op_acc: 73.44%] [G loss: 1.429363]\n",
      "1074 [D loss: 0.215673, acc: 92.97%, op_acc: 64.06%] [G loss: 1.425579]\n",
      "1075 [D loss: 0.208034, acc: 91.41%, op_acc: 68.75%] [G loss: 1.516306]\n",
      "1076 [D loss: 0.214142, acc: 89.06%, op_acc: 64.06%] [G loss: 1.472580]\n",
      "1077 [D loss: 0.203748, acc: 92.97%, op_acc: 67.97%] [G loss: 1.407293]\n",
      "1078 [D loss: 0.207912, acc: 92.97%, op_acc: 74.22%] [G loss: 1.523766]\n",
      "1079 [D loss: 0.208796, acc: 89.84%, op_acc: 72.66%] [G loss: 1.446470]\n",
      "1080 [D loss: 0.220509, acc: 89.84%, op_acc: 69.53%] [G loss: 1.420020]\n",
      "Epoch: 1080, F1: 0.65854, F1P: 108\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "91.25\n",
      "1081 [D loss: 0.208916, acc: 91.41%, op_acc: 63.28%] [G loss: 1.460048]\n",
      "1082 [D loss: 0.214772, acc: 88.28%, op_acc: 69.53%] [G loss: 1.437501]\n",
      "1083 [D loss: 0.217789, acc: 89.84%, op_acc: 64.84%] [G loss: 1.414092]\n",
      "1084 [D loss: 0.242368, acc: 83.59%, op_acc: 61.72%] [G loss: 1.460523]\n",
      "1085 [D loss: 0.197768, acc: 89.06%, op_acc: 68.75%] [G loss: 1.466197]\n",
      "1086 [D loss: 0.207195, acc: 90.62%, op_acc: 75.78%] [G loss: 1.467852]\n",
      "1087 [D loss: 0.215943, acc: 88.28%, op_acc: 67.19%] [G loss: 1.458221]\n",
      "1088 [D loss: 0.208807, acc: 93.75%, op_acc: 67.97%] [G loss: 1.453048]\n",
      "1089 [D loss: 0.210064, acc: 91.41%, op_acc: 71.09%] [G loss: 1.478980]\n",
      "1090 [D loss: 0.202256, acc: 92.19%, op_acc: 69.53%] [G loss: 1.443028]\n",
      "Epoch: 1090, F1: 0.65854, F1P: 109\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "89.84375\n",
      "1091 [D loss: 0.215852, acc: 87.50%, op_acc: 71.88%] [G loss: 1.441587]\n",
      "1092 [D loss: 0.216389, acc: 87.50%, op_acc: 63.28%] [G loss: 1.529320]\n",
      "1093 [D loss: 0.198263, acc: 96.09%, op_acc: 67.97%] [G loss: 1.552779]\n",
      "1094 [D loss: 0.204691, acc: 92.97%, op_acc: 76.56%] [G loss: 1.548867]\n",
      "1095 [D loss: 0.202348, acc: 96.09%, op_acc: 71.88%] [G loss: 1.380099]\n",
      "1096 [D loss: 0.194067, acc: 92.97%, op_acc: 67.19%] [G loss: 1.463732]\n",
      "1097 [D loss: 0.212368, acc: 91.41%, op_acc: 70.31%] [G loss: 1.476147]\n",
      "1098 [D loss: 0.212821, acc: 89.06%, op_acc: 60.94%] [G loss: 1.435131]\n",
      "1099 [D loss: 0.216191, acc: 92.97%, op_acc: 67.97%] [G loss: 1.437817]\n",
      "1100 [D loss: 0.210221, acc: 92.97%, op_acc: 65.62%] [G loss: 1.473773]\n",
      "Epoch: 1100, F1: 0.67470, F1P: 110\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "91.953125\n",
      "1101 [D loss: 0.212327, acc: 90.62%, op_acc: 60.16%] [G loss: 1.434452]\n",
      "1102 [D loss: 0.212276, acc: 90.62%, op_acc: 60.16%] [G loss: 1.432487]\n",
      "1103 [D loss: 0.217162, acc: 89.84%, op_acc: 68.75%] [G loss: 1.491910]\n",
      "1104 [D loss: 0.222333, acc: 92.19%, op_acc: 69.53%] [G loss: 1.527667]\n",
      "1105 [D loss: 0.201867, acc: 93.75%, op_acc: 71.88%] [G loss: 1.417048]\n",
      "1106 [D loss: 0.201294, acc: 94.53%, op_acc: 76.56%] [G loss: 1.525206]\n",
      "1107 [D loss: 0.198077, acc: 91.41%, op_acc: 74.22%] [G loss: 1.484794]\n",
      "1108 [D loss: 0.195814, acc: 91.41%, op_acc: 66.41%] [G loss: 1.470590]\n",
      "1109 [D loss: 0.209593, acc: 90.62%, op_acc: 66.41%] [G loss: 1.508376]\n",
      "1110 [D loss: 0.207796, acc: 94.53%, op_acc: 71.09%] [G loss: 1.559332]\n",
      "Epoch: 1110, F1: 0.65854, F1P: 111\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "91.953125\n",
      "1111 [D loss: 0.210243, acc: 91.41%, op_acc: 70.31%] [G loss: 1.545253]\n",
      "1112 [D loss: 0.199653, acc: 92.19%, op_acc: 68.75%] [G loss: 1.488427]\n",
      "1113 [D loss: 0.192755, acc: 91.41%, op_acc: 70.31%] [G loss: 1.530848]\n",
      "1114 [D loss: 0.200450, acc: 92.19%, op_acc: 68.75%] [G loss: 1.611002]\n",
      "1115 [D loss: 0.205733, acc: 94.53%, op_acc: 67.19%] [G loss: 1.459221]\n",
      "1116 [D loss: 0.192641, acc: 92.97%, op_acc: 70.31%] [G loss: 1.547933]\n",
      "1117 [D loss: 0.202867, acc: 91.41%, op_acc: 65.62%] [G loss: 1.553217]\n",
      "1118 [D loss: 0.205396, acc: 92.97%, op_acc: 71.88%] [G loss: 1.556515]\n",
      "1119 [D loss: 0.211749, acc: 92.19%, op_acc: 64.84%] [G loss: 1.562154]\n",
      "1120 [D loss: 0.204584, acc: 86.72%, op_acc: 67.19%] [G loss: 1.509073]\n",
      "Epoch: 1120, F1: 0.65854, F1P: 112\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "91.796875\n",
      "1121 [D loss: 0.200816, acc: 94.53%, op_acc: 72.66%] [G loss: 1.594200]\n",
      "1122 [D loss: 0.202046, acc: 91.41%, op_acc: 69.53%] [G loss: 1.467330]\n",
      "1123 [D loss: 0.199908, acc: 94.53%, op_acc: 64.84%] [G loss: 1.492569]\n",
      "1124 [D loss: 0.220527, acc: 89.06%, op_acc: 66.41%] [G loss: 1.413501]\n",
      "1125 [D loss: 0.207811, acc: 91.41%, op_acc: 69.53%] [G loss: 1.501947]\n",
      "1126 [D loss: 0.203810, acc: 96.09%, op_acc: 73.44%] [G loss: 1.521753]\n",
      "1127 [D loss: 0.195689, acc: 91.41%, op_acc: 67.19%] [G loss: 1.605349]\n",
      "1128 [D loss: 0.194818, acc: 94.53%, op_acc: 62.50%] [G loss: 1.596164]\n",
      "1129 [D loss: 0.190835, acc: 90.62%, op_acc: 71.09%] [G loss: 1.499845]\n",
      "1130 [D loss: 0.206006, acc: 89.06%, op_acc: 77.34%] [G loss: 1.553783]\n",
      "Epoch: 1130, F1: 0.65060, F1P: 113\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.265625\n",
      "1131 [D loss: 0.203954, acc: 91.41%, op_acc: 72.66%] [G loss: 1.567313]\n",
      "1132 [D loss: 0.219359, acc: 87.50%, op_acc: 64.84%] [G loss: 1.565489]\n",
      "1133 [D loss: 0.214069, acc: 92.19%, op_acc: 64.84%] [G loss: 1.473933]\n",
      "1134 [D loss: 0.201937, acc: 92.19%, op_acc: 66.41%] [G loss: 1.589507]\n",
      "1135 [D loss: 0.210539, acc: 85.94%, op_acc: 71.88%] [G loss: 1.463994]\n",
      "1136 [D loss: 0.213868, acc: 92.19%, op_acc: 70.31%] [G loss: 1.564573]\n",
      "1137 [D loss: 0.203975, acc: 95.31%, op_acc: 73.44%] [G loss: 1.447697]\n",
      "1138 [D loss: 0.200774, acc: 97.66%, op_acc: 58.59%] [G loss: 1.500654]\n",
      "1139 [D loss: 0.218961, acc: 90.62%, op_acc: 66.41%] [G loss: 1.501945]\n",
      "1140 [D loss: 0.188491, acc: 92.97%, op_acc: 73.44%] [G loss: 1.479186]\n",
      "Epoch: 1140, F1: 0.66667, F1P: 114\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "91.796875\n",
      "1141 [D loss: 0.203926, acc: 89.84%, op_acc: 69.53%] [G loss: 1.536382]\n",
      "1142 [D loss: 0.216163, acc: 91.41%, op_acc: 71.09%] [G loss: 1.609886]\n",
      "1143 [D loss: 0.216811, acc: 89.06%, op_acc: 62.50%] [G loss: 1.596808]\n",
      "1144 [D loss: 0.201247, acc: 89.84%, op_acc: 64.06%] [G loss: 1.537984]\n",
      "1145 [D loss: 0.204661, acc: 92.97%, op_acc: 64.06%] [G loss: 1.598431]\n",
      "1146 [D loss: 0.190006, acc: 92.19%, op_acc: 69.53%] [G loss: 1.608964]\n",
      "1147 [D loss: 0.189389, acc: 96.88%, op_acc: 68.75%] [G loss: 1.506203]\n",
      "1148 [D loss: 0.197362, acc: 92.19%, op_acc: 75.00%] [G loss: 1.551433]\n",
      "1149 [D loss: 0.210028, acc: 87.50%, op_acc: 68.75%] [G loss: 1.617535]\n",
      "1150 [D loss: 0.205799, acc: 91.41%, op_acc: 71.88%] [G loss: 1.476547]\n",
      "Epoch: 1150, F1: 0.65060, F1P: 115\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "91.328125\n",
      "1151 [D loss: 0.196893, acc: 91.41%, op_acc: 67.97%] [G loss: 1.592309]\n",
      "1152 [D loss: 0.206752, acc: 87.50%, op_acc: 67.97%] [G loss: 1.565675]\n",
      "1153 [D loss: 0.193182, acc: 91.41%, op_acc: 71.09%] [G loss: 1.594074]\n",
      "1154 [D loss: 0.196568, acc: 94.53%, op_acc: 75.00%] [G loss: 1.511485]\n",
      "1155 [D loss: 0.205038, acc: 88.28%, op_acc: 74.22%] [G loss: 1.549567]\n",
      "1156 [D loss: 0.184166, acc: 94.53%, op_acc: 70.31%] [G loss: 1.508668]\n",
      "1157 [D loss: 0.187876, acc: 95.31%, op_acc: 71.88%] [G loss: 1.538234]\n",
      "1158 [D loss: 0.203107, acc: 91.41%, op_acc: 70.31%] [G loss: 1.573118]\n",
      "1159 [D loss: 0.189827, acc: 95.31%, op_acc: 68.75%] [G loss: 1.544765]\n",
      "1160 [D loss: 0.189476, acc: 93.75%, op_acc: 61.72%] [G loss: 1.540919]\n",
      "Epoch: 1160, F1: 0.65060, F1P: 116\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.34375\n",
      "1161 [D loss: 0.191614, acc: 95.31%, op_acc: 68.75%] [G loss: 1.586159]\n",
      "1162 [D loss: 0.193390, acc: 92.19%, op_acc: 69.53%] [G loss: 1.524923]\n",
      "1163 [D loss: 0.184817, acc: 95.31%, op_acc: 75.00%] [G loss: 1.653082]\n",
      "1164 [D loss: 0.189902, acc: 92.19%, op_acc: 64.84%] [G loss: 1.573895]\n",
      "1165 [D loss: 0.184800, acc: 93.75%, op_acc: 76.56%] [G loss: 1.696083]\n",
      "1166 [D loss: 0.206647, acc: 91.41%, op_acc: 66.41%] [G loss: 1.657899]\n",
      "1167 [D loss: 0.195654, acc: 90.62%, op_acc: 66.41%] [G loss: 1.628762]\n",
      "1168 [D loss: 0.193383, acc: 92.19%, op_acc: 67.19%] [G loss: 1.611763]\n",
      "1169 [D loss: 0.189825, acc: 92.97%, op_acc: 71.09%] [G loss: 1.604561]\n",
      "1170 [D loss: 0.191173, acc: 91.41%, op_acc: 67.97%] [G loss: 1.606912]\n",
      "Epoch: 1170, F1: 0.65060, F1P: 117\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.734375\n",
      "1171 [D loss: 0.196450, acc: 90.62%, op_acc: 76.56%] [G loss: 1.538801]\n",
      "1172 [D loss: 0.190750, acc: 93.75%, op_acc: 74.22%] [G loss: 1.620570]\n",
      "1173 [D loss: 0.198029, acc: 92.97%, op_acc: 70.31%] [G loss: 1.671697]\n",
      "1174 [D loss: 0.197758, acc: 90.62%, op_acc: 70.31%] [G loss: 1.625612]\n",
      "1175 [D loss: 0.184358, acc: 92.97%, op_acc: 70.31%] [G loss: 1.608373]\n",
      "1176 [D loss: 0.180163, acc: 93.75%, op_acc: 79.69%] [G loss: 1.664032]\n",
      "1177 [D loss: 0.191864, acc: 93.75%, op_acc: 69.53%] [G loss: 1.532213]\n",
      "1178 [D loss: 0.197222, acc: 92.97%, op_acc: 75.00%] [G loss: 1.608723]\n",
      "1179 [D loss: 0.210976, acc: 89.84%, op_acc: 66.41%] [G loss: 1.626655]\n",
      "1180 [D loss: 0.185653, acc: 93.75%, op_acc: 67.19%] [G loss: 1.598831]\n",
      "Epoch: 1180, F1: 0.65060, F1P: 118\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.5\n",
      "1181 [D loss: 0.183212, acc: 91.41%, op_acc: 71.09%] [G loss: 1.662503]\n",
      "1182 [D loss: 0.186366, acc: 92.97%, op_acc: 69.53%] [G loss: 1.579644]\n",
      "1183 [D loss: 0.200875, acc: 90.62%, op_acc: 66.41%] [G loss: 1.558464]\n",
      "1184 [D loss: 0.183907, acc: 92.97%, op_acc: 71.88%] [G loss: 1.561967]\n",
      "1185 [D loss: 0.184522, acc: 94.53%, op_acc: 66.41%] [G loss: 1.608183]\n",
      "1186 [D loss: 0.180740, acc: 98.44%, op_acc: 70.31%] [G loss: 1.595120]\n",
      "1187 [D loss: 0.190069, acc: 95.31%, op_acc: 66.41%] [G loss: 1.593630]\n",
      "1188 [D loss: 0.193456, acc: 91.41%, op_acc: 68.75%] [G loss: 1.527502]\n",
      "1189 [D loss: 0.199545, acc: 90.62%, op_acc: 75.00%] [G loss: 1.617067]\n",
      "1190 [D loss: 0.199278, acc: 89.06%, op_acc: 67.97%] [G loss: 1.643679]\n",
      "Epoch: 1190, F1: 0.65060, F1P: 119\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.734375\n",
      "1191 [D loss: 0.186052, acc: 93.75%, op_acc: 62.50%] [G loss: 1.659416]\n",
      "1192 [D loss: 0.204774, acc: 89.06%, op_acc: 68.75%] [G loss: 1.704557]\n",
      "1193 [D loss: 0.185180, acc: 92.19%, op_acc: 67.19%] [G loss: 1.675804]\n",
      "1194 [D loss: 0.196098, acc: 94.53%, op_acc: 70.31%] [G loss: 1.676383]\n",
      "1195 [D loss: 0.191304, acc: 93.75%, op_acc: 63.28%] [G loss: 1.639682]\n",
      "1196 [D loss: 0.188245, acc: 95.31%, op_acc: 76.56%] [G loss: 1.616857]\n",
      "1197 [D loss: 0.191025, acc: 95.31%, op_acc: 68.75%] [G loss: 1.619552]\n",
      "1198 [D loss: 0.185526, acc: 92.19%, op_acc: 74.22%] [G loss: 1.589286]\n",
      "1199 [D loss: 0.193634, acc: 89.06%, op_acc: 68.75%] [G loss: 1.641351]\n",
      "1200 [D loss: 0.200765, acc: 92.19%, op_acc: 71.88%] [G loss: 1.681920]\n",
      "Epoch: 1200, F1: 0.65060, F1P: 120\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.734375\n",
      "1201 [D loss: 0.183619, acc: 93.75%, op_acc: 71.88%] [G loss: 1.716944]\n",
      "1202 [D loss: 0.203901, acc: 89.84%, op_acc: 68.75%] [G loss: 1.704966]\n",
      "1203 [D loss: 0.190848, acc: 96.09%, op_acc: 71.88%] [G loss: 1.689435]\n",
      "1204 [D loss: 0.176091, acc: 95.31%, op_acc: 75.78%] [G loss: 1.600805]\n",
      "1205 [D loss: 0.190700, acc: 95.31%, op_acc: 76.56%] [G loss: 1.649983]\n",
      "1206 [D loss: 0.191883, acc: 92.97%, op_acc: 69.53%] [G loss: 1.593173]\n",
      "1207 [D loss: 0.206231, acc: 90.62%, op_acc: 74.22%] [G loss: 1.607202]\n",
      "1208 [D loss: 0.170728, acc: 96.88%, op_acc: 75.00%] [G loss: 1.672407]\n",
      "1209 [D loss: 0.187761, acc: 94.53%, op_acc: 70.31%] [G loss: 1.675621]\n",
      "1210 [D loss: 0.179776, acc: 90.62%, op_acc: 71.09%] [G loss: 1.615842]\n",
      "Epoch: 1210, F1: 0.65060, F1P: 121\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "93.59375\n",
      "1211 [D loss: 0.201827, acc: 89.84%, op_acc: 73.44%] [G loss: 1.545282]\n",
      "1212 [D loss: 0.197001, acc: 91.41%, op_acc: 69.53%] [G loss: 1.625367]\n",
      "1213 [D loss: 0.190865, acc: 92.19%, op_acc: 67.19%] [G loss: 1.667563]\n",
      "1214 [D loss: 0.195789, acc: 92.19%, op_acc: 71.09%] [G loss: 1.618356]\n",
      "1215 [D loss: 0.179172, acc: 92.97%, op_acc: 71.88%] [G loss: 1.600598]\n",
      "1216 [D loss: 0.188413, acc: 96.88%, op_acc: 71.09%] [G loss: 1.653055]\n",
      "1217 [D loss: 0.195439, acc: 91.41%, op_acc: 70.31%] [G loss: 1.721236]\n",
      "1218 [D loss: 0.196764, acc: 92.97%, op_acc: 72.66%] [G loss: 1.668606]\n",
      "1219 [D loss: 0.189002, acc: 96.09%, op_acc: 79.69%] [G loss: 1.662395]\n",
      "1220 [D loss: 0.192371, acc: 91.41%, op_acc: 66.41%] [G loss: 1.640033]\n",
      "Epoch: 1220, F1: 0.65060, F1P: 122\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.734375\n",
      "1221 [D loss: 0.207998, acc: 91.41%, op_acc: 69.53%] [G loss: 1.562162]\n",
      "1222 [D loss: 0.188202, acc: 94.53%, op_acc: 69.53%] [G loss: 1.618322]\n",
      "1223 [D loss: 0.195772, acc: 93.75%, op_acc: 71.88%] [G loss: 1.568589]\n",
      "1224 [D loss: 0.195051, acc: 91.41%, op_acc: 67.19%] [G loss: 1.628892]\n",
      "1225 [D loss: 0.191545, acc: 90.62%, op_acc: 71.88%] [G loss: 1.745943]\n",
      "1226 [D loss: 0.184481, acc: 95.31%, op_acc: 75.78%] [G loss: 1.592809]\n",
      "1227 [D loss: 0.187348, acc: 94.53%, op_acc: 71.09%] [G loss: 1.607655]\n",
      "1228 [D loss: 0.180194, acc: 92.19%, op_acc: 71.88%] [G loss: 1.664239]\n",
      "1229 [D loss: 0.180220, acc: 97.66%, op_acc: 70.31%] [G loss: 1.623248]\n",
      "1230 [D loss: 0.192361, acc: 94.53%, op_acc: 75.78%] [G loss: 1.631604]\n",
      "Epoch: 1230, F1: 0.65060, F1P: 123\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "93.59375\n",
      "1231 [D loss: 0.198191, acc: 89.84%, op_acc: 67.19%] [G loss: 1.710747]\n",
      "1232 [D loss: 0.195740, acc: 88.28%, op_acc: 75.78%] [G loss: 1.620538]\n",
      "1233 [D loss: 0.180816, acc: 90.62%, op_acc: 76.56%] [G loss: 1.543994]\n",
      "1234 [D loss: 0.179204, acc: 93.75%, op_acc: 68.75%] [G loss: 1.639538]\n",
      "1235 [D loss: 0.191122, acc: 92.97%, op_acc: 71.88%] [G loss: 1.598684]\n",
      "1236 [D loss: 0.191409, acc: 92.19%, op_acc: 71.88%] [G loss: 1.664541]\n",
      "1237 [D loss: 0.180580, acc: 95.31%, op_acc: 75.00%] [G loss: 1.595633]\n",
      "1238 [D loss: 0.179985, acc: 96.09%, op_acc: 74.22%] [G loss: 1.639660]\n",
      "1239 [D loss: 0.190865, acc: 93.75%, op_acc: 73.44%] [G loss: 1.667192]\n",
      "1240 [D loss: 0.203281, acc: 89.84%, op_acc: 74.22%] [G loss: 1.692158]\n",
      "Epoch: 1240, F1: 0.65854, F1P: 124\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "92.265625\n",
      "1241 [D loss: 0.196811, acc: 89.84%, op_acc: 75.00%] [G loss: 1.655190]\n",
      "1242 [D loss: 0.177649, acc: 96.09%, op_acc: 73.44%] [G loss: 1.686844]\n",
      "1243 [D loss: 0.191850, acc: 91.41%, op_acc: 76.56%] [G loss: 1.690387]\n",
      "1244 [D loss: 0.199594, acc: 91.41%, op_acc: 75.78%] [G loss: 1.678998]\n",
      "1245 [D loss: 0.184955, acc: 94.53%, op_acc: 82.03%] [G loss: 1.694083]\n",
      "1246 [D loss: 0.180571, acc: 94.53%, op_acc: 75.00%] [G loss: 1.682922]\n",
      "1247 [D loss: 0.187818, acc: 91.41%, op_acc: 69.53%] [G loss: 1.673061]\n",
      "1248 [D loss: 0.191871, acc: 92.97%, op_acc: 72.66%] [G loss: 1.661416]\n",
      "1249 [D loss: 0.199389, acc: 87.50%, op_acc: 71.09%] [G loss: 1.560965]\n",
      "1250 [D loss: 0.182231, acc: 92.97%, op_acc: 71.09%] [G loss: 1.692190]\n",
      "Epoch: 1250, F1: 0.65854, F1P: 125\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "92.265625\n",
      "1251 [D loss: 0.194713, acc: 88.28%, op_acc: 73.44%] [G loss: 1.710272]\n",
      "1252 [D loss: 0.179534, acc: 92.97%, op_acc: 77.34%] [G loss: 1.625525]\n",
      "1253 [D loss: 0.190026, acc: 95.31%, op_acc: 75.78%] [G loss: 1.650230]\n",
      "1254 [D loss: 0.194396, acc: 93.75%, op_acc: 72.66%] [G loss: 1.588770]\n",
      "1255 [D loss: 0.185930, acc: 92.97%, op_acc: 77.34%] [G loss: 1.699394]\n",
      "1256 [D loss: 0.183373, acc: 96.09%, op_acc: 83.59%] [G loss: 1.573334]\n",
      "1257 [D loss: 0.180128, acc: 92.97%, op_acc: 80.47%] [G loss: 1.697912]\n",
      "1258 [D loss: 0.181416, acc: 90.62%, op_acc: 80.47%] [G loss: 1.703050]\n",
      "1259 [D loss: 0.201078, acc: 90.62%, op_acc: 70.31%] [G loss: 1.570810]\n",
      "1260 [D loss: 0.188892, acc: 91.41%, op_acc: 71.88%] [G loss: 1.640976]\n",
      "Epoch: 1260, F1: 0.65854, F1P: 126\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "92.5\n",
      "1261 [D loss: 0.183137, acc: 92.19%, op_acc: 75.78%] [G loss: 1.621626]\n",
      "1262 [D loss: 0.191930, acc: 92.19%, op_acc: 76.56%] [G loss: 1.659529]\n",
      "1263 [D loss: 0.186625, acc: 93.75%, op_acc: 67.19%] [G loss: 1.663543]\n",
      "1264 [D loss: 0.172856, acc: 94.53%, op_acc: 82.03%] [G loss: 1.703286]\n",
      "1265 [D loss: 0.168510, acc: 96.88%, op_acc: 74.22%] [G loss: 1.605426]\n",
      "1266 [D loss: 0.183712, acc: 96.09%, op_acc: 71.88%] [G loss: 1.760300]\n",
      "1267 [D loss: 0.176994, acc: 95.31%, op_acc: 75.00%] [G loss: 1.693751]\n",
      "1268 [D loss: 0.167087, acc: 96.09%, op_acc: 79.69%] [G loss: 1.689496]\n",
      "1269 [D loss: 0.165437, acc: 96.88%, op_acc: 84.38%] [G loss: 1.688408]\n",
      "1270 [D loss: 0.186423, acc: 94.53%, op_acc: 75.78%] [G loss: 1.588221]\n",
      "Epoch: 1270, F1: 0.65854, F1P: 127\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "94.84375\n",
      "1271 [D loss: 0.197976, acc: 90.62%, op_acc: 72.66%] [G loss: 1.659589]\n",
      "1272 [D loss: 0.192999, acc: 92.97%, op_acc: 85.16%] [G loss: 1.765981]\n",
      "1273 [D loss: 0.187303, acc: 92.97%, op_acc: 75.78%] [G loss: 1.715938]\n",
      "1274 [D loss: 0.172703, acc: 96.09%, op_acc: 75.00%] [G loss: 1.684179]\n",
      "1275 [D loss: 0.183126, acc: 96.09%, op_acc: 74.22%] [G loss: 1.701889]\n",
      "1276 [D loss: 0.184716, acc: 93.75%, op_acc: 78.91%] [G loss: 1.671678]\n",
      "1277 [D loss: 0.184133, acc: 92.19%, op_acc: 77.34%] [G loss: 1.788016]\n",
      "1278 [D loss: 0.169517, acc: 96.09%, op_acc: 73.44%] [G loss: 1.681396]\n",
      "1279 [D loss: 0.183141, acc: 94.53%, op_acc: 77.34%] [G loss: 1.649336]\n",
      "1280 [D loss: 0.182512, acc: 95.31%, op_acc: 77.34%] [G loss: 1.722215]\n",
      "Epoch: 1280, F1: 0.65854, F1P: 128\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "94.0625\n",
      "1281 [D loss: 0.178953, acc: 93.75%, op_acc: 74.22%] [G loss: 1.626707]\n",
      "1282 [D loss: 0.185773, acc: 91.41%, op_acc: 75.00%] [G loss: 1.635585]\n",
      "1283 [D loss: 0.173754, acc: 93.75%, op_acc: 82.81%] [G loss: 1.689239]\n",
      "1284 [D loss: 0.178788, acc: 91.41%, op_acc: 75.78%] [G loss: 1.682773]\n",
      "1285 [D loss: 0.168776, acc: 93.75%, op_acc: 75.00%] [G loss: 1.669127]\n",
      "1286 [D loss: 0.167495, acc: 95.31%, op_acc: 79.69%] [G loss: 1.689803]\n",
      "1287 [D loss: 0.195954, acc: 93.75%, op_acc: 77.34%] [G loss: 1.613577]\n",
      "1288 [D loss: 0.181034, acc: 94.53%, op_acc: 81.25%] [G loss: 1.583429]\n",
      "1289 [D loss: 0.171215, acc: 93.75%, op_acc: 80.47%] [G loss: 1.660282]\n",
      "1290 [D loss: 0.182294, acc: 95.31%, op_acc: 73.44%] [G loss: 1.752638]\n",
      "Epoch: 1290, F1: 0.65854, F1P: 129\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "93.671875\n",
      "1291 [D loss: 0.171271, acc: 98.44%, op_acc: 77.34%] [G loss: 1.661643]\n",
      "1292 [D loss: 0.187090, acc: 93.75%, op_acc: 78.12%] [G loss: 1.651856]\n",
      "1293 [D loss: 0.178965, acc: 93.75%, op_acc: 76.56%] [G loss: 1.680378]\n",
      "1294 [D loss: 0.166624, acc: 93.75%, op_acc: 80.47%] [G loss: 1.704301]\n",
      "1295 [D loss: 0.189353, acc: 89.84%, op_acc: 75.00%] [G loss: 1.718360]\n",
      "1296 [D loss: 0.187613, acc: 94.53%, op_acc: 81.25%] [G loss: 1.790589]\n",
      "1297 [D loss: 0.180956, acc: 91.41%, op_acc: 76.56%] [G loss: 1.668797]\n",
      "1298 [D loss: 0.178830, acc: 95.31%, op_acc: 77.34%] [G loss: 1.623600]\n",
      "1299 [D loss: 0.175105, acc: 96.88%, op_acc: 77.34%] [G loss: 1.639059]\n",
      "1300 [D loss: 0.188782, acc: 89.84%, op_acc: 77.34%] [G loss: 1.743838]\n",
      "Epoch: 1300, F1: 0.65854, F1P: 130\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "93.75\n",
      "1301 [D loss: 0.172962, acc: 96.09%, op_acc: 78.12%] [G loss: 1.703019]\n",
      "1302 [D loss: 0.176976, acc: 93.75%, op_acc: 76.56%] [G loss: 1.747607]\n",
      "1303 [D loss: 0.179923, acc: 96.09%, op_acc: 80.47%] [G loss: 1.732392]\n",
      "1304 [D loss: 0.183540, acc: 94.53%, op_acc: 76.56%] [G loss: 1.682075]\n",
      "1305 [D loss: 0.187395, acc: 93.75%, op_acc: 80.47%] [G loss: 1.642919]\n",
      "1306 [D loss: 0.195598, acc: 89.84%, op_acc: 75.78%] [G loss: 1.768598]\n",
      "1307 [D loss: 0.187237, acc: 94.53%, op_acc: 73.44%] [G loss: 1.816002]\n",
      "1308 [D loss: 0.177770, acc: 95.31%, op_acc: 78.12%] [G loss: 1.678437]\n",
      "1309 [D loss: 0.194214, acc: 90.62%, op_acc: 71.88%] [G loss: 1.711636]\n",
      "1310 [D loss: 0.170577, acc: 96.09%, op_acc: 78.91%] [G loss: 1.624338]\n",
      "Epoch: 1310, F1: 0.62500, F1P: 131\n",
      "[[28426     6]\n",
      " [   24    25]]\n",
      "94.0625\n",
      "1311 [D loss: 0.171769, acc: 96.09%, op_acc: 82.03%] [G loss: 1.743744]\n",
      "1312 [D loss: 0.178512, acc: 93.75%, op_acc: 80.47%] [G loss: 1.874732]\n",
      "1313 [D loss: 0.165589, acc: 95.31%, op_acc: 79.69%] [G loss: 1.694907]\n",
      "1314 [D loss: 0.170559, acc: 96.88%, op_acc: 79.69%] [G loss: 1.805724]\n",
      "1315 [D loss: 0.180280, acc: 92.19%, op_acc: 80.47%] [G loss: 1.692742]\n",
      "1316 [D loss: 0.175278, acc: 93.75%, op_acc: 79.69%] [G loss: 1.827040]\n",
      "1317 [D loss: 0.167460, acc: 95.31%, op_acc: 80.47%] [G loss: 1.845412]\n",
      "1318 [D loss: 0.172842, acc: 92.97%, op_acc: 78.91%] [G loss: 1.712870]\n",
      "1319 [D loss: 0.174784, acc: 93.75%, op_acc: 81.25%] [G loss: 1.714158]\n",
      "1320 [D loss: 0.181861, acc: 90.62%, op_acc: 78.12%] [G loss: 1.720335]\n",
      "Epoch: 1320, F1: 0.65854, F1P: 132\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "94.0625\n",
      "1321 [D loss: 0.187561, acc: 89.84%, op_acc: 76.56%] [G loss: 1.679849]\n",
      "1322 [D loss: 0.176025, acc: 96.09%, op_acc: 78.91%] [G loss: 1.805616]\n",
      "1323 [D loss: 0.186638, acc: 92.97%, op_acc: 78.91%] [G loss: 1.732155]\n",
      "1324 [D loss: 0.186202, acc: 93.75%, op_acc: 80.47%] [G loss: 1.693845]\n",
      "1325 [D loss: 0.172482, acc: 93.75%, op_acc: 81.25%] [G loss: 1.622753]\n",
      "1326 [D loss: 0.179350, acc: 92.97%, op_acc: 82.81%] [G loss: 1.715453]\n",
      "1327 [D loss: 0.180786, acc: 92.97%, op_acc: 78.12%] [G loss: 1.818701]\n",
      "1328 [D loss: 0.160729, acc: 96.09%, op_acc: 80.47%] [G loss: 1.788430]\n",
      "1329 [D loss: 0.176204, acc: 96.88%, op_acc: 82.81%] [G loss: 1.674793]\n",
      "1330 [D loss: 0.165054, acc: 98.44%, op_acc: 82.03%] [G loss: 1.786378]\n",
      "Epoch: 1330, F1: 0.64198, F1P: 133\n",
      "[[28426     6]\n",
      " [   23    26]]\n",
      "94.375\n",
      "1331 [D loss: 0.152249, acc: 96.09%, op_acc: 84.38%] [G loss: 1.804549]\n",
      "1332 [D loss: 0.190221, acc: 95.31%, op_acc: 71.09%] [G loss: 1.674153]\n",
      "1333 [D loss: 0.173975, acc: 95.31%, op_acc: 75.78%] [G loss: 1.746225]\n",
      "1334 [D loss: 0.174769, acc: 94.53%, op_acc: 85.16%] [G loss: 1.803096]\n",
      "1335 [D loss: 0.180710, acc: 92.19%, op_acc: 80.47%] [G loss: 1.858134]\n",
      "1336 [D loss: 0.178520, acc: 89.84%, op_acc: 78.91%] [G loss: 1.817865]\n",
      "1337 [D loss: 0.170709, acc: 92.97%, op_acc: 82.81%] [G loss: 1.775032]\n",
      "1338 [D loss: 0.174998, acc: 95.31%, op_acc: 80.47%] [G loss: 1.752678]\n",
      "1339 [D loss: 0.168151, acc: 96.88%, op_acc: 84.38%] [G loss: 1.881438]\n",
      "1340 [D loss: 0.174620, acc: 95.31%, op_acc: 83.59%] [G loss: 1.846215]\n",
      "Epoch: 1340, F1: 0.60759, F1P: 134\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "94.375\n",
      "1341 [D loss: 0.194665, acc: 92.19%, op_acc: 75.00%] [G loss: 1.702964]\n",
      "1342 [D loss: 0.171707, acc: 94.53%, op_acc: 78.91%] [G loss: 1.672297]\n",
      "1343 [D loss: 0.187093, acc: 90.62%, op_acc: 76.56%] [G loss: 1.693517]\n",
      "1344 [D loss: 0.187362, acc: 91.41%, op_acc: 77.34%] [G loss: 1.767821]\n",
      "1345 [D loss: 0.173302, acc: 94.53%, op_acc: 86.72%] [G loss: 1.762463]\n",
      "1346 [D loss: 0.156617, acc: 95.31%, op_acc: 83.59%] [G loss: 1.777179]\n",
      "1347 [D loss: 0.180259, acc: 93.75%, op_acc: 80.47%] [G loss: 1.748875]\n",
      "1348 [D loss: 0.171515, acc: 96.09%, op_acc: 76.56%] [G loss: 1.857291]\n",
      "1349 [D loss: 0.177018, acc: 92.97%, op_acc: 81.25%] [G loss: 1.702287]\n",
      "1350 [D loss: 0.169103, acc: 95.31%, op_acc: 79.69%] [G loss: 1.787193]\n",
      "Epoch: 1350, F1: 0.60759, F1P: 135\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "93.671875\n",
      "1351 [D loss: 0.166229, acc: 96.88%, op_acc: 85.16%] [G loss: 1.744422]\n",
      "1352 [D loss: 0.160778, acc: 96.09%, op_acc: 85.94%] [G loss: 1.805908]\n",
      "1353 [D loss: 0.166885, acc: 98.44%, op_acc: 82.81%] [G loss: 1.675804]\n",
      "1354 [D loss: 0.164593, acc: 95.31%, op_acc: 85.94%] [G loss: 1.848879]\n",
      "1355 [D loss: 0.172351, acc: 96.09%, op_acc: 82.81%] [G loss: 1.877929]\n",
      "1356 [D loss: 0.167800, acc: 93.75%, op_acc: 78.91%] [G loss: 1.786975]\n",
      "1357 [D loss: 0.168451, acc: 95.31%, op_acc: 78.91%] [G loss: 1.718554]\n",
      "1358 [D loss: 0.182545, acc: 92.19%, op_acc: 81.25%] [G loss: 1.802517]\n",
      "1359 [D loss: 0.169442, acc: 94.53%, op_acc: 78.12%] [G loss: 1.726608]\n",
      "1360 [D loss: 0.167985, acc: 96.09%, op_acc: 85.94%] [G loss: 1.830388]\n",
      "Epoch: 1360, F1: 0.60759, F1P: 136\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "95.46875\n",
      "1361 [D loss: 0.179214, acc: 91.41%, op_acc: 78.91%] [G loss: 1.785777]\n",
      "1362 [D loss: 0.177623, acc: 94.53%, op_acc: 81.25%] [G loss: 1.789953]\n",
      "1363 [D loss: 0.169112, acc: 97.66%, op_acc: 87.50%] [G loss: 1.836230]\n",
      "1364 [D loss: 0.180035, acc: 92.19%, op_acc: 82.81%] [G loss: 1.722629]\n",
      "1365 [D loss: 0.169013, acc: 95.31%, op_acc: 82.03%] [G loss: 1.921815]\n",
      "1366 [D loss: 0.168791, acc: 95.31%, op_acc: 84.38%] [G loss: 1.828653]\n",
      "1367 [D loss: 0.181253, acc: 95.31%, op_acc: 76.56%] [G loss: 1.829477]\n",
      "1368 [D loss: 0.162625, acc: 95.31%, op_acc: 84.38%] [G loss: 1.874649]\n",
      "1369 [D loss: 0.180428, acc: 92.97%, op_acc: 80.47%] [G loss: 1.738180]\n",
      "1370 [D loss: 0.178057, acc: 92.19%, op_acc: 85.16%] [G loss: 1.696384]\n",
      "Epoch: 1370, F1: 0.60759, F1P: 137\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "94.21875\n",
      "1371 [D loss: 0.180715, acc: 91.41%, op_acc: 85.16%] [G loss: 1.731997]\n",
      "1372 [D loss: 0.167510, acc: 94.53%, op_acc: 84.38%] [G loss: 1.817618]\n",
      "1373 [D loss: 0.171354, acc: 96.09%, op_acc: 79.69%] [G loss: 1.743115]\n",
      "1374 [D loss: 0.176194, acc: 97.66%, op_acc: 81.25%] [G loss: 1.761037]\n",
      "1375 [D loss: 0.165321, acc: 97.66%, op_acc: 82.03%] [G loss: 1.764009]\n",
      "1376 [D loss: 0.184640, acc: 89.84%, op_acc: 78.12%] [G loss: 1.755307]\n",
      "1377 [D loss: 0.163662, acc: 92.97%, op_acc: 87.50%] [G loss: 1.848132]\n",
      "1378 [D loss: 0.170449, acc: 97.66%, op_acc: 80.47%] [G loss: 1.819475]\n",
      "1379 [D loss: 0.173354, acc: 94.53%, op_acc: 82.81%] [G loss: 1.753689]\n",
      "1380 [D loss: 0.168259, acc: 96.09%, op_acc: 78.12%] [G loss: 1.849390]\n",
      "Epoch: 1380, F1: 0.60000, F1P: 138\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "94.84375\n",
      "1381 [D loss: 0.158771, acc: 96.88%, op_acc: 83.59%] [G loss: 1.812137]\n",
      "1382 [D loss: 0.185651, acc: 91.41%, op_acc: 71.88%] [G loss: 1.799099]\n",
      "1383 [D loss: 0.173618, acc: 93.75%, op_acc: 82.81%] [G loss: 1.688451]\n",
      "1384 [D loss: 0.165445, acc: 95.31%, op_acc: 83.59%] [G loss: 1.858189]\n",
      "1385 [D loss: 0.182880, acc: 91.41%, op_acc: 78.12%] [G loss: 1.943333]\n",
      "1386 [D loss: 0.170847, acc: 96.09%, op_acc: 82.81%] [G loss: 1.873103]\n",
      "1387 [D loss: 0.193157, acc: 89.84%, op_acc: 71.88%] [G loss: 1.847723]\n",
      "1388 [D loss: 0.193268, acc: 92.19%, op_acc: 77.34%] [G loss: 1.652963]\n",
      "1389 [D loss: 0.179370, acc: 92.19%, op_acc: 83.59%] [G loss: 1.774941]\n",
      "1390 [D loss: 0.170098, acc: 96.88%, op_acc: 79.69%] [G loss: 1.774216]\n",
      "Epoch: 1390, F1: 0.60759, F1P: 139\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "93.59375\n",
      "1391 [D loss: 0.180323, acc: 94.53%, op_acc: 75.78%] [G loss: 1.830436]\n",
      "1392 [D loss: 0.166917, acc: 96.09%, op_acc: 82.03%] [G loss: 1.844143]\n",
      "1393 [D loss: 0.192208, acc: 92.97%, op_acc: 85.16%] [G loss: 1.858911]\n",
      "1394 [D loss: 0.182495, acc: 93.75%, op_acc: 75.78%] [G loss: 1.676812]\n",
      "1395 [D loss: 0.176021, acc: 93.75%, op_acc: 82.03%] [G loss: 1.750694]\n",
      "1396 [D loss: 0.161107, acc: 96.88%, op_acc: 80.47%] [G loss: 1.891528]\n",
      "1397 [D loss: 0.182453, acc: 89.84%, op_acc: 78.91%] [G loss: 1.716777]\n",
      "1398 [D loss: 0.176198, acc: 92.19%, op_acc: 74.22%] [G loss: 1.622771]\n",
      "1399 [D loss: 0.169127, acc: 94.53%, op_acc: 84.38%] [G loss: 1.753934]\n",
      "1400 [D loss: 0.168447, acc: 94.53%, op_acc: 81.25%] [G loss: 1.716043]\n",
      "Epoch: 1400, F1: 0.60000, F1P: 140\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.90625\n",
      "1401 [D loss: 0.187576, acc: 92.97%, op_acc: 75.78%] [G loss: 1.834712]\n",
      "1402 [D loss: 0.182714, acc: 92.97%, op_acc: 71.09%] [G loss: 1.725678]\n",
      "1403 [D loss: 0.172800, acc: 96.09%, op_acc: 84.38%] [G loss: 1.758094]\n",
      "1404 [D loss: 0.180521, acc: 93.75%, op_acc: 78.91%] [G loss: 1.661574]\n",
      "1405 [D loss: 0.175718, acc: 93.75%, op_acc: 81.25%] [G loss: 1.792661]\n",
      "1406 [D loss: 0.168169, acc: 94.53%, op_acc: 82.03%] [G loss: 1.801820]\n",
      "1407 [D loss: 0.185620, acc: 92.19%, op_acc: 80.47%] [G loss: 1.833435]\n",
      "1408 [D loss: 0.182122, acc: 95.31%, op_acc: 80.47%] [G loss: 1.680653]\n",
      "1409 [D loss: 0.167099, acc: 96.09%, op_acc: 82.03%] [G loss: 1.730739]\n",
      "1410 [D loss: 0.174721, acc: 95.31%, op_acc: 79.69%] [G loss: 1.769705]\n",
      "Epoch: 1410, F1: 0.60759, F1P: 141\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "94.296875\n",
      "1411 [D loss: 0.160838, acc: 94.53%, op_acc: 82.03%] [G loss: 1.791249]\n",
      "1412 [D loss: 0.160377, acc: 93.75%, op_acc: 81.25%] [G loss: 1.740950]\n",
      "1413 [D loss: 0.187419, acc: 90.62%, op_acc: 82.03%] [G loss: 1.735551]\n",
      "1414 [D loss: 0.179920, acc: 93.75%, op_acc: 76.56%] [G loss: 1.735550]\n",
      "1415 [D loss: 0.175729, acc: 94.53%, op_acc: 71.09%] [G loss: 1.815089]\n",
      "1416 [D loss: 0.183681, acc: 96.88%, op_acc: 80.47%] [G loss: 1.796874]\n",
      "1417 [D loss: 0.167530, acc: 94.53%, op_acc: 83.59%] [G loss: 1.828104]\n",
      "1418 [D loss: 0.169474, acc: 96.09%, op_acc: 80.47%] [G loss: 1.824494]\n",
      "1419 [D loss: 0.168634, acc: 94.53%, op_acc: 78.91%] [G loss: 1.809308]\n",
      "1420 [D loss: 0.175109, acc: 93.75%, op_acc: 74.22%] [G loss: 1.749938]\n",
      "Epoch: 1420, F1: 0.60000, F1P: 142\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "94.296875\n",
      "1421 [D loss: 0.168472, acc: 96.09%, op_acc: 82.03%] [G loss: 1.686059]\n",
      "1422 [D loss: 0.190974, acc: 90.62%, op_acc: 78.91%] [G loss: 1.713104]\n",
      "1423 [D loss: 0.180908, acc: 95.31%, op_acc: 76.56%] [G loss: 1.719748]\n",
      "1424 [D loss: 0.158924, acc: 98.44%, op_acc: 82.03%] [G loss: 1.748752]\n",
      "1425 [D loss: 0.190702, acc: 90.62%, op_acc: 74.22%] [G loss: 1.711767]\n",
      "1426 [D loss: 0.169717, acc: 93.75%, op_acc: 76.56%] [G loss: 1.768410]\n",
      "1427 [D loss: 0.173085, acc: 96.09%, op_acc: 81.25%] [G loss: 1.721675]\n",
      "1428 [D loss: 0.162511, acc: 97.66%, op_acc: 82.81%] [G loss: 1.711446]\n",
      "1429 [D loss: 0.165940, acc: 96.09%, op_acc: 84.38%] [G loss: 1.716549]\n",
      "1430 [D loss: 0.192034, acc: 94.53%, op_acc: 75.00%] [G loss: 1.901300]\n",
      "Epoch: 1430, F1: 0.60000, F1P: 143\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "94.921875\n",
      "1431 [D loss: 0.175921, acc: 95.31%, op_acc: 82.81%] [G loss: 1.830364]\n",
      "1432 [D loss: 0.187994, acc: 90.62%, op_acc: 79.69%] [G loss: 1.717925]\n",
      "1433 [D loss: 0.175028, acc: 94.53%, op_acc: 80.47%] [G loss: 1.772851]\n",
      "1434 [D loss: 0.186329, acc: 90.62%, op_acc: 79.69%] [G loss: 1.702554]\n",
      "1435 [D loss: 0.172472, acc: 94.53%, op_acc: 80.47%] [G loss: 1.869594]\n",
      "1436 [D loss: 0.180973, acc: 90.62%, op_acc: 85.16%] [G loss: 1.642356]\n",
      "1437 [D loss: 0.186183, acc: 92.19%, op_acc: 78.91%] [G loss: 1.771270]\n",
      "1438 [D loss: 0.163250, acc: 96.88%, op_acc: 84.38%] [G loss: 1.674805]\n",
      "1439 [D loss: 0.161535, acc: 96.09%, op_acc: 82.81%] [G loss: 1.590628]\n",
      "1440 [D loss: 0.169054, acc: 96.09%, op_acc: 82.81%] [G loss: 1.694906]\n",
      "Epoch: 1440, F1: 0.60000, F1P: 144\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.75\n",
      "1441 [D loss: 0.167147, acc: 95.31%, op_acc: 83.59%] [G loss: 1.800032]\n",
      "1442 [D loss: 0.192280, acc: 89.84%, op_acc: 78.12%] [G loss: 1.734721]\n",
      "1443 [D loss: 0.172382, acc: 94.53%, op_acc: 82.03%] [G loss: 1.741933]\n",
      "1444 [D loss: 0.170700, acc: 93.75%, op_acc: 81.25%] [G loss: 1.673104]\n",
      "1445 [D loss: 0.173291, acc: 95.31%, op_acc: 78.12%] [G loss: 1.759262]\n",
      "1446 [D loss: 0.169813, acc: 96.88%, op_acc: 75.78%] [G loss: 1.919700]\n",
      "1447 [D loss: 0.171767, acc: 94.53%, op_acc: 88.28%] [G loss: 1.832188]\n",
      "1448 [D loss: 0.176892, acc: 92.19%, op_acc: 81.25%] [G loss: 1.863863]\n",
      "1449 [D loss: 0.164925, acc: 97.66%, op_acc: 81.25%] [G loss: 1.799891]\n",
      "1450 [D loss: 0.169858, acc: 98.44%, op_acc: 83.59%] [G loss: 1.752614]\n",
      "Epoch: 1450, F1: 0.60000, F1P: 145\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "94.84375\n",
      "1451 [D loss: 0.156393, acc: 94.53%, op_acc: 81.25%] [G loss: 1.687994]\n",
      "1452 [D loss: 0.166829, acc: 95.31%, op_acc: 76.56%] [G loss: 1.628398]\n",
      "1453 [D loss: 0.178346, acc: 92.97%, op_acc: 75.78%] [G loss: 1.665241]\n",
      "1454 [D loss: 0.179173, acc: 92.97%, op_acc: 85.16%] [G loss: 1.836106]\n",
      "1455 [D loss: 0.176336, acc: 92.97%, op_acc: 78.91%] [G loss: 1.809162]\n",
      "1456 [D loss: 0.159376, acc: 96.09%, op_acc: 82.81%] [G loss: 1.775945]\n",
      "1457 [D loss: 0.173538, acc: 96.88%, op_acc: 75.00%] [G loss: 1.745014]\n",
      "1458 [D loss: 0.183703, acc: 92.97%, op_acc: 75.78%] [G loss: 1.822481]\n",
      "1459 [D loss: 0.177804, acc: 96.88%, op_acc: 74.22%] [G loss: 1.766126]\n",
      "1460 [D loss: 0.178043, acc: 92.97%, op_acc: 82.81%] [G loss: 1.788671]\n",
      "Epoch: 1460, F1: 0.60000, F1P: 146\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "94.453125\n",
      "1461 [D loss: 0.185315, acc: 89.06%, op_acc: 76.56%] [G loss: 1.729300]\n",
      "1462 [D loss: 0.165542, acc: 96.09%, op_acc: 82.81%] [G loss: 1.777294]\n",
      "1463 [D loss: 0.166970, acc: 95.31%, op_acc: 75.78%] [G loss: 1.786304]\n",
      "1464 [D loss: 0.163269, acc: 95.31%, op_acc: 85.16%] [G loss: 1.892879]\n",
      "1465 [D loss: 0.175483, acc: 92.19%, op_acc: 78.91%] [G loss: 1.755713]\n",
      "1466 [D loss: 0.168441, acc: 95.31%, op_acc: 83.59%] [G loss: 1.696726]\n",
      "1467 [D loss: 0.165433, acc: 96.88%, op_acc: 79.69%] [G loss: 1.797941]\n",
      "1468 [D loss: 0.174705, acc: 94.53%, op_acc: 83.59%] [G loss: 1.617084]\n",
      "1469 [D loss: 0.171982, acc: 96.88%, op_acc: 80.47%] [G loss: 1.823744]\n",
      "1470 [D loss: 0.167570, acc: 96.09%, op_acc: 81.25%] [G loss: 1.834520]\n",
      "Epoch: 1470, F1: 0.60976, F1P: 147\n",
      "[[28424     8]\n",
      " [   24    25]]\n",
      "94.765625\n",
      "1471 [D loss: 0.169445, acc: 94.53%, op_acc: 78.91%] [G loss: 1.895409]\n",
      "1472 [D loss: 0.176294, acc: 92.97%, op_acc: 75.00%] [G loss: 1.776136]\n",
      "1473 [D loss: 0.178930, acc: 90.62%, op_acc: 77.34%] [G loss: 1.812547]\n",
      "1474 [D loss: 0.165326, acc: 95.31%, op_acc: 80.47%] [G loss: 1.744139]\n",
      "1475 [D loss: 0.172114, acc: 94.53%, op_acc: 79.69%] [G loss: 1.896914]\n",
      "1476 [D loss: 0.162163, acc: 96.09%, op_acc: 86.72%] [G loss: 1.869617]\n",
      "1477 [D loss: 0.168048, acc: 96.09%, op_acc: 77.34%] [G loss: 1.695753]\n",
      "1478 [D loss: 0.155967, acc: 97.66%, op_acc: 82.81%] [G loss: 1.753740]\n",
      "1479 [D loss: 0.182129, acc: 92.19%, op_acc: 75.00%] [G loss: 1.804107]\n",
      "1480 [D loss: 0.176357, acc: 94.53%, op_acc: 83.59%] [G loss: 1.815660]\n",
      "Epoch: 1480, F1: 0.60976, F1P: 148\n",
      "[[28424     8]\n",
      " [   24    25]]\n",
      "94.453125\n",
      "1481 [D loss: 0.174499, acc: 93.75%, op_acc: 78.91%] [G loss: 1.838152]\n",
      "1482 [D loss: 0.159486, acc: 96.88%, op_acc: 79.69%] [G loss: 1.916667]\n",
      "1483 [D loss: 0.178829, acc: 94.53%, op_acc: 75.78%] [G loss: 1.833623]\n",
      "1484 [D loss: 0.182422, acc: 92.19%, op_acc: 78.12%] [G loss: 1.786720]\n",
      "1485 [D loss: 0.182853, acc: 93.75%, op_acc: 75.78%] [G loss: 1.771730]\n",
      "1486 [D loss: 0.164716, acc: 93.75%, op_acc: 76.56%] [G loss: 1.880662]\n",
      "1487 [D loss: 0.176822, acc: 94.53%, op_acc: 80.47%] [G loss: 1.853928]\n",
      "1488 [D loss: 0.156376, acc: 96.88%, op_acc: 85.94%] [G loss: 1.852030]\n",
      "1489 [D loss: 0.163132, acc: 96.09%, op_acc: 83.59%] [G loss: 1.894176]\n",
      "1490 [D loss: 0.186242, acc: 92.19%, op_acc: 79.69%] [G loss: 1.911446]\n",
      "Epoch: 1490, F1: 0.62651, F1P: 149\n",
      "[[28424     8]\n",
      " [   23    26]]\n",
      "94.453125\n",
      "1491 [D loss: 0.171976, acc: 95.31%, op_acc: 79.69%] [G loss: 1.841036]\n",
      "1492 [D loss: 0.169840, acc: 94.53%, op_acc: 79.69%] [G loss: 1.816974]\n",
      "1493 [D loss: 0.177344, acc: 92.19%, op_acc: 78.12%] [G loss: 1.781898]\n",
      "1494 [D loss: 0.171923, acc: 96.88%, op_acc: 77.34%] [G loss: 1.822440]\n",
      "1495 [D loss: 0.169350, acc: 93.75%, op_acc: 83.59%] [G loss: 1.803204]\n",
      "1496 [D loss: 0.173692, acc: 90.62%, op_acc: 74.22%] [G loss: 1.861508]\n",
      "1497 [D loss: 0.171583, acc: 96.09%, op_acc: 77.34%] [G loss: 1.793541]\n",
      "1498 [D loss: 0.172171, acc: 93.75%, op_acc: 82.03%] [G loss: 1.822218]\n",
      "1499 [D loss: 0.170514, acc: 92.19%, op_acc: 76.56%] [G loss: 1.900539]\n",
      "1500 [D loss: 0.182729, acc: 92.97%, op_acc: 77.34%] [G loss: 1.675598]\n",
      "Epoch: 1500, F1: 0.60976, F1P: 150\n",
      "[[28424     8]\n",
      " [   24    25]]\n",
      "93.828125\n",
      "1501 [D loss: 0.169763, acc: 96.09%, op_acc: 76.56%] [G loss: 1.822848]\n",
      "1502 [D loss: 0.175139, acc: 93.75%, op_acc: 80.47%] [G loss: 1.867316]\n",
      "1503 [D loss: 0.179799, acc: 92.19%, op_acc: 72.66%] [G loss: 1.854103]\n",
      "1504 [D loss: 0.166537, acc: 90.62%, op_acc: 82.03%] [G loss: 1.707405]\n",
      "1505 [D loss: 0.171275, acc: 92.19%, op_acc: 80.47%] [G loss: 1.831968]\n",
      "1506 [D loss: 0.169481, acc: 92.97%, op_acc: 75.78%] [G loss: 1.890793]\n",
      "1507 [D loss: 0.172721, acc: 96.88%, op_acc: 77.34%] [G loss: 1.796628]\n",
      "1508 [D loss: 0.164088, acc: 96.09%, op_acc: 75.78%] [G loss: 1.896905]\n",
      "1509 [D loss: 0.172228, acc: 93.75%, op_acc: 80.47%] [G loss: 1.872905]\n",
      "1510 [D loss: 0.162514, acc: 94.53%, op_acc: 86.72%] [G loss: 1.705790]\n",
      "Epoch: 1510, F1: 0.60976, F1P: 151\n",
      "[[28424     8]\n",
      " [   24    25]]\n",
      "93.90625\n",
      "1511 [D loss: 0.176573, acc: 95.31%, op_acc: 79.69%] [G loss: 1.921192]\n",
      "1512 [D loss: 0.165481, acc: 94.53%, op_acc: 77.34%] [G loss: 1.867513]\n",
      "1513 [D loss: 0.146958, acc: 95.31%, op_acc: 82.81%] [G loss: 1.879436]\n",
      "1514 [D loss: 0.187803, acc: 92.19%, op_acc: 73.44%] [G loss: 1.894593]\n",
      "1515 [D loss: 0.163616, acc: 95.31%, op_acc: 80.47%] [G loss: 1.904634]\n",
      "1516 [D loss: 0.173377, acc: 93.75%, op_acc: 74.22%] [G loss: 1.837462]\n",
      "1517 [D loss: 0.182437, acc: 93.75%, op_acc: 80.47%] [G loss: 1.885599]\n",
      "1518 [D loss: 0.155898, acc: 96.88%, op_acc: 88.28%] [G loss: 1.894664]\n",
      "1519 [D loss: 0.166865, acc: 95.31%, op_acc: 84.38%] [G loss: 1.900965]\n",
      "1520 [D loss: 0.168402, acc: 93.75%, op_acc: 77.34%] [G loss: 1.823986]\n",
      "Epoch: 1520, F1: 0.64286, F1P: 152\n",
      "[[28424     8]\n",
      " [   22    27]]\n",
      "94.609375\n",
      "1521 [D loss: 0.182439, acc: 92.97%, op_acc: 76.56%] [G loss: 1.950615]\n",
      "1522 [D loss: 0.152048, acc: 95.31%, op_acc: 80.47%] [G loss: 1.852415]\n",
      "1523 [D loss: 0.171152, acc: 93.75%, op_acc: 71.09%] [G loss: 1.920209]\n",
      "1524 [D loss: 0.157353, acc: 95.31%, op_acc: 83.59%] [G loss: 1.902124]\n",
      "1525 [D loss: 0.167289, acc: 91.41%, op_acc: 80.47%] [G loss: 1.934159]\n",
      "1526 [D loss: 0.172216, acc: 96.88%, op_acc: 76.56%] [G loss: 1.821520]\n",
      "1527 [D loss: 0.174605, acc: 91.41%, op_acc: 75.00%] [G loss: 1.996503]\n",
      "1528 [D loss: 0.161409, acc: 96.09%, op_acc: 78.12%] [G loss: 1.863228]\n",
      "1529 [D loss: 0.150041, acc: 95.31%, op_acc: 82.81%] [G loss: 2.036753]\n",
      "1530 [D loss: 0.183390, acc: 92.97%, op_acc: 79.69%] [G loss: 1.974579]\n",
      "Epoch: 1530, F1: 0.62651, F1P: 153\n",
      "[[28424     8]\n",
      " [   23    26]]\n",
      "94.140625\n",
      "1531 [D loss: 0.155366, acc: 96.09%, op_acc: 77.34%] [G loss: 1.737222]\n",
      "1532 [D loss: 0.152458, acc: 97.66%, op_acc: 80.47%] [G loss: 1.971317]\n",
      "1533 [D loss: 0.164200, acc: 92.97%, op_acc: 78.91%] [G loss: 1.950646]\n",
      "1534 [D loss: 0.179242, acc: 91.41%, op_acc: 76.56%] [G loss: 1.830699]\n",
      "1535 [D loss: 0.154609, acc: 96.09%, op_acc: 79.69%] [G loss: 1.913027]\n",
      "1536 [D loss: 0.166194, acc: 92.97%, op_acc: 81.25%] [G loss: 1.964363]\n",
      "1537 [D loss: 0.157007, acc: 96.09%, op_acc: 78.91%] [G loss: 1.935200]\n",
      "1538 [D loss: 0.176374, acc: 89.06%, op_acc: 73.44%] [G loss: 1.830308]\n",
      "1539 [D loss: 0.167821, acc: 92.97%, op_acc: 83.59%] [G loss: 1.702977]\n",
      "1540 [D loss: 0.174269, acc: 96.09%, op_acc: 79.69%] [G loss: 1.811549]\n",
      "Epoch: 1540, F1: 0.64286, F1P: 154\n",
      "[[28424     8]\n",
      " [   22    27]]\n",
      "94.140625\n",
      "1541 [D loss: 0.166137, acc: 96.09%, op_acc: 77.34%] [G loss: 1.877016]\n",
      "1542 [D loss: 0.174954, acc: 93.75%, op_acc: 85.94%] [G loss: 1.860234]\n",
      "1543 [D loss: 0.167251, acc: 91.41%, op_acc: 76.56%] [G loss: 1.914655]\n",
      "1544 [D loss: 0.161875, acc: 94.53%, op_acc: 86.72%] [G loss: 1.923876]\n",
      "1545 [D loss: 0.180096, acc: 92.97%, op_acc: 84.38%] [G loss: 1.839358]\n",
      "1546 [D loss: 0.174514, acc: 89.84%, op_acc: 83.59%] [G loss: 1.854727]\n",
      "1547 [D loss: 0.160278, acc: 95.31%, op_acc: 83.59%] [G loss: 1.837505]\n",
      "1548 [D loss: 0.165640, acc: 93.75%, op_acc: 77.34%] [G loss: 1.793554]\n",
      "1549 [D loss: 0.162064, acc: 95.31%, op_acc: 80.47%] [G loss: 1.908193]\n",
      "1550 [D loss: 0.161444, acc: 93.75%, op_acc: 83.59%] [G loss: 1.796649]\n",
      "Epoch: 1550, F1: 0.63529, F1P: 155\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "93.671875\n",
      "1551 [D loss: 0.160960, acc: 92.97%, op_acc: 84.38%] [G loss: 2.058418]\n",
      "1552 [D loss: 0.169363, acc: 93.75%, op_acc: 81.25%] [G loss: 1.945369]\n",
      "1553 [D loss: 0.162600, acc: 92.19%, op_acc: 80.47%] [G loss: 1.874772]\n",
      "1554 [D loss: 0.169236, acc: 92.19%, op_acc: 82.81%] [G loss: 2.001509]\n",
      "1555 [D loss: 0.170110, acc: 92.19%, op_acc: 80.47%] [G loss: 1.802108]\n",
      "1556 [D loss: 0.178309, acc: 92.97%, op_acc: 82.03%] [G loss: 1.810444]\n",
      "1557 [D loss: 0.164986, acc: 93.75%, op_acc: 80.47%] [G loss: 1.833383]\n",
      "1558 [D loss: 0.163708, acc: 95.31%, op_acc: 76.56%] [G loss: 1.787366]\n",
      "1559 [D loss: 0.165156, acc: 94.53%, op_acc: 79.69%] [G loss: 1.846166]\n",
      "1560 [D loss: 0.177508, acc: 89.06%, op_acc: 78.91%] [G loss: 1.798254]\n",
      "Epoch: 1560, F1: 0.63636, F1P: 156\n",
      "[[28421    11]\n",
      " [   21    28]]\n",
      "92.890625\n",
      "1561 [D loss: 0.160298, acc: 99.22%, op_acc: 81.25%] [G loss: 1.818240]\n",
      "1562 [D loss: 0.157122, acc: 96.09%, op_acc: 79.69%] [G loss: 1.872599]\n",
      "1563 [D loss: 0.161219, acc: 95.31%, op_acc: 81.25%] [G loss: 1.915627]\n",
      "1564 [D loss: 0.174078, acc: 92.97%, op_acc: 85.16%] [G loss: 1.806147]\n",
      "1565 [D loss: 0.154218, acc: 94.53%, op_acc: 85.16%] [G loss: 1.806711]\n",
      "1566 [D loss: 0.156048, acc: 94.53%, op_acc: 78.91%] [G loss: 1.866293]\n",
      "1567 [D loss: 0.153514, acc: 95.31%, op_acc: 82.81%] [G loss: 1.925532]\n",
      "1568 [D loss: 0.159672, acc: 94.53%, op_acc: 83.59%] [G loss: 2.052969]\n",
      "1569 [D loss: 0.159671, acc: 92.97%, op_acc: 82.03%] [G loss: 1.893041]\n",
      "1570 [D loss: 0.175271, acc: 93.75%, op_acc: 75.78%] [G loss: 1.856436]\n",
      "Epoch: 1570, F1: 0.63636, F1P: 157\n",
      "[[28421    11]\n",
      " [   21    28]]\n",
      "94.921875\n",
      "1571 [D loss: 0.160363, acc: 94.53%, op_acc: 84.38%] [G loss: 1.840752]\n",
      "1572 [D loss: 0.168606, acc: 92.19%, op_acc: 77.34%] [G loss: 1.864596]\n",
      "1573 [D loss: 0.172984, acc: 92.97%, op_acc: 75.78%] [G loss: 1.963037]\n",
      "1574 [D loss: 0.167860, acc: 92.97%, op_acc: 74.22%] [G loss: 1.853444]\n",
      "1575 [D loss: 0.154644, acc: 92.97%, op_acc: 83.59%] [G loss: 1.799818]\n",
      "1576 [D loss: 0.172997, acc: 92.97%, op_acc: 78.12%] [G loss: 1.818053]\n",
      "1577 [D loss: 0.177080, acc: 92.19%, op_acc: 75.78%] [G loss: 1.842198]\n",
      "1578 [D loss: 0.153394, acc: 95.31%, op_acc: 85.16%] [G loss: 1.986533]\n",
      "1579 [D loss: 0.161378, acc: 93.75%, op_acc: 82.81%] [G loss: 2.012156]\n",
      "1580 [D loss: 0.158591, acc: 96.09%, op_acc: 75.78%] [G loss: 1.914707]\n",
      "Epoch: 1580, F1: 0.62921, F1P: 158\n",
      "[[28420    12]\n",
      " [   21    28]]\n",
      "93.59375\n",
      "1581 [D loss: 0.173212, acc: 91.41%, op_acc: 77.34%] [G loss: 1.828033]\n",
      "1582 [D loss: 0.167807, acc: 94.53%, op_acc: 81.25%] [G loss: 1.808100]\n",
      "1583 [D loss: 0.182136, acc: 94.53%, op_acc: 79.69%] [G loss: 1.818669]\n",
      "1584 [D loss: 0.150047, acc: 95.31%, op_acc: 84.38%] [G loss: 1.782223]\n",
      "1585 [D loss: 0.147459, acc: 95.31%, op_acc: 82.03%] [G loss: 1.784393]\n",
      "1586 [D loss: 0.152379, acc: 94.53%, op_acc: 85.94%] [G loss: 1.924963]\n",
      "1587 [D loss: 0.155427, acc: 92.19%, op_acc: 86.72%] [G loss: 1.876256]\n",
      "1588 [D loss: 0.178711, acc: 94.53%, op_acc: 82.03%] [G loss: 1.797303]\n",
      "1589 [D loss: 0.176046, acc: 94.53%, op_acc: 81.25%] [G loss: 1.855541]\n",
      "1590 [D loss: 0.170256, acc: 93.75%, op_acc: 82.03%] [G loss: 1.769193]\n",
      "Epoch: 1590, F1: 0.65217, F1P: 159\n",
      "[[28419    13]\n",
      " [   19    30]]\n",
      "94.0625\n",
      "1591 [D loss: 0.171763, acc: 94.53%, op_acc: 77.34%] [G loss: 1.970688]\n",
      "1592 [D loss: 0.159305, acc: 94.53%, op_acc: 76.56%] [G loss: 1.852839]\n",
      "1593 [D loss: 0.156725, acc: 94.53%, op_acc: 74.22%] [G loss: 1.772000]\n",
      "1594 [D loss: 0.151001, acc: 96.88%, op_acc: 79.69%] [G loss: 1.849948]\n",
      "1595 [D loss: 0.169081, acc: 92.97%, op_acc: 76.56%] [G loss: 1.771474]\n",
      "1596 [D loss: 0.153437, acc: 95.31%, op_acc: 84.38%] [G loss: 1.737243]\n",
      "1597 [D loss: 0.155135, acc: 93.75%, op_acc: 85.94%] [G loss: 1.827848]\n",
      "1598 [D loss: 0.157103, acc: 96.88%, op_acc: 88.28%] [G loss: 1.806482]\n",
      "1599 [D loss: 0.167985, acc: 91.41%, op_acc: 80.47%] [G loss: 1.902175]\n",
      "1600 [D loss: 0.166785, acc: 93.75%, op_acc: 80.47%] [G loss: 1.934775]\n",
      "Epoch: 1600, F1: 0.65934, F1P: 160\n",
      "[[28420    12]\n",
      " [   19    30]]\n",
      "94.453125\n",
      "1601 [D loss: 0.156247, acc: 96.88%, op_acc: 81.25%] [G loss: 1.816855]\n",
      "1602 [D loss: 0.159280, acc: 94.53%, op_acc: 78.91%] [G loss: 1.795491]\n",
      "1603 [D loss: 0.169626, acc: 93.75%, op_acc: 82.03%] [G loss: 1.680997]\n",
      "1604 [D loss: 0.162159, acc: 95.31%, op_acc: 82.81%] [G loss: 1.677542]\n",
      "1605 [D loss: 0.173155, acc: 92.19%, op_acc: 85.16%] [G loss: 1.835668]\n",
      "1606 [D loss: 0.149906, acc: 92.97%, op_acc: 82.81%] [G loss: 1.769355]\n",
      "1607 [D loss: 0.160175, acc: 93.75%, op_acc: 84.38%] [G loss: 1.817866]\n",
      "1608 [D loss: 0.155802, acc: 95.31%, op_acc: 85.16%] [G loss: 1.783975]\n",
      "1609 [D loss: 0.166372, acc: 96.09%, op_acc: 84.38%] [G loss: 1.881173]\n",
      "1610 [D loss: 0.173394, acc: 92.97%, op_acc: 82.81%] [G loss: 1.842395]\n",
      "Epoch: 1610, F1: 0.67368, F1P: 161\n",
      "[[28418    14]\n",
      " [   17    32]]\n",
      "94.375\n",
      "1611 [D loss: 0.170208, acc: 92.97%, op_acc: 76.56%] [G loss: 1.810849]\n",
      "1612 [D loss: 0.151233, acc: 96.88%, op_acc: 82.81%] [G loss: 1.771967]\n",
      "1613 [D loss: 0.159941, acc: 96.88%, op_acc: 77.34%] [G loss: 1.811223]\n",
      "1614 [D loss: 0.173533, acc: 90.62%, op_acc: 78.12%] [G loss: 1.704682]\n",
      "1615 [D loss: 0.156175, acc: 94.53%, op_acc: 81.25%] [G loss: 1.818127]\n",
      "1616 [D loss: 0.159237, acc: 93.75%, op_acc: 82.03%] [G loss: 1.785843]\n",
      "1617 [D loss: 0.165721, acc: 93.75%, op_acc: 82.03%] [G loss: 1.850783]\n",
      "1618 [D loss: 0.157945, acc: 97.66%, op_acc: 82.81%] [G loss: 1.821850]\n",
      "1619 [D loss: 0.161272, acc: 95.31%, op_acc: 82.03%] [G loss: 1.874035]\n",
      "1620 [D loss: 0.153070, acc: 95.31%, op_acc: 81.25%] [G loss: 1.739458]\n",
      "Epoch: 1620, F1: 0.66667, F1P: 162\n",
      "[[28415    17]\n",
      " [   16    33]]\n",
      "94.765625\n",
      "1621 [D loss: 0.155427, acc: 96.88%, op_acc: 79.69%] [G loss: 1.846915]\n",
      "1622 [D loss: 0.158608, acc: 93.75%, op_acc: 85.16%] [G loss: 1.876610]\n",
      "1623 [D loss: 0.156390, acc: 94.53%, op_acc: 82.03%] [G loss: 1.762686]\n",
      "1624 [D loss: 0.157127, acc: 96.88%, op_acc: 82.03%] [G loss: 1.802024]\n",
      "1625 [D loss: 0.162393, acc: 96.09%, op_acc: 76.56%] [G loss: 1.826306]\n",
      "1626 [D loss: 0.147031, acc: 97.66%, op_acc: 84.38%] [G loss: 1.700289]\n",
      "1627 [D loss: 0.154826, acc: 96.09%, op_acc: 75.78%] [G loss: 1.764529]\n",
      "1628 [D loss: 0.159441, acc: 93.75%, op_acc: 82.81%] [G loss: 1.745434]\n",
      "1629 [D loss: 0.165726, acc: 93.75%, op_acc: 84.38%] [G loss: 1.956170]\n",
      "1630 [D loss: 0.155875, acc: 94.53%, op_acc: 78.12%] [G loss: 1.825396]\n",
      "Epoch: 1630, F1: 0.66019, F1P: 163\n",
      "[[28412    20]\n",
      " [   15    34]]\n",
      "95.390625\n",
      "1631 [D loss: 0.153944, acc: 96.88%, op_acc: 83.59%] [G loss: 1.860955]\n",
      "1632 [D loss: 0.155914, acc: 93.75%, op_acc: 83.59%] [G loss: 1.854204]\n",
      "1633 [D loss: 0.152100, acc: 97.66%, op_acc: 87.50%] [G loss: 1.973157]\n",
      "1634 [D loss: 0.166134, acc: 94.53%, op_acc: 81.25%] [G loss: 1.999569]\n",
      "1635 [D loss: 0.159629, acc: 94.53%, op_acc: 85.94%] [G loss: 1.827250]\n",
      "1636 [D loss: 0.143334, acc: 96.88%, op_acc: 85.94%] [G loss: 1.872250]\n",
      "1637 [D loss: 0.157448, acc: 96.09%, op_acc: 82.81%] [G loss: 1.917712]\n",
      "1638 [D loss: 0.140542, acc: 97.66%, op_acc: 86.72%] [G loss: 1.873444]\n",
      "1639 [D loss: 0.168868, acc: 92.19%, op_acc: 82.03%] [G loss: 1.940929]\n",
      "1640 [D loss: 0.158025, acc: 96.88%, op_acc: 85.94%] [G loss: 1.806466]\n",
      "Epoch: 1640, F1: 0.63636, F1P: 164\n",
      "[[28406    26]\n",
      " [   14    35]]\n",
      "95.703125\n",
      "1641 [D loss: 0.146624, acc: 96.88%, op_acc: 81.25%] [G loss: 1.960710]\n",
      "1642 [D loss: 0.159641, acc: 96.09%, op_acc: 85.94%] [G loss: 1.754163]\n",
      "1643 [D loss: 0.152706, acc: 92.97%, op_acc: 78.91%] [G loss: 1.873966]\n",
      "1644 [D loss: 0.171948, acc: 92.19%, op_acc: 78.12%] [G loss: 1.747596]\n",
      "1645 [D loss: 0.151999, acc: 98.44%, op_acc: 85.94%] [G loss: 1.822662]\n",
      "1646 [D loss: 0.166331, acc: 90.62%, op_acc: 83.59%] [G loss: 1.822142]\n",
      "1647 [D loss: 0.158834, acc: 94.53%, op_acc: 82.03%] [G loss: 1.780074]\n",
      "1648 [D loss: 0.171100, acc: 93.75%, op_acc: 78.12%] [G loss: 1.884504]\n",
      "1649 [D loss: 0.159257, acc: 96.09%, op_acc: 82.81%] [G loss: 1.873261]\n",
      "1650 [D loss: 0.169456, acc: 94.53%, op_acc: 75.78%] [G loss: 1.961366]\n",
      "Epoch: 1650, F1: 0.64865, F1P: 165\n",
      "[[28406    26]\n",
      " [   13    36]]\n",
      "94.609375\n",
      "1651 [D loss: 0.162249, acc: 94.53%, op_acc: 78.91%] [G loss: 1.910619]\n",
      "1652 [D loss: 0.170052, acc: 92.19%, op_acc: 79.69%] [G loss: 1.954901]\n",
      "1653 [D loss: 0.165236, acc: 93.75%, op_acc: 81.25%] [G loss: 1.973922]\n",
      "1654 [D loss: 0.157558, acc: 95.31%, op_acc: 78.91%] [G loss: 1.889721]\n",
      "1655 [D loss: 0.167166, acc: 92.97%, op_acc: 82.03%] [G loss: 1.836292]\n",
      "1656 [D loss: 0.155961, acc: 95.31%, op_acc: 82.03%] [G loss: 1.961279]\n",
      "1657 [D loss: 0.163936, acc: 96.88%, op_acc: 80.47%] [G loss: 1.840955]\n",
      "1658 [D loss: 0.152667, acc: 97.66%, op_acc: 82.81%] [G loss: 2.015280]\n",
      "1659 [D loss: 0.151052, acc: 98.44%, op_acc: 88.28%] [G loss: 1.963279]\n",
      "1660 [D loss: 0.170902, acc: 91.41%, op_acc: 82.81%] [G loss: 2.043010]\n",
      "Epoch: 1660, F1: 0.59504, F1P: 166\n",
      "[[28396    36]\n",
      " [   13    36]]\n",
      "94.84375\n",
      "1661 [D loss: 0.160264, acc: 91.41%, op_acc: 82.03%] [G loss: 1.892068]\n",
      "1662 [D loss: 0.130643, acc: 98.44%, op_acc: 86.72%] [G loss: 1.769902]\n",
      "1663 [D loss: 0.166488, acc: 94.53%, op_acc: 81.25%] [G loss: 1.888884]\n",
      "1664 [D loss: 0.159997, acc: 93.75%, op_acc: 79.69%] [G loss: 1.746612]\n",
      "1665 [D loss: 0.164203, acc: 92.19%, op_acc: 82.03%] [G loss: 1.886216]\n",
      "1666 [D loss: 0.151353, acc: 94.53%, op_acc: 77.34%] [G loss: 1.813669]\n",
      "1667 [D loss: 0.148754, acc: 94.53%, op_acc: 78.91%] [G loss: 1.936205]\n",
      "1668 [D loss: 0.163869, acc: 92.97%, op_acc: 82.03%] [G loss: 1.786456]\n",
      "1669 [D loss: 0.154355, acc: 94.53%, op_acc: 85.16%] [G loss: 1.805242]\n",
      "1670 [D loss: 0.150409, acc: 93.75%, op_acc: 79.69%] [G loss: 1.910684]\n",
      "Epoch: 1670, F1: 0.62069, F1P: 167\n",
      "[[28401    31]\n",
      " [   13    36]]\n",
      "94.0625\n",
      "1671 [D loss: 0.163645, acc: 93.75%, op_acc: 77.34%] [G loss: 1.846771]\n",
      "1672 [D loss: 0.143354, acc: 95.31%, op_acc: 85.16%] [G loss: 1.913108]\n",
      "1673 [D loss: 0.158170, acc: 96.09%, op_acc: 80.47%] [G loss: 1.810567]\n",
      "1674 [D loss: 0.163655, acc: 95.31%, op_acc: 83.59%] [G loss: 1.790105]\n",
      "1675 [D loss: 0.163609, acc: 93.75%, op_acc: 80.47%] [G loss: 1.796736]\n",
      "1676 [D loss: 0.156706, acc: 93.75%, op_acc: 81.25%] [G loss: 1.865611]\n",
      "1677 [D loss: 0.165010, acc: 93.75%, op_acc: 82.81%] [G loss: 1.777925]\n",
      "1678 [D loss: 0.143957, acc: 96.88%, op_acc: 77.34%] [G loss: 1.769884]\n",
      "1679 [D loss: 0.155638, acc: 95.31%, op_acc: 82.03%] [G loss: 1.969608]\n",
      "1680 [D loss: 0.151314, acc: 96.88%, op_acc: 76.56%] [G loss: 1.737601]\n",
      "Epoch: 1680, F1: 0.62069, F1P: 168\n",
      "[[28401    31]\n",
      " [   13    36]]\n",
      "95.078125\n",
      "1681 [D loss: 0.160215, acc: 94.53%, op_acc: 80.47%] [G loss: 1.850150]\n",
      "1682 [D loss: 0.155498, acc: 92.97%, op_acc: 78.12%] [G loss: 1.835359]\n",
      "1683 [D loss: 0.152932, acc: 95.31%, op_acc: 77.34%] [G loss: 2.041983]\n",
      "1684 [D loss: 0.155270, acc: 95.31%, op_acc: 83.59%] [G loss: 2.048922]\n",
      "1685 [D loss: 0.152963, acc: 96.09%, op_acc: 79.69%] [G loss: 1.876366]\n",
      "1686 [D loss: 0.152673, acc: 100.00%, op_acc: 77.34%] [G loss: 1.782546]\n",
      "1687 [D loss: 0.147729, acc: 97.66%, op_acc: 78.91%] [G loss: 1.956603]\n",
      "1688 [D loss: 0.168871, acc: 94.53%, op_acc: 76.56%] [G loss: 1.951166]\n",
      "1689 [D loss: 0.165559, acc: 96.88%, op_acc: 77.34%] [G loss: 1.918740]\n",
      "1690 [D loss: 0.168449, acc: 92.19%, op_acc: 77.34%] [G loss: 1.768931]\n",
      "Epoch: 1690, F1: 0.59504, F1P: 169\n",
      "[[28396    36]\n",
      " [   13    36]]\n",
      "95.546875\n",
      "1691 [D loss: 0.135925, acc: 97.66%, op_acc: 85.16%] [G loss: 1.875693]\n",
      "1692 [D loss: 0.155854, acc: 92.97%, op_acc: 76.56%] [G loss: 1.880926]\n",
      "1693 [D loss: 0.164270, acc: 89.84%, op_acc: 83.59%] [G loss: 1.813143]\n",
      "1694 [D loss: 0.155076, acc: 93.75%, op_acc: 79.69%] [G loss: 1.844916]\n",
      "1695 [D loss: 0.172058, acc: 95.31%, op_acc: 75.78%] [G loss: 1.684948]\n",
      "1696 [D loss: 0.141526, acc: 98.44%, op_acc: 82.81%] [G loss: 1.759729]\n",
      "1697 [D loss: 0.153047, acc: 97.66%, op_acc: 76.56%] [G loss: 1.935516]\n",
      "1698 [D loss: 0.156430, acc: 95.31%, op_acc: 70.31%] [G loss: 1.769356]\n",
      "1699 [D loss: 0.139719, acc: 98.44%, op_acc: 78.12%] [G loss: 1.845589]\n",
      "1700 [D loss: 0.148186, acc: 93.75%, op_acc: 82.03%] [G loss: 1.747660]\n",
      "Epoch: 1700, F1: 0.59504, F1P: 170\n",
      "[[28396    36]\n",
      " [   13    36]]\n",
      "95.3125\n",
      "1701 [D loss: 0.152810, acc: 95.31%, op_acc: 75.78%] [G loss: 1.872233]\n",
      "1702 [D loss: 0.162046, acc: 93.75%, op_acc: 85.94%] [G loss: 1.769311]\n",
      "1703 [D loss: 0.158034, acc: 94.53%, op_acc: 82.81%] [G loss: 1.812553]\n",
      "1704 [D loss: 0.164032, acc: 96.09%, op_acc: 80.47%] [G loss: 1.811182]\n",
      "1705 [D loss: 0.155789, acc: 96.09%, op_acc: 77.34%] [G loss: 1.852674]\n",
      "1706 [D loss: 0.158786, acc: 92.97%, op_acc: 77.34%] [G loss: 1.788679]\n",
      "1707 [D loss: 0.153033, acc: 96.09%, op_acc: 82.81%] [G loss: 1.855063]\n",
      "1708 [D loss: 0.149987, acc: 96.09%, op_acc: 83.59%] [G loss: 1.845713]\n",
      "1709 [D loss: 0.157175, acc: 93.75%, op_acc: 82.81%] [G loss: 1.976062]\n",
      "1710 [D loss: 0.155271, acc: 96.88%, op_acc: 79.69%] [G loss: 1.922690]\n",
      "Epoch: 1710, F1: 0.56923, F1P: 171\n",
      "[[28388    44]\n",
      " [   12    37]]\n",
      "95.15625\n",
      "1711 [D loss: 0.153072, acc: 94.53%, op_acc: 81.25%] [G loss: 1.750685]\n",
      "1712 [D loss: 0.150399, acc: 95.31%, op_acc: 78.91%] [G loss: 1.821354]\n",
      "1713 [D loss: 0.172113, acc: 95.31%, op_acc: 81.25%] [G loss: 1.853885]\n",
      "1714 [D loss: 0.155692, acc: 96.09%, op_acc: 75.78%] [G loss: 1.847014]\n",
      "1715 [D loss: 0.166636, acc: 95.31%, op_acc: 82.03%] [G loss: 1.802781]\n",
      "1716 [D loss: 0.163751, acc: 96.09%, op_acc: 79.69%] [G loss: 1.802582]\n",
      "1717 [D loss: 0.156067, acc: 96.09%, op_acc: 82.81%] [G loss: 1.888410]\n",
      "1718 [D loss: 0.160054, acc: 93.75%, op_acc: 77.34%] [G loss: 1.994090]\n",
      "1719 [D loss: 0.158741, acc: 92.19%, op_acc: 82.03%] [G loss: 1.829231]\n",
      "1720 [D loss: 0.149035, acc: 96.88%, op_acc: 75.78%] [G loss: 1.823369]\n",
      "Epoch: 1720, F1: 0.47134, F1P: 172\n",
      "[[28361    71]\n",
      " [   12    37]]\n",
      "95.15625\n",
      "1721 [D loss: 0.163669, acc: 92.97%, op_acc: 78.12%] [G loss: 1.876280]\n",
      "1722 [D loss: 0.159329, acc: 90.62%, op_acc: 78.91%] [G loss: 1.852550]\n",
      "1723 [D loss: 0.165851, acc: 93.75%, op_acc: 79.69%] [G loss: 1.924942]\n",
      "1724 [D loss: 0.156201, acc: 95.31%, op_acc: 75.78%] [G loss: 1.757158]\n",
      "1725 [D loss: 0.153019, acc: 96.88%, op_acc: 80.47%] [G loss: 1.885864]\n",
      "1726 [D loss: 0.156961, acc: 95.31%, op_acc: 75.78%] [G loss: 1.906846]\n",
      "1727 [D loss: 0.138729, acc: 97.66%, op_acc: 76.56%] [G loss: 1.859052]\n",
      "1728 [D loss: 0.143606, acc: 96.09%, op_acc: 76.56%] [G loss: 1.901234]\n",
      "1729 [D loss: 0.151065, acc: 96.09%, op_acc: 78.91%] [G loss: 1.812879]\n",
      "1730 [D loss: 0.167845, acc: 95.31%, op_acc: 75.78%] [G loss: 1.912175]\n",
      "Epoch: 1730, F1: 0.39572, F1P: 173\n",
      "[[28331   101]\n",
      " [   12    37]]\n",
      "95.0\n",
      "1731 [D loss: 0.145117, acc: 96.09%, op_acc: 82.81%] [G loss: 1.810977]\n",
      "1732 [D loss: 0.156925, acc: 96.09%, op_acc: 81.25%] [G loss: 1.900699]\n",
      "1733 [D loss: 0.139390, acc: 98.44%, op_acc: 84.38%] [G loss: 1.806273]\n",
      "1734 [D loss: 0.151967, acc: 95.31%, op_acc: 80.47%] [G loss: 1.970189]\n",
      "1735 [D loss: 0.145952, acc: 95.31%, op_acc: 77.34%] [G loss: 1.879040]\n",
      "1736 [D loss: 0.149962, acc: 97.66%, op_acc: 81.25%] [G loss: 1.870502]\n",
      "1737 [D loss: 0.140333, acc: 95.31%, op_acc: 78.91%] [G loss: 1.743865]\n",
      "1738 [D loss: 0.155370, acc: 94.53%, op_acc: 83.59%] [G loss: 1.928992]\n",
      "1739 [D loss: 0.158106, acc: 97.66%, op_acc: 77.34%] [G loss: 1.987356]\n",
      "1740 [D loss: 0.150985, acc: 96.09%, op_acc: 82.03%] [G loss: 1.891159]\n",
      "Epoch: 1740, F1: 0.25868, F1P: 174\n",
      "[[28205   227]\n",
      " [    8    41]]\n",
      "96.25\n",
      "1741 [D loss: 0.154178, acc: 97.66%, op_acc: 75.78%] [G loss: 1.879915]\n",
      "1742 [D loss: 0.153673, acc: 96.09%, op_acc: 80.47%] [G loss: 1.850332]\n",
      "1743 [D loss: 0.151558, acc: 96.88%, op_acc: 79.69%] [G loss: 1.924367]\n",
      "1744 [D loss: 0.149569, acc: 96.09%, op_acc: 82.81%] [G loss: 1.900656]\n",
      "1745 [D loss: 0.148795, acc: 96.88%, op_acc: 84.38%] [G loss: 1.892830]\n",
      "1746 [D loss: 0.161827, acc: 95.31%, op_acc: 81.25%] [G loss: 1.892684]\n",
      "1747 [D loss: 0.158514, acc: 96.88%, op_acc: 82.03%] [G loss: 1.873549]\n",
      "1748 [D loss: 0.142935, acc: 96.88%, op_acc: 84.38%] [G loss: 2.016702]\n",
      "1749 [D loss: 0.162141, acc: 91.41%, op_acc: 81.25%] [G loss: 1.846614]\n",
      "1750 [D loss: 0.166531, acc: 89.84%, op_acc: 78.12%] [G loss: 1.641485]\n",
      "Epoch: 1750, F1: 0.20197, F1P: 175\n",
      "[[28116   316]\n",
      " [    8    41]]\n",
      "95.390625\n",
      "1751 [D loss: 0.157557, acc: 96.09%, op_acc: 82.81%] [G loss: 1.889379]\n",
      "1752 [D loss: 0.148547, acc: 93.75%, op_acc: 77.34%] [G loss: 1.820743]\n",
      "1753 [D loss: 0.149736, acc: 93.75%, op_acc: 84.38%] [G loss: 1.959174]\n",
      "1754 [D loss: 0.145953, acc: 97.66%, op_acc: 81.25%] [G loss: 1.851425]\n",
      "1755 [D loss: 0.170245, acc: 92.97%, op_acc: 75.78%] [G loss: 1.902510]\n",
      "1756 [D loss: 0.145673, acc: 97.66%, op_acc: 80.47%] [G loss: 1.909858]\n",
      "1757 [D loss: 0.140974, acc: 96.88%, op_acc: 77.34%] [G loss: 1.994102]\n",
      "1758 [D loss: 0.156229, acc: 96.88%, op_acc: 80.47%] [G loss: 1.813246]\n",
      "1759 [D loss: 0.167233, acc: 96.09%, op_acc: 81.25%] [G loss: 1.766641]\n",
      "1760 [D loss: 0.147289, acc: 97.66%, op_acc: 78.91%] [G loss: 1.768069]\n",
      "Epoch: 1760, F1: 0.24189, F1P: 176\n",
      "[[28183   249]\n",
      " [    8    41]]\n",
      "95.9375\n",
      "1761 [D loss: 0.140402, acc: 96.88%, op_acc: 82.81%] [G loss: 1.848878]\n",
      "1762 [D loss: 0.165532, acc: 93.75%, op_acc: 83.59%] [G loss: 1.847787]\n",
      "1763 [D loss: 0.134984, acc: 96.88%, op_acc: 82.03%] [G loss: 1.958930]\n",
      "1764 [D loss: 0.157543, acc: 94.53%, op_acc: 82.81%] [G loss: 1.826548]\n",
      "1765 [D loss: 0.148884, acc: 93.75%, op_acc: 82.03%] [G loss: 1.929332]\n",
      "1766 [D loss: 0.155636, acc: 96.09%, op_acc: 76.56%] [G loss: 1.931359]\n",
      "1767 [D loss: 0.152692, acc: 93.75%, op_acc: 80.47%] [G loss: 1.947869]\n",
      "1768 [D loss: 0.143803, acc: 96.88%, op_acc: 82.03%] [G loss: 1.811542]\n",
      "1769 [D loss: 0.132618, acc: 98.44%, op_acc: 82.81%] [G loss: 1.907025]\n",
      "1770 [D loss: 0.157762, acc: 96.09%, op_acc: 78.91%] [G loss: 1.912088]\n",
      "Epoch: 1770, F1: 0.22652, F1P: 177\n",
      "[[28160   272]\n",
      " [    8    41]]\n",
      "95.703125\n",
      "1771 [D loss: 0.141288, acc: 96.09%, op_acc: 75.78%] [G loss: 1.901144]\n",
      "1772 [D loss: 0.147045, acc: 96.88%, op_acc: 85.16%] [G loss: 1.829626]\n",
      "1773 [D loss: 0.150458, acc: 94.53%, op_acc: 73.44%] [G loss: 1.851899]\n",
      "1774 [D loss: 0.150640, acc: 93.75%, op_acc: 80.47%] [G loss: 1.760136]\n",
      "1775 [D loss: 0.151442, acc: 93.75%, op_acc: 77.34%] [G loss: 1.821225]\n",
      "1776 [D loss: 0.147374, acc: 96.09%, op_acc: 81.25%] [G loss: 1.711559]\n",
      "1777 [D loss: 0.154879, acc: 93.75%, op_acc: 82.81%] [G loss: 1.925390]\n",
      "1778 [D loss: 0.149503, acc: 98.44%, op_acc: 83.59%] [G loss: 1.930333]\n",
      "1779 [D loss: 0.165853, acc: 94.53%, op_acc: 73.44%] [G loss: 1.918212]\n",
      "1780 [D loss: 0.148170, acc: 96.09%, op_acc: 88.28%] [G loss: 1.928047]\n",
      "Epoch: 1780, F1: 0.18981, F1P: 178\n",
      "[[28090   342]\n",
      " [    8    41]]\n",
      "95.390625\n",
      "1781 [D loss: 0.141017, acc: 95.31%, op_acc: 85.94%] [G loss: 1.826101]\n",
      "1782 [D loss: 0.149849, acc: 95.31%, op_acc: 78.91%] [G loss: 1.973369]\n",
      "1783 [D loss: 0.153519, acc: 94.53%, op_acc: 81.25%] [G loss: 1.819950]\n",
      "1784 [D loss: 0.156306, acc: 96.09%, op_acc: 82.03%] [G loss: 1.965655]\n",
      "1785 [D loss: 0.153808, acc: 96.09%, op_acc: 81.25%] [G loss: 1.782760]\n",
      "1786 [D loss: 0.143848, acc: 96.88%, op_acc: 82.03%] [G loss: 1.891476]\n",
      "1787 [D loss: 0.147610, acc: 96.88%, op_acc: 81.25%] [G loss: 1.794917]\n",
      "1788 [D loss: 0.148407, acc: 95.31%, op_acc: 78.12%] [G loss: 1.795417]\n",
      "1789 [D loss: 0.145477, acc: 96.09%, op_acc: 82.03%] [G loss: 1.816390]\n",
      "1790 [D loss: 0.154019, acc: 95.31%, op_acc: 75.78%] [G loss: 1.929290]\n",
      "Epoch: 1790, F1: 0.23099, F1P: 179\n",
      "[[28167   265]\n",
      " [    8    41]]\n",
      "95.78125\n",
      "1791 [D loss: 0.147534, acc: 94.53%, op_acc: 80.47%] [G loss: 1.832986]\n",
      "1792 [D loss: 0.155641, acc: 95.31%, op_acc: 83.59%] [G loss: 1.825487]\n",
      "1793 [D loss: 0.145814, acc: 96.09%, op_acc: 82.03%] [G loss: 1.848812]\n",
      "1794 [D loss: 0.147147, acc: 96.09%, op_acc: 78.91%] [G loss: 1.815788]\n",
      "1795 [D loss: 0.149005, acc: 96.09%, op_acc: 81.25%] [G loss: 1.811112]\n",
      "1796 [D loss: 0.141803, acc: 96.09%, op_acc: 83.59%] [G loss: 1.953058]\n",
      "1797 [D loss: 0.152974, acc: 95.31%, op_acc: 80.47%] [G loss: 1.906407]\n",
      "1798 [D loss: 0.138778, acc: 96.09%, op_acc: 82.03%] [G loss: 1.733270]\n",
      "1799 [D loss: 0.134794, acc: 96.88%, op_acc: 86.72%] [G loss: 1.849999]\n",
      "1800 [D loss: 0.153786, acc: 95.31%, op_acc: 83.59%] [G loss: 1.865988]\n",
      "Epoch: 1800, F1: 0.19070, F1P: 180\n",
      "[[28092   340]\n",
      " [    8    41]]\n",
      "95.78125\n",
      "1801 [D loss: 0.170808, acc: 94.53%, op_acc: 78.91%] [G loss: 1.758530]\n",
      "1802 [D loss: 0.147476, acc: 95.31%, op_acc: 81.25%] [G loss: 1.790494]\n",
      "1803 [D loss: 0.150098, acc: 93.75%, op_acc: 86.72%] [G loss: 1.823504]\n",
      "1804 [D loss: 0.149759, acc: 97.66%, op_acc: 84.38%] [G loss: 1.874357]\n",
      "1805 [D loss: 0.142382, acc: 95.31%, op_acc: 86.72%] [G loss: 1.810457]\n",
      "1806 [D loss: 0.143722, acc: 96.88%, op_acc: 85.16%] [G loss: 1.825734]\n",
      "1807 [D loss: 0.141113, acc: 97.66%, op_acc: 80.47%] [G loss: 1.895727]\n",
      "1808 [D loss: 0.146377, acc: 96.09%, op_acc: 82.81%] [G loss: 1.693744]\n",
      "1809 [D loss: 0.141782, acc: 99.22%, op_acc: 80.47%] [G loss: 1.870442]\n",
      "1810 [D loss: 0.148559, acc: 95.31%, op_acc: 85.16%] [G loss: 1.711289]\n",
      "Epoch: 1810, F1: 0.19807, F1P: 181\n",
      "[[28108   324]\n",
      " [    8    41]]\n",
      "96.171875\n",
      "1811 [D loss: 0.154115, acc: 95.31%, op_acc: 81.25%] [G loss: 1.689124]\n",
      "1812 [D loss: 0.154371, acc: 94.53%, op_acc: 80.47%] [G loss: 1.965945]\n",
      "1813 [D loss: 0.162642, acc: 93.75%, op_acc: 82.03%] [G loss: 1.781721]\n",
      "1814 [D loss: 0.144511, acc: 96.88%, op_acc: 80.47%] [G loss: 1.802064]\n",
      "1815 [D loss: 0.161195, acc: 95.31%, op_acc: 80.47%] [G loss: 1.915761]\n",
      "1816 [D loss: 0.150490, acc: 94.53%, op_acc: 80.47%] [G loss: 1.772250]\n",
      "1817 [D loss: 0.164012, acc: 92.97%, op_acc: 81.25%] [G loss: 1.849348]\n",
      "1818 [D loss: 0.170292, acc: 93.75%, op_acc: 80.47%] [G loss: 1.690127]\n",
      "1819 [D loss: 0.136872, acc: 96.88%, op_acc: 81.25%] [G loss: 1.786716]\n",
      "1820 [D loss: 0.157301, acc: 95.31%, op_acc: 82.03%] [G loss: 1.950785]\n",
      "Epoch: 1820, F1: 0.16838, F1P: 182\n",
      "[[28035   397]\n",
      " [    8    41]]\n",
      "94.921875\n",
      "1821 [D loss: 0.144602, acc: 96.88%, op_acc: 78.91%] [G loss: 1.830567]\n",
      "1822 [D loss: 0.144393, acc: 96.88%, op_acc: 87.50%] [G loss: 1.714551]\n",
      "1823 [D loss: 0.161765, acc: 95.31%, op_acc: 84.38%] [G loss: 1.740272]\n",
      "1824 [D loss: 0.159488, acc: 93.75%, op_acc: 85.16%] [G loss: 1.722092]\n",
      "1825 [D loss: 0.169390, acc: 92.97%, op_acc: 82.81%] [G loss: 1.816545]\n",
      "1826 [D loss: 0.144126, acc: 96.88%, op_acc: 85.94%] [G loss: 1.720907]\n",
      "1827 [D loss: 0.159359, acc: 94.53%, op_acc: 80.47%] [G loss: 1.831776]\n",
      "1828 [D loss: 0.144803, acc: 96.88%, op_acc: 79.69%] [G loss: 1.892413]\n",
      "1829 [D loss: 0.158956, acc: 96.88%, op_acc: 89.06%] [G loss: 1.915512]\n",
      "1830 [D loss: 0.139556, acc: 96.88%, op_acc: 82.03%] [G loss: 1.777831]\n",
      "Epoch: 1830, F1: 0.08537, F1P: 183\n",
      "[[27539   893]\n",
      " [    7    42]]\n",
      "95.78125\n",
      "1831 [D loss: 0.144206, acc: 98.44%, op_acc: 86.72%] [G loss: 1.753168]\n",
      "1832 [D loss: 0.150415, acc: 96.09%, op_acc: 82.03%] [G loss: 1.825653]\n",
      "1833 [D loss: 0.141046, acc: 98.44%, op_acc: 85.94%] [G loss: 1.814200]\n",
      "1834 [D loss: 0.180268, acc: 92.19%, op_acc: 77.34%] [G loss: 1.899603]\n",
      "1835 [D loss: 0.145580, acc: 93.75%, op_acc: 88.28%] [G loss: 1.825519]\n",
      "1836 [D loss: 0.161466, acc: 93.75%, op_acc: 82.03%] [G loss: 1.784164]\n",
      "1837 [D loss: 0.147825, acc: 96.88%, op_acc: 82.81%] [G loss: 1.884933]\n",
      "1838 [D loss: 0.157231, acc: 96.09%, op_acc: 85.16%] [G loss: 1.892387]\n",
      "1839 [D loss: 0.150115, acc: 96.09%, op_acc: 86.72%] [G loss: 1.734758]\n",
      "1840 [D loss: 0.149023, acc: 93.75%, op_acc: 85.94%] [G loss: 1.742977]\n",
      "Epoch: 1840, F1: 0.03226, F1P: 184\n",
      "[[25858  2574]\n",
      " [    6    43]]\n",
      "95.546875\n",
      "1841 [D loss: 0.148622, acc: 96.88%, op_acc: 82.81%] [G loss: 1.714132]\n",
      "1842 [D loss: 0.153986, acc: 93.75%, op_acc: 82.03%] [G loss: 1.827016]\n",
      "1843 [D loss: 0.154868, acc: 93.75%, op_acc: 89.06%] [G loss: 1.794008]\n",
      "1844 [D loss: 0.148887, acc: 96.88%, op_acc: 88.28%] [G loss: 1.822352]\n",
      "1845 [D loss: 0.144331, acc: 96.88%, op_acc: 85.94%] [G loss: 1.814594]\n",
      "1846 [D loss: 0.167511, acc: 92.97%, op_acc: 82.03%] [G loss: 1.859258]\n",
      "1847 [D loss: 0.141088, acc: 99.22%, op_acc: 86.72%] [G loss: 1.811864]\n",
      "1848 [D loss: 0.149076, acc: 96.88%, op_acc: 88.28%] [G loss: 1.775627]\n",
      "1849 [D loss: 0.141795, acc: 96.88%, op_acc: 85.16%] [G loss: 1.776319]\n",
      "1850 [D loss: 0.163756, acc: 93.75%, op_acc: 85.16%] [G loss: 1.747395]\n",
      "Epoch: 1850, F1: 0.01773, F1P: 185\n",
      "[[23339  5093]\n",
      " [    3    46]]\n",
      "95.78125\n",
      "1851 [D loss: 0.145325, acc: 98.44%, op_acc: 85.94%] [G loss: 1.770497]\n",
      "1852 [D loss: 0.134719, acc: 96.09%, op_acc: 83.59%] [G loss: 1.800392]\n",
      "1853 [D loss: 0.151928, acc: 96.88%, op_acc: 83.59%] [G loss: 1.803645]\n",
      "1854 [D loss: 0.137271, acc: 96.88%, op_acc: 82.81%] [G loss: 1.704362]\n",
      "1855 [D loss: 0.156391, acc: 92.19%, op_acc: 82.81%] [G loss: 1.766692]\n",
      "1856 [D loss: 0.149494, acc: 94.53%, op_acc: 84.38%] [G loss: 1.767846]\n",
      "1857 [D loss: 0.151286, acc: 99.22%, op_acc: 84.38%] [G loss: 1.843154]\n",
      "1858 [D loss: 0.152025, acc: 96.09%, op_acc: 85.16%] [G loss: 1.777548]\n",
      "1859 [D loss: 0.138653, acc: 96.88%, op_acc: 87.50%] [G loss: 1.862024]\n",
      "1860 [D loss: 0.142102, acc: 95.31%, op_acc: 84.38%] [G loss: 1.834548]\n",
      "Epoch: 1860, F1: 0.01330, F1P: 186\n",
      "[[21612  6820]\n",
      " [    3    46]]\n",
      "96.25\n",
      "1861 [D loss: 0.144493, acc: 97.66%, op_acc: 85.94%] [G loss: 1.817500]\n",
      "1862 [D loss: 0.137743, acc: 97.66%, op_acc: 83.59%] [G loss: 1.777291]\n",
      "1863 [D loss: 0.144771, acc: 94.53%, op_acc: 89.84%] [G loss: 1.771323]\n",
      "1864 [D loss: 0.154345, acc: 96.09%, op_acc: 82.81%] [G loss: 1.753369]\n",
      "1865 [D loss: 0.139891, acc: 96.88%, op_acc: 85.16%] [G loss: 1.831250]\n",
      "1866 [D loss: 0.162650, acc: 96.88%, op_acc: 85.16%] [G loss: 1.639643]\n",
      "1867 [D loss: 0.145725, acc: 93.75%, op_acc: 85.94%] [G loss: 1.831869]\n",
      "1868 [D loss: 0.138194, acc: 97.66%, op_acc: 86.72%] [G loss: 1.799834]\n",
      "1869 [D loss: 0.158193, acc: 96.09%, op_acc: 79.69%] [G loss: 1.650909]\n",
      "1870 [D loss: 0.149566, acc: 96.09%, op_acc: 88.28%] [G loss: 1.740631]\n",
      "Epoch: 1870, F1: 0.01416, F1P: 187\n",
      "[[22029  6403]\n",
      " [    3    46]]\n",
      "96.328125\n",
      "1871 [D loss: 0.155033, acc: 94.53%, op_acc: 87.50%] [G loss: 1.788404]\n",
      "1872 [D loss: 0.158348, acc: 93.75%, op_acc: 84.38%] [G loss: 1.799697]\n",
      "1873 [D loss: 0.153688, acc: 98.44%, op_acc: 77.34%] [G loss: 1.863559]\n",
      "1874 [D loss: 0.146131, acc: 95.31%, op_acc: 85.16%] [G loss: 1.800950]\n",
      "1875 [D loss: 0.164309, acc: 92.97%, op_acc: 81.25%] [G loss: 1.819678]\n",
      "1876 [D loss: 0.150892, acc: 93.75%, op_acc: 81.25%] [G loss: 1.734612]\n",
      "1877 [D loss: 0.137278, acc: 96.88%, op_acc: 85.16%] [G loss: 1.856235]\n",
      "1878 [D loss: 0.157358, acc: 95.31%, op_acc: 79.69%] [G loss: 1.756229]\n",
      "1879 [D loss: 0.152349, acc: 96.09%, op_acc: 78.91%] [G loss: 1.815054]\n",
      "1880 [D loss: 0.156016, acc: 94.53%, op_acc: 82.81%] [G loss: 1.767776]\n",
      "Epoch: 1880, F1: 0.00948, F1P: 188\n",
      "[[18402 10030]\n",
      " [    1    48]]\n",
      "95.15625\n",
      "1881 [D loss: 0.158617, acc: 97.66%, op_acc: 82.81%] [G loss: 1.818617]\n",
      "1882 [D loss: 0.139856, acc: 97.66%, op_acc: 85.16%] [G loss: 1.908915]\n",
      "1883 [D loss: 0.130571, acc: 97.66%, op_acc: 85.16%] [G loss: 1.831517]\n",
      "1884 [D loss: 0.144090, acc: 94.53%, op_acc: 87.50%] [G loss: 1.825376]\n",
      "1885 [D loss: 0.152808, acc: 95.31%, op_acc: 83.59%] [G loss: 1.839020]\n",
      "1886 [D loss: 0.138438, acc: 97.66%, op_acc: 88.28%] [G loss: 1.692538]\n",
      "1887 [D loss: 0.147321, acc: 98.44%, op_acc: 86.72%] [G loss: 1.907744]\n",
      "1888 [D loss: 0.147836, acc: 93.75%, op_acc: 85.94%] [G loss: 1.900613]\n",
      "1889 [D loss: 0.161906, acc: 94.53%, op_acc: 79.69%] [G loss: 1.790521]\n",
      "1890 [D loss: 0.158561, acc: 92.19%, op_acc: 88.28%] [G loss: 1.823720]\n",
      "Epoch: 1890, F1: 0.00936, F1P: 189\n",
      "[[18271 10161]\n",
      " [    1    48]]\n",
      "95.9375\n",
      "1891 [D loss: 0.140172, acc: 96.88%, op_acc: 83.59%] [G loss: 1.640057]\n",
      "1892 [D loss: 0.159820, acc: 95.31%, op_acc: 81.25%] [G loss: 1.871357]\n",
      "1893 [D loss: 0.147547, acc: 96.88%, op_acc: 81.25%] [G loss: 1.960639]\n",
      "1894 [D loss: 0.159279, acc: 93.75%, op_acc: 85.94%] [G loss: 1.898507]\n",
      "1895 [D loss: 0.170430, acc: 92.97%, op_acc: 84.38%] [G loss: 1.861577]\n",
      "1896 [D loss: 0.150656, acc: 96.09%, op_acc: 85.16%] [G loss: 1.916872]\n",
      "1897 [D loss: 0.145376, acc: 96.09%, op_acc: 78.12%] [G loss: 1.825701]\n",
      "1898 [D loss: 0.158477, acc: 95.31%, op_acc: 81.25%] [G loss: 1.934274]\n",
      "1899 [D loss: 0.137355, acc: 98.44%, op_acc: 87.50%] [G loss: 1.833513]\n",
      "1900 [D loss: 0.159534, acc: 93.75%, op_acc: 79.69%] [G loss: 1.892897]\n",
      "Epoch: 1900, F1: 0.00553, F1P: 190\n",
      "[[10801 17631]\n",
      " [    0    49]]\n",
      "95.546875\n",
      "1901 [D loss: 0.148223, acc: 96.88%, op_acc: 85.16%] [G loss: 1.939600]\n",
      "1902 [D loss: 0.149883, acc: 97.66%, op_acc: 86.72%] [G loss: 1.825748]\n",
      "1903 [D loss: 0.153283, acc: 96.09%, op_acc: 79.69%] [G loss: 1.924430]\n",
      "1904 [D loss: 0.130232, acc: 96.88%, op_acc: 84.38%] [G loss: 1.861081]\n",
      "1905 [D loss: 0.153833, acc: 96.09%, op_acc: 88.28%] [G loss: 1.801335]\n",
      "1906 [D loss: 0.145693, acc: 94.53%, op_acc: 88.28%] [G loss: 1.787263]\n",
      "1907 [D loss: 0.133361, acc: 96.09%, op_acc: 88.28%] [G loss: 1.869571]\n",
      "1908 [D loss: 0.153024, acc: 96.09%, op_acc: 84.38%] [G loss: 1.898010]\n",
      "1909 [D loss: 0.141559, acc: 97.66%, op_acc: 86.72%] [G loss: 1.954170]\n",
      "1910 [D loss: 0.144069, acc: 97.66%, op_acc: 84.38%] [G loss: 1.924633]\n",
      "Epoch: 1910, F1: 0.00436, F1P: 191\n",
      "[[ 6054 22378]\n",
      " [    0    49]]\n",
      "96.5625\n",
      "1911 [D loss: 0.121715, acc: 99.22%, op_acc: 86.72%] [G loss: 1.845683]\n",
      "1912 [D loss: 0.144954, acc: 96.09%, op_acc: 82.03%] [G loss: 1.850578]\n",
      "1913 [D loss: 0.143450, acc: 94.53%, op_acc: 83.59%] [G loss: 1.788372]\n",
      "1914 [D loss: 0.146963, acc: 96.09%, op_acc: 84.38%] [G loss: 1.867663]\n",
      "1915 [D loss: 0.145272, acc: 96.09%, op_acc: 87.50%] [G loss: 1.872662]\n",
      "1916 [D loss: 0.139132, acc: 95.31%, op_acc: 89.84%] [G loss: 1.836485]\n",
      "1917 [D loss: 0.148098, acc: 97.66%, op_acc: 86.72%] [G loss: 1.860998]\n",
      "1918 [D loss: 0.145094, acc: 96.09%, op_acc: 86.72%] [G loss: 1.944189]\n",
      "1919 [D loss: 0.141382, acc: 95.31%, op_acc: 79.69%] [G loss: 1.822323]\n",
      "1920 [D loss: 0.146218, acc: 95.31%, op_acc: 86.72%] [G loss: 1.916626]\n",
      "Epoch: 1920, F1: 0.00566, F1P: 192\n",
      "[[11220 17212]\n",
      " [    0    49]]\n",
      "96.171875\n",
      "1921 [D loss: 0.136880, acc: 98.44%, op_acc: 83.59%] [G loss: 1.919068]\n",
      "1922 [D loss: 0.143568, acc: 97.66%, op_acc: 85.16%] [G loss: 1.826645]\n",
      "1923 [D loss: 0.151824, acc: 98.44%, op_acc: 85.16%] [G loss: 1.764438]\n",
      "1924 [D loss: 0.156796, acc: 95.31%, op_acc: 85.94%] [G loss: 1.818176]\n",
      "1925 [D loss: 0.139955, acc: 96.09%, op_acc: 78.12%] [G loss: 1.723916]\n",
      "1926 [D loss: 0.141127, acc: 97.66%, op_acc: 89.84%] [G loss: 1.861693]\n",
      "1927 [D loss: 0.141000, acc: 96.88%, op_acc: 90.62%] [G loss: 1.743850]\n",
      "1928 [D loss: 0.140746, acc: 97.66%, op_acc: 92.19%] [G loss: 1.806635]\n",
      "1929 [D loss: 0.150032, acc: 96.09%, op_acc: 83.59%] [G loss: 1.797025]\n",
      "1930 [D loss: 0.158670, acc: 92.97%, op_acc: 82.81%] [G loss: 1.820437]\n",
      "Epoch: 1930, F1: 0.00567, F1P: 193\n",
      "[[11250 17182]\n",
      " [    0    49]]\n",
      "96.71875\n",
      "1931 [D loss: 0.149742, acc: 96.88%, op_acc: 84.38%] [G loss: 1.875016]\n",
      "1932 [D loss: 0.146036, acc: 98.44%, op_acc: 86.72%] [G loss: 1.739069]\n",
      "1933 [D loss: 0.139629, acc: 96.88%, op_acc: 85.16%] [G loss: 1.723258]\n",
      "1934 [D loss: 0.140119, acc: 97.66%, op_acc: 85.94%] [G loss: 1.949825]\n",
      "1935 [D loss: 0.146914, acc: 96.09%, op_acc: 83.59%] [G loss: 1.784964]\n",
      "1936 [D loss: 0.138383, acc: 97.66%, op_acc: 85.16%] [G loss: 1.875552]\n",
      "1937 [D loss: 0.121639, acc: 99.22%, op_acc: 87.50%] [G loss: 1.930871]\n",
      "1938 [D loss: 0.147420, acc: 96.09%, op_acc: 86.72%] [G loss: 1.844214]\n",
      "1939 [D loss: 0.144060, acc: 96.09%, op_acc: 85.94%] [G loss: 1.836714]\n",
      "1940 [D loss: 0.142482, acc: 93.75%, op_acc: 88.28%] [G loss: 1.894961]\n",
      "Epoch: 1940, F1: 0.00599, F1P: 194\n",
      "[[12157 16275]\n",
      " [    0    49]]\n",
      "96.875\n",
      "1941 [D loss: 0.129697, acc: 96.88%, op_acc: 86.72%] [G loss: 1.828907]\n",
      "1942 [D loss: 0.137051, acc: 96.09%, op_acc: 87.50%] [G loss: 2.067377]\n",
      "1943 [D loss: 0.128908, acc: 98.44%, op_acc: 85.94%] [G loss: 1.861406]\n",
      "1944 [D loss: 0.142970, acc: 94.53%, op_acc: 85.16%] [G loss: 1.968704]\n",
      "1945 [D loss: 0.131996, acc: 100.00%, op_acc: 87.50%] [G loss: 1.854811]\n",
      "1946 [D loss: 0.138694, acc: 97.66%, op_acc: 89.06%] [G loss: 1.801996]\n",
      "1947 [D loss: 0.138139, acc: 97.66%, op_acc: 90.62%] [G loss: 1.754410]\n",
      "1948 [D loss: 0.135375, acc: 97.66%, op_acc: 87.50%] [G loss: 1.733327]\n",
      "1949 [D loss: 0.137511, acc: 97.66%, op_acc: 89.06%] [G loss: 1.968652]\n",
      "1950 [D loss: 0.137307, acc: 98.44%, op_acc: 83.59%] [G loss: 1.780581]\n",
      "Epoch: 1950, F1: 0.00599, F1P: 195\n",
      "[[12172 16260]\n",
      " [    0    49]]\n",
      "97.5\n",
      "1951 [D loss: 0.148395, acc: 95.31%, op_acc: 88.28%] [G loss: 1.857482]\n",
      "1952 [D loss: 0.154815, acc: 93.75%, op_acc: 85.94%] [G loss: 1.935773]\n",
      "1953 [D loss: 0.153405, acc: 94.53%, op_acc: 80.47%] [G loss: 1.882472]\n",
      "1954 [D loss: 0.132624, acc: 98.44%, op_acc: 86.72%] [G loss: 1.925818]\n",
      "1955 [D loss: 0.162524, acc: 91.41%, op_acc: 82.81%] [G loss: 1.770335]\n",
      "1956 [D loss: 0.164856, acc: 93.75%, op_acc: 85.16%] [G loss: 1.867209]\n",
      "1957 [D loss: 0.131388, acc: 98.44%, op_acc: 89.06%] [G loss: 1.879254]\n",
      "1958 [D loss: 0.131251, acc: 96.88%, op_acc: 87.50%] [G loss: 1.847309]\n",
      "1959 [D loss: 0.147892, acc: 92.97%, op_acc: 82.81%] [G loss: 1.771671]\n",
      "1960 [D loss: 0.140014, acc: 94.53%, op_acc: 85.94%] [G loss: 1.840916]\n",
      "Epoch: 1960, F1: 0.00722, F1P: 196\n",
      "[[15227 13205]\n",
      " [    1    48]]\n",
      "95.0\n",
      "1961 [D loss: 0.131343, acc: 100.00%, op_acc: 87.50%] [G loss: 1.943474]\n",
      "1962 [D loss: 0.138160, acc: 96.88%, op_acc: 85.16%] [G loss: 1.835331]\n",
      "1963 [D loss: 0.120424, acc: 96.88%, op_acc: 88.28%] [G loss: 1.680763]\n",
      "1964 [D loss: 0.139846, acc: 96.09%, op_acc: 87.50%] [G loss: 1.820913]\n",
      "1965 [D loss: 0.147796, acc: 95.31%, op_acc: 88.28%] [G loss: 1.930439]\n",
      "1966 [D loss: 0.125407, acc: 96.88%, op_acc: 90.62%] [G loss: 1.785592]\n",
      "1967 [D loss: 0.134468, acc: 98.44%, op_acc: 85.94%] [G loss: 1.878539]\n",
      "1968 [D loss: 0.125235, acc: 99.22%, op_acc: 88.28%] [G loss: 1.888112]\n",
      "1969 [D loss: 0.120289, acc: 99.22%, op_acc: 93.75%] [G loss: 1.857666]\n",
      "1970 [D loss: 0.146273, acc: 94.53%, op_acc: 90.62%] [G loss: 1.859559]\n",
      "Epoch: 1970, F1: 0.00677, F1P: 197\n",
      "[[14340 14092]\n",
      " [    1    48]]\n",
      "97.34375\n",
      "1971 [D loss: 0.145000, acc: 98.44%, op_acc: 83.59%] [G loss: 1.850948]\n",
      "1972 [D loss: 0.149703, acc: 96.09%, op_acc: 85.94%] [G loss: 1.905422]\n",
      "1973 [D loss: 0.146903, acc: 96.09%, op_acc: 86.72%] [G loss: 1.869080]\n",
      "1974 [D loss: 0.134390, acc: 97.66%, op_acc: 89.06%] [G loss: 1.906905]\n",
      "1975 [D loss: 0.119812, acc: 97.66%, op_acc: 90.62%] [G loss: 1.820024]\n",
      "1976 [D loss: 0.132754, acc: 97.66%, op_acc: 88.28%] [G loss: 1.856142]\n",
      "1977 [D loss: 0.144988, acc: 96.09%, op_acc: 86.72%] [G loss: 1.805649]\n",
      "1978 [D loss: 0.140605, acc: 96.88%, op_acc: 83.59%] [G loss: 1.848854]\n",
      "1979 [D loss: 0.145395, acc: 94.53%, op_acc: 88.28%] [G loss: 1.785661]\n",
      "1980 [D loss: 0.132491, acc: 98.44%, op_acc: 89.84%] [G loss: 1.812444]\n",
      "Epoch: 1980, F1: 0.00434, F1P: 198\n",
      "[[ 5970 22462]\n",
      " [    0    49]]\n",
      "96.953125\n",
      "1981 [D loss: 0.138242, acc: 96.09%, op_acc: 87.50%] [G loss: 1.731976]\n",
      "1982 [D loss: 0.131786, acc: 97.66%, op_acc: 85.94%] [G loss: 1.790249]\n",
      "1983 [D loss: 0.127892, acc: 98.44%, op_acc: 88.28%] [G loss: 1.942707]\n",
      "1984 [D loss: 0.147253, acc: 96.88%, op_acc: 87.50%] [G loss: 1.863962]\n",
      "1985 [D loss: 0.154169, acc: 95.31%, op_acc: 84.38%] [G loss: 1.852062]\n",
      "1986 [D loss: 0.137643, acc: 96.09%, op_acc: 86.72%] [G loss: 1.869774]\n",
      "1987 [D loss: 0.133952, acc: 95.31%, op_acc: 86.72%] [G loss: 1.784727]\n",
      "1988 [D loss: 0.144233, acc: 99.22%, op_acc: 85.16%] [G loss: 1.860547]\n",
      "1989 [D loss: 0.146260, acc: 96.09%, op_acc: 84.38%] [G loss: 1.844074]\n",
      "1990 [D loss: 0.131005, acc: 96.88%, op_acc: 85.94%] [G loss: 1.900390]\n",
      "Epoch: 1990, F1: 0.00463, F1P: 199\n",
      "[[ 7347 21085]\n",
      " [    0    49]]\n",
      "96.796875\n",
      "1991 [D loss: 0.134419, acc: 98.44%, op_acc: 92.97%] [G loss: 1.883491]\n",
      "1992 [D loss: 0.147934, acc: 96.09%, op_acc: 81.25%] [G loss: 1.802537]\n",
      "1993 [D loss: 0.140335, acc: 95.31%, op_acc: 83.59%] [G loss: 1.909217]\n",
      "1994 [D loss: 0.113223, acc: 98.44%, op_acc: 94.53%] [G loss: 1.889621]\n",
      "1995 [D loss: 0.131924, acc: 98.44%, op_acc: 92.19%] [G loss: 1.925879]\n",
      "1996 [D loss: 0.148492, acc: 96.88%, op_acc: 84.38%] [G loss: 1.907329]\n",
      "1997 [D loss: 0.125758, acc: 99.22%, op_acc: 87.50%] [G loss: 1.910610]\n",
      "1998 [D loss: 0.140201, acc: 97.66%, op_acc: 85.16%] [G loss: 1.873155]\n",
      "1999 [D loss: 0.160124, acc: 94.53%, op_acc: 81.25%] [G loss: 1.824131]\n"
     ]
    }
   ],
   "source": [
    "f1_p, d_l_p = train(X_res,y_res,\n",
    "             X_test,y_test,\n",
    "             generator,discriminator,\n",
    "             combined,\n",
    "             num_classes=2,\n",
    "             epochs=2000, \n",
    "             batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "275574636046ce8cfe041ab9776628447da970ac",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'F1 Score Validation')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f0d4b35f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.plot(f1_p)\n",
    "plt.xlabel('10 Epochs')\n",
    "plt.ylabel('F1 Score Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2efd5c2da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.plot(d_l_p)\n",
    "plt.xlabel('10 Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
